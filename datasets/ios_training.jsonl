{"instruction": "Create a SwiftUI View that utilizes the `LocalAuthentication` framework to authenticate a user via FaceID or TouchID before revealing sensitive content.", "output": "import SwiftUI\nimport LocalAuthentication\n\nstruct BiometricView: View {\n    @State private var isUnlocked = false\n\n    var body: some View {\n        VStack {\n            if isUnlocked {\n                Text(\"Sensitive Data Revealed\")\n                    .font(.title)\n                    .foregroundColor(.green)\n            } else {\n                Text(\"Locked\")\n                Button(\"Authenticate\") {\n                    authenticate()\n                }\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(8)\n            }\n        }\n    }\n\n    func authenticate() {\n        let context = LAContext()\n        var error: NSError?\n\n        if context.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &error) {\n            let reason = \"Please authenticate to unlock data.\"\n\n            context.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: reason) { success, authenticationError in\n                DispatchQueue.main.async {\n                    if success {\n                        self.isUnlocked = true\n                    } else {\n                        // Handle authentication failure\n                        print(\"Authentication failed\")\n                    }\n                }\n            }\n        } else {\n            // Biometrics not available\n            print(\"Biometrics not available\")\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI `UIViewControllerRepresentable` to wrap a native `AVCaptureVideoPreviewLayer` for a custom camera view.", "output": "import SwiftUI\nimport AVFoundation\nimport UIKit\n\nstruct CameraPreview: UIViewControllerRepresentable {\n    \n    class CameraViewController: UIViewController {\n        var captureSession: AVCaptureSession?\n        var previewLayer: AVCaptureVideoPreviewLayer?\n\n        override func viewDidLoad() {\n            super.viewDidLoad()\n            setupCamera()\n        }\n\n        func setupCamera() {\n            let session = AVCaptureSession()\n            guard let device = AVCaptureDevice.default(for: .video),\n                  let input = try? AVCaptureDeviceInput(device: device) else { return }\n            \n            if session.canAddInput(input) {\n                session.addInput(input)\n            }\n            \n            previewLayer = AVCaptureVideoPreviewLayer(session: session)\n            previewLayer?.videoGravity = .resizeAspectFill\n            previewLayer?.frame = view.layer.bounds\n            \n            if let layer = previewLayer {\n                view.layer.addSublayer(layer)\n            }\n            \n            DispatchQueue.global(qos: .background).async {\n                session.startRunning()\n            }\n            self.captureSession = session\n        }\n        \n        override func viewDidLayoutSubviews() {\n            super.viewDidLayoutSubviews()\n            previewLayer?.frame = view.bounds\n        }\n    }\n\n    func makeUIViewController(context: Context) -> CameraViewController {\n        return CameraViewController()\n    }\n\n    func updateUIViewController(_ uiViewController: CameraViewController, context: Context) {}\n}"}
{"instruction": "Write a Swift function to trigger a heavy impact haptic feedback using `UIImpactFeedbackGenerator`.", "output": "import UIKit\n\nfunc triggerHeavyHaptic() {\n    let generator = UIImpactFeedbackGenerator(style: .heavy)\n    generator.prepare()\n    generator.impactOccurred()\n}"}
{"instruction": "Use CoreMotion in Swift to query the pedometer for the number of steps taken in the last 24 hours.", "output": "import CoreMotion\n\nclass PedometerManager {\n    private let pedometer = CMPedometer()\n\n    func getStepsForLast24Hours(completion: @escaping (Int?, Error?) -> Void) {\n        guard CMPedometer.isStepCountingAvailable() else {\n            completion(nil, NSError(domain: \"Pedometer\", code: 1, userInfo: [NSLocalizedDescriptionKey: \"Step counting unavailable\"]))\n            return\n        }\n\n        let now = Date()\n        let yesterday = Calendar.current.date(byAdding: .hour, value: -24, to: now)!\n\n        pedometer.queryPedometerData(from: yesterday, to: now) { data, error in\n            if let error = error {\n                completion(nil, error)\n            } else if let data = data {\n                completion(data.numberOfSteps.intValue, nil)\n            }\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI view that displays the current magnetic heading (compass) using CoreLocation.", "output": "import SwiftUI\nimport CoreLocation\nimport Combine\n\nclass CompassManager: NSObject, ObservableObject, CLLocationManagerDelegate {\n    private let locationManager = CLLocationManager()\n    @Published var heading: Double = 0\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.requestWhenInUseAuthorization()\n        locationManager.startUpdatingHeading()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateHeading newHeading: CLHeading) {\n        self.heading = newHeading.magneticHeading\n    }\n}\n\nstruct CompassView: View {\n    @StateObject private var compass = CompassManager()\n\n    var body: some View {\n        VStack {\n            Text(\"Heading\")\n                .font(.headline)\n            Text(\"\\(Int(compass.heading))\u00b0\")\n                .font(.largeTitle)\n                .fontWeight(.bold)\n            \n            Image(systemName: \"arrow.up\")\n                .resizable()\n                .scaledToFit()\n                .frame(width: 100, height: 100)\n                .rotationEffect(Angle(degrees: -compass.heading))\n                .animation(.easeInOut, value: compass.heading)\n        }\n    }\n}"}
{"instruction": "Write a SwiftUI function to authenticate a user using FaceID or TouchID (LocalAuthentication).", "output": "import LocalAuthentication\nimport SwiftUI\n\nfunc authenticateUser(completion: @escaping (Bool) -> Void) {\n    let context = LAContext()\n    var error: NSError?\n\n    // Check if biometric authentication is available\n    if context.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &error) {\n        let reason = \"Authenticate to access secure data.\"\n\n        context.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: reason) { success, authenticationError in\n            DispatchQueue.main.async {\n                if success {\n                    completion(true)\n                } else {\n                    // Failed to authenticate\n                    completion(false)\n                }\n            }\n        }\n    } else {\n        // Biometrics not available\n        completion(false)\n    }\n}"}
{"instruction": "Create a SwiftUI wrapper for a native UIKit Camera View Controller using UIViewControllerRepresentable.", "output": "import SwiftUI\nimport UIKit\n\nstruct CameraView: UIViewControllerRepresentable {\n    @Binding var image: UIImage?\n    @Environment(\\.presentationMode) var presentationMode\n\n    class Coordinator: NSObject, UINavigationControllerDelegate, UIImagePickerControllerDelegate {\n        let parent: CameraView\n\n        init(parent: CameraView) {\n            self.parent = parent\n        }\n\n        func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey : Any]) {\n            if let uiImage = info[.originalImage] as? UIImage {\n                parent.image = uiImage\n            }\n            parent.presentationMode.wrappedValue.dismiss()\n        }\n    }\n\n    func makeCoordinator() -> Coordinator {\n        Coordinator(parent: self)\n    }\n\n    func makeUIViewController(context: Context) -> UIImagePickerController {\n        let picker = UIImagePickerController()\n        picker.delegate = context.coordinator\n        picker.sourceType = .camera\n        return picker\n    }\n\n    func updateUIViewController(_ uiViewController: UIImagePickerController, context: Context) {}\n}"}
{"instruction": "Implement a SwiftUI view that triggers haptic feedback using UIImpactFeedbackGenerator.", "output": "import SwiftUI\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            // Trigger Haptic Feedback\n            let generator = UIImpactFeedbackGenerator(style: .medium)\n            generator.prepare()\n            generator.impactOccurred()\n        }) {\n            Text(\"Tap for Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(10)\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI ObservableObject that monitors the device's accelerometer using CoreMotion to detect tilt.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private var motionManager: CMMotionManager\n    @Published var x: Double = 0.0\n    @Published var y: Double = 0.0\n    @Published var z: Double = 0.0\n\n    init() {\n        self.motionManager = CMMotionManager()\n        self.motionManager.accelerometerUpdateInterval = 0.1\n        startAccelerometers()\n    }\n\n    private func startAccelerometers() {\n        if self.motionManager.isAccelerometerAvailable {\n            self.motionManager.startAccelerometerUpdates(to: .main) { (data, error) in\n                guard let data = data else { return }\n                self.x = data.acceleration.x\n                self.y = data.acceleration.y\n                self.z = data.acceleration.z\n            }\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI `UIViewRepresentable` to display a native UIKit `WKWebView`.", "output": "import SwiftUI\nimport WebKit\n\nstruct WebView: UIViewRepresentable {\n    let url: URL\n\n    func makeUIView(context: Context) -> WKWebView {\n        return WKWebView()\n    }\n\n    func updateUIView(_ uiView: WKWebView, context: Context) {\n        let request = URLRequest(url: url)\n        uiView.load(request)\n    }\n}\n\n// Usage Example:\n// WebView(url: URL(string: \"https://www.apple.com\")!)"}
{"instruction": "Create a SwiftUI view that triggers Haptic Feedback (Impact) when a button is pressed.", "output": "import SwiftUI\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            let impactMed = UIImpactFeedbackGenerator(style: .medium)\n            impactMed.impactOccurred()\n        }) {\n            Text(\"Press for Haptics\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(8)\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI View that displays the current value of the Proximity Sensor (detecting if the phone is held near the ear).", "output": "import SwiftUI\n\nstruct ProximityView: View {\n    @State private var isClose = false\n\n    var body: some View {\n        Text(isClose ? \"Near Ear\" : \"Far Away\")\n            .font(.largeTitle)\n            .onAppear {\n                UIDevice.current.isProximityMonitoringEnabled = true\n                NotificationCenter.default.addObserver(\n                    forName: UIDevice.proximityStateDidChangeNotification,\n                    object: nil,\n                    queue: .main\n                ) { _ in\n                    self.isClose = UIDevice.current.proximityState\n                }\n            }\n            .onDisappear {\n                UIDevice.current.isProximityMonitoringEnabled = false\n            }\n    }\n}"}
{"instruction": "Create a SwiftUI view that displays live accelerometer data (X, Y, Z) using CoreMotion.", "output": "import SwiftUI\nimport CoreMotion\n\nstruct AccelerometerView: View {\n    @State private var x = 0.0\n    @State private var y = 0.0\n    @State private var z = 0.0\n    let motionManager = CMMotionManager()\n\n    var body: some View {\n        VStack(spacing: 20) {\n            Text(\"Accelerometer Data\")\n                .font(.headline)\n            Text(\"X: \\(x, specifier: \"%.2f\")\")\n            Text(\"Y: \\(y, specifier: \"%.2f\")\")\n            Text(\"Z: \\(z, specifier: \"%.2f\")\")\n        }\n        .onAppear {\n            startAccelerometers()\n        }\n        .onDisappear {\n            motionManager.stopAccelerometerUpdates()\n        }\n    }\n\n    func startAccelerometers() {\n        if motionManager.isAccelerometerAvailable {\n            motionManager.accelerometerUpdateInterval = 0.1\n            motionManager.startAccelerometerUpdates(to: .main) { data, error in\n                guard let data = data else { return }\n                self.x = data.acceleration.x\n                self.y = data.acceleration.y\n                self.z = data.acceleration.z\n            }\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI function to play a complex haptic pattern (sharp tap followed by a rumble) using CoreHaptics.", "output": "import CoreHaptics\nimport SwiftUI\n\nclass HapticManager {\n    var engine: CHHapticEngine?\n\n    init() {\n        prepareHaptics()\n    }\n\n    func prepareHaptics() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        do {\n            engine = try CHHapticEngine()\n            try engine?.start()\n        } catch {\n            print(\"Haptic engine error: \\(error.localizedDescription)\")\n        }\n    }\n\n    func playComplexPattern() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n\n        var events = [CHHapticEvent]()\n\n        // Sharp tap\n        let intensity = CHHapticEventParameter(parameterID: .hapticIntensity, value: 1.0)\n        let sharpness = CHHapticEventParameter(parameterID: .hapticSharpness, value: 1.0)\n        let tap = CHHapticEvent(eventType: .hapticTransient, parameters: [intensity, sharpness], relativeTime: 0)\n        events.append(tap)\n\n        // Rumble 0.1 seconds later\n        let rumbleIntensity = CHHapticEventParameter(parameterID: .hapticIntensity, value: 0.8)\n        let rumbleSharpness = CHHapticEventParameter(parameterID: .hapticSharpness, value: 0.2)\n        let rumble = CHHapticEvent(eventType: .hapticContinuous, parameters: [rumbleIntensity, rumbleSharpness], relativeTime: 0.1, duration: 0.5)\n        events.append(rumble)\n\n        do {\n            let pattern = try CHHapticPattern(events: events, parameters: [])\n            let player = try engine?.makePlayer(with: pattern)\n            try player?.start(atTime: 0)\n        } catch {\n            print(\"Failed to play pattern: \\(error.localizedDescription)\")\n        }\n    }\n}"}
{"instruction": "Build a SwiftUI view using ARKit (via UIViewRepresentable) that places a simple blue box 0.5 meters in front of the camera.", "output": "import SwiftUI\nimport RealityKit\n\nstruct ARBoxView: UIViewRepresentable {\n    func makeUIView(context: Context) -> ARView {\n        let arView = ARView(frame: .zero)\n\n        // Create a cube model\n        let mesh = MeshResource.generateBox(size: 0.1)\n        let material = SimpleMaterial(color: .blue, isMetallic: true)\n        let modelEntity = ModelEntity(mesh: mesh, materials: [material])\n\n        // Create an anchor 0.5 meters in front of the camera\n        let anchor = AnchorEntity(.camera)\n        modelEntity.transform.translation = [0, 0, -0.5]\n        \n        anchor.addChild(modelEntity)\n        arView.scene.addAnchor(anchor)\n\n        return arView\n    }\n\n    func updateUIView(_ uiView: ARView, context: Context) {}\n}"}
{"instruction": "Create a SwiftUI view that acts as a digital compass, rotating an arrow image based on magnetic heading.", "output": "import SwiftUI\nimport CoreLocation\n\nstruct CompassView: View {\n    @StateObject private var compass = CompassModel()\n\n    var body: some View {\n        VStack {\n            Text(\"\\(Int(compass.heading))\u00b0\")\n                .font(.largeTitle)\n                .bold()\n            \n            Image(systemName: \"arrow.up.circle.fill\")\n                .resizable()\n                .frame(width: 200, height: 200)\n                .rotationEffect(Angle(degrees: -compass.heading))\n                .animation(.easeInOut, value: compass.heading)\n        }\n    }\n}\n\nclass CompassModel: NSObject, ObservableObject, CLLocationManagerDelegate {\n    private let locationManager = CLLocationManager()\n    @Published var heading: Double = 0\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.requestWhenInUseAuthorization()\n        locationManager.startUpdatingHeading()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateHeading newHeading: CLHeading) {\n        self.heading = newHeading.magneticHeading\n    }\n}"}
{"instruction": "Create a SwiftUI ObservableObject that uses CoreMotion to read Accelerometer data and publish X, Y, and Z coordinates.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private var motionManager = CMMotionManager()\n    @Published var x = 0.0\n    @Published var y = 0.0\n    @Published var z = 0.0\n\n    init() {\n        startAccelerometer()\n    }\n\n    func startAccelerometer() {\n        if motionManager.isAccelerometerAvailable {\n            motionManager.accelerometerUpdateInterval = 0.1\n            motionManager.startAccelerometerUpdates(to: .main) { [weak self] data, error in\n                guard let data = data else { return }\n                self?.x = data.acceleration.x\n                self?.y = data.acceleration.y\n                self?.z = data.acceleration.z\n            }\n        }\n    }\n    \n    func stopAccelerometer() {\n        motionManager.stopAccelerometerUpdates()\n    }\n}"}
{"instruction": "Write a SwiftUI Button that triggers a heavy haptic impact feedback when tapped.", "output": "import SwiftUI\n\nstruct HapticButton: View {\n    var body: some View {\n        Button(action: {\n            let impactHeavy = UIImpactFeedbackGenerator(style: .heavy)\n            impactHeavy.impactOccurred()\n            print(\"Button Tapped\")\n        }) {\n            Text(\"Trigger Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(10)\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI UIViewRepresentable to wrap a native UIKit MKMapView.", "output": "import SwiftUI\nimport MapKit\n\nstruct MapViewWrapper: UIViewRepresentable {\n    func makeUIView(context: Context) -> MKMapView {\n        let mapView = MKMapView()\n        mapView.showsUserLocation = true\n        mapView.userTrackingMode = .follow\n        return mapView\n    }\n\n    func updateUIView(_ uiView: MKMapView, context: Context) {\n        // Update map view configuration here if needed\n    }\n}"}
{"instruction": "Create a SwiftUI view that displays altitude changes using CMAltimeter (Barometer).", "output": "import SwiftUI\nimport CoreMotion\n\nstruct AltimeterView: View {\n    @State private var relativeAltitude: String = \"0.0 m\"\n    private let altimeter = CMAltimeter()\n\n    var body: some View {\n        Text(\"Relative Altitude: \\(relativeAltitude)\")\n            .onAppear {\n                if CMAltimeter.isRelativeAltitudeAvailable() {\n                    altimeter.startRelativeAltitudeUpdates(to: .main) { data, error in\n                        if let data = data {\n                            self.relativeAltitude = String(format: \"%.2f m\", data.relativeAltitude.doubleValue)\n                        }\n                    }\n                } else {\n                    relativeAltitude = \"Not Available\"\n                }\n            }\n            .onDisappear {\n                altimeter.stopRelativeAltitudeUpdates()\n            }\n    }\n}"}
{"instruction": "Create a SwiftUI View with a button that triggers a 'heavy' haptic feedback impact when tapped using UIKit integration.", "output": "import SwiftUI\nimport UIKit\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            let generator = UIImpactFeedbackGenerator(style: .heavy)\n            generator.prepare()\n            generator.impactOccurred()\n        }) {\n            Text(\"Trigger Heavy Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(10)\n        }\n    }\n}"}
{"instruction": "Build a `UIViewRepresentable` in SwiftUI to display a live camera feed using `AVFoundation`.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreview: UIViewRepresentable {\n    class VideoPreviewView: UIView {\n        override class var layerClass: AnyClass {\n            AVCaptureVideoPreviewLayer.self\n        }\n        \n        var videoPreviewLayer: AVCaptureVideoPreviewLayer {\n            return layer as! AVCaptureVideoPreviewLayer\n        }\n    }\n\n    func makeUIView(context: Context) -> VideoPreviewView {\n        let view = VideoPreviewView()\n        view.backgroundColor = .black\n        \n        let session = AVCaptureSession()\n        if let device = AVCaptureDevice.default(for: .video),\n           let input = try? AVCaptureDeviceInput(device: device) {\n            if session.canAddInput(input) {\n                session.addInput(input)\n            }\n        }\n        \n        view.videoPreviewLayer.session = session\n        view.videoPreviewLayer.videoGravity = .resizeAspectFill\n        \n        DispatchQueue.global(qos: .userInitiated).async {\n            session.startRunning()\n        }\n        \n        return view\n    }\n\n    func updateUIView(_ uiView: VideoPreviewView, context: Context) {}\n}"}
{"instruction": "Use Swift and `CoreMotion` to create a `MotionManager` class that publishes the device's pitch, roll, and yaw.", "output": "import CoreMotion\nimport Combine\n\nclass MotionManager: ObservableObject {\n    private let motionManager = CMMotionManager()\n    @Published var pitch: Double = 0.0\n    @Published var roll: Double = 0.0\n    @Published var yaw: Double = 0.0\n\n    func startUpdates() {\n        if motionManager.isDeviceMotionAvailable {\n            motionManager.deviceMotionUpdateInterval = 0.1\n            motionManager.startDeviceMotionUpdates(to: .main) { [weak self] (data, error) in\n                guard let data = data, error == nil else { return }\n                \n                self?.pitch = data.attitude.pitch\n                self?.roll = data.attitude.roll\n                self?.yaw = data.attitude.yaw\n            }\n        }\n    }\n\n    func stopUpdates() {\n        motionManager.stopDeviceMotionUpdates()\n    }\n}"}
{"instruction": "Apply a custom color inversion effect to an Image in SwiftUI using a Metal shader (iOS 17+).", "output": "import SwiftUI\n\n@available(iOS 17.0, *)\nstruct ShaderView: View {\n    var body: some View {\n        Image(\"exampleImage\")\n            .resizable()\n            .aspectRatio(contentMode: .fit)\n            .colorEffect(ShaderLibrary.invertColor())\n    }\n}\n\n// Assumes a .metal file exists with:\n// [[ stitchable ]]\n// half4 invertColor(float2 position, half4 color) {\n//    return half4(1.0 - color.r, 1.0 - color.g, 1.0 - color.b, color.a);\n// }"}
{"instruction": "Create a SwiftUI ObservableObject that monitors the device's accelerometer using CoreMotion and publishes X, Y, and Z coordinates.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private var motionManager: CMMotionManager\n    @Published var x: Double = 0.0\n    @Published var y: Double = 0.0\n    @Published var z: Double = 0.0\n\n    init() {\n        self.motionManager = CMMotionManager()\n        self.motionManager.accelerometerUpdateInterval = 0.1\n        startAccelerometers()\n    }\n\n    private func startAccelerometers() {\n        if self.motionManager.isAccelerometerAvailable {\n            self.motionManager.startAccelerometerUpdates(to: .main) { [weak self] (data, error) in\n                guard let data = data else { return }\n                self?.x = data.acceleration.x\n                self?.y = data.acceleration.y\n                self?.z = data.acceleration.z\n            }\n        }\n    }\n}"}
{"instruction": "Implement a custom SwiftUI `Shape` that draws a simple Triangle.", "output": "import SwiftUI\n\nstruct Triangle: Shape {\n    func path(in rect: CGRect) -> Path {\n        var path = Path()\n\n        // Start at the top center\n        path.move(to: CGPoint(x: rect.midX, y: rect.minY))\n        \n        // Draw line to bottom right\n        path.addLine(to: CGPoint(x: rect.maxX, y: rect.maxY))\n        \n        // Draw line to bottom left\n        path.addLine(to: CGPoint(x: rect.minX, y: rect.maxY))\n        \n        // Close path back to top center\n        path.closeSubpath()\n\n        return path\n    }\n}"}
{"instruction": "Write a Swift function using `UIImpactFeedbackGenerator` to trigger a 'rigid' haptic feedback event.", "output": "import UIKit\n\nfunc triggerRigidHaptic() {\n    let generator = UIImpactFeedbackGenerator(style: .rigid)\n    generator.prepare()\n    generator.impactOccurred()\n}"}
{"instruction": "Create a UIView subclass in Swift that sets up a basic AVFoundation camera preview layer.", "output": "import UIKit\nimport AVFoundation\n\nclass CameraPreviewView: UIView {\n    override class var layerClass: AnyClass {\n        return AVCaptureVideoPreviewLayer.self\n    }\n    \n    var videoPreviewLayer: AVCaptureVideoPreviewLayer {\n        return layer as! AVCaptureVideoPreviewLayer\n    }\n    \n    func setupSession(session: AVCaptureSession) {\n        videoPreviewLayer.session = session\n        videoPreviewLayer.videoGravity = .resizeAspectFill\n    }\n}"}
{"instruction": "Create a SwiftUI `UIViewRepresentable` to display a native `WKWebView` that loads a specific URL.", "output": "import SwiftUI\nimport WebKit\n\nstruct WebView: UIViewRepresentable {\n    let url: URL\n\n    func makeUIView(context: Context) -> WKWebView {\n        return WKWebView()\n    }\n\n    func updateUIView(_ webView: WKWebView, context: Context) {\n        let request = URLRequest(url: url)\n        webView.load(request)\n    }\n}\n\n// Usage:\n// WebView(url: URL(string: \"https://www.example.com\")!)"}
{"instruction": "Create a SwiftUI View that utilizes the CoreMotion framework to display real-time accelerometer data (X, Y, Z).", "output": "import SwiftUI\nimport CoreMotion\n\nstruct AccelerometerView: View {\n    @State private var x = 0.0\n    @State private var y = 0.0\n    @State private var z = 0.0\n    let motionManager = CMMotionManager()\n\n    var body: some View {\n        VStack {\n            Text(\"X: \\(x, specifier: \"%.2f\")\")\n            Text(\"Y: \\(y, specifier: \"%.2f\")\")\n            Text(\"Z: \\(z, specifier: \"%.2f\")\")\n        }\n        .onAppear {\n            if motionManager.isAccelerometerAvailable {\n                motionManager.accelerometerUpdateInterval = 0.1\n                motionManager.startAccelerometerUpdates(to: .main) { data, error in\n                    guard let data = data else { return }\n                    self.x = data.acceleration.x\n                    self.y = data.acceleration.y\n                    self.z = data.acceleration.z\n                }\n            }\n        }\n        .onDisappear {\n            motionManager.stopAccelerometerUpdates()\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI function that triggers the native haptic feedback engine for a 'success' notification.", "output": "import SwiftUI\n\nfunc triggerSuccessHaptic() {\n    let generator = UINotificationFeedbackGenerator()\n    generator.prepare()\n    generator.notificationOccurred(.success)\n}\n\n// Usage inside a View:\n// Button(\"Save\") {\n//     triggerSuccessHaptic()\n// }"}
{"instruction": "Create a SwiftUI View that uses `AVCaptureVideoPreviewLayer` to show a live camera feed.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreviewView: UIViewRepresentable {\n    func makeUIView(context: Context) -> UIView {\n        let view = UIView(frame: UIScreen.main.bounds)\n        \n        let captureSession = AVCaptureSession()\n        captureSession.sessionPreset = .high\n        \n        guard let videoDevice = AVCaptureDevice.default(for: .video),\n              let videoInput = try? AVCaptureDeviceInput(device: videoDevice) else {\n            return view\n        }\n        \n        if captureSession.canAddInput(videoInput) {\n            captureSession.addInput(videoInput)\n        }\n        \n        let previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)\n        previewLayer.frame = view.frame\n        previewLayer.videoGravity = .resizeAspectFill\n        view.layer.addSublayer(previewLayer)\n        \n        DispatchQueue.global(qos: .background).async {\n            captureSession.startRunning()\n        }\n        \n        return view\n    }\n\n    func updateUIView(_ uiView: UIView, context: Context) {}\n}"}
{"instruction": "Create a SwiftUI ObservableObject that monitors the device's accelerometer using CoreMotion and publishes the X, Y, and Z values.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private var motionManager: CMMotionManager\n    @Published var x: Double = 0.0\n    @Published var y: Double = 0.0\n    @Published var z: Double = 0.0\n\n    init() {\n        self.motionManager = CMMotionManager()\n        self.startAccelerometer()\n    }\n\n    func startAccelerometer() {\n        if motionManager.isAccelerometerAvailable {\n            motionManager.accelerometerUpdateInterval = 0.1\n            motionManager.startAccelerometerUpdates(to: .main) { [weak self] (data, error) in\n                guard let data = data else { return }\n                self?.x = data.acceleration.x\n                self?.y = data.acceleration.y\n                self?.z = data.acceleration.z\n            }\n        }\n    }\n    \n    func stopAccelerometer() {\n        motionManager.stopAccelerometerUpdates()\n    }\n}"}
{"instruction": "Implement a SwiftUI `UIViewRepresentable` to display a live camera preview using `AVCaptureVideoPreviewLayer`.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreview: UIViewRepresentable {\n    let session: AVCaptureSession\n\n    func makeUIView(context: Context) -> VideoPreviewView {\n        let view = VideoPreviewView()\n        view.videoPreviewLayer.session = session\n        view.videoPreviewLayer.videoGravity = .resizeAspectFill\n        return view\n    }\n\n    func updateUIView(_ uiView: VideoPreviewView, context: Context) {}\n\n    class VideoPreviewView: UIView {\n        override class var layerClass: AnyClass {\n            AVCaptureVideoPreviewLayer.self\n        }\n\n        var videoPreviewLayer: AVCaptureVideoPreviewLayer {\n            return layer as! AVCaptureVideoPreviewLayer\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI View that triggers a heavy haptic impact feedback when a button is pressed.", "output": "import SwiftUI\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            let generator = UIImpactFeedbackGenerator(style: .heavy)\n            generator.prepare()\n            generator.impactOccurred()\n        }) {\n            Text(\"Trigger Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(8)\n        }\n    }\n}"}
{"instruction": "Implement a Location Manager in Swift that requests 'When In Use' authorization and updates user coordinates.", "output": "import Foundation\nimport CoreLocation\n\nclass LocationService: NSObject, ObservableObject, CLLocationManagerDelegate {\n    private let locationManager = CLLocationManager()\n    @Published var location: CLLocation?\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.desiredAccuracy = kCLLocationAccuracyBest\n        locationManager.requestWhenInUseAuthorization()\n        locationManager.startUpdatingLocation()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n        guard let location = locations.last else { return }\n        self.location = location\n    }\n\n    func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {\n        print(\"Location error: \\(error.localizedDescription)\")\n    }\n}"}
{"instruction": "Create a SwiftUI Button that triggers a medium native haptic feedback impact when tapped.", "output": "import SwiftUI\n\nstruct HapticButton: View {\n    var body: some View {\n        Button(action: {\n            let impactMed = UIImpactFeedbackGenerator(style: .medium)\n            impactMed.impactOccurred()\n        }) {\n            Text(\"Tap for Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(8)\n        }\n    }\n}"}
{"instruction": "Wrap a native UIKit PencilKit canvas (PKCanvasView) inside a SwiftUI UIViewRepresentable to allow drawing.", "output": "import SwiftUI\nimport PencilKit\n\nstruct CanvasView: UIViewRepresentable {\n    @Binding var canvasView: PKCanvasView\n\n    func makeUIView(context: Context) -> PKCanvasView {\n        canvasView.drawingPolicy = .anyInput\n        canvasView.tool = PKInkingTool(.pen, color: .black, width: 15)\n        return canvasView\n    }\n\n    func updateUIView(_ uiView: PKCanvasView, context: Context) {\n        // Update logic if needed\n    }\n}\n\n// Usage in View\nstruct DrawingPad: View {\n    @State private var canvas = PKCanvasView()\n    \n    var body: some View {\n        CanvasView(canvasView: $canvas)\n            .frame(maxHeight: .infinity)\n    }\n}"}
{"instruction": "Write a Swift class that uses CoreLocation to request 'When In Use' authorization and start updating location.", "output": "import CoreLocation\n\nclass LocationManager: NSObject, CLLocationManagerDelegate {\n    private let locationManager = CLLocationManager()\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.desiredAccuracy = kCLLocationAccuracyBest\n    }\n\n    func requestLocation() {\n        locationManager.requestWhenInUseAuthorization()\n        locationManager.startUpdatingLocation()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n        guard let location = locations.last else { return }\n        print(\"Lat: \\(location.coordinate.latitude), Lon: \\(location.coordinate.longitude)\")\n    }\n\n    func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {\n        print(\"Error: \\(error.localizedDescription)\")\n    }\n}"}
{"instruction": "Implement a SwiftUI struct that displays a live Camera preview using AVFoundation and UIViewRepresentable.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreview: UIViewRepresentable {\n    class VideoPreviewView: UIView {\n        override class var layerClass: AnyClass {\n             AVCaptureVideoPreviewLayer.self\n        }\n        var videoPreviewLayer: AVCaptureVideoPreviewLayer {\n            return layer as! AVCaptureVideoPreviewLayer\n        }\n    }\n\n    let session: AVCaptureSession\n\n    func makeUIView(context: Context) -> VideoPreviewView {\n        let view = VideoPreviewView()\n        view.videoPreviewLayer.session = session\n        view.videoPreviewLayer.videoGravity = .resizeAspectFill\n        return view\n    }\n\n    func updateUIView(_ uiView: VideoPreviewView, context: Context) {}\n}"}
{"instruction": "Create a SwiftUI view that acts as a digital compass. It should display the current heading and trigger a haptic feedback vibration when the device points North (between 355 and 5 degrees).", "output": "import SwiftUI\nimport CoreLocation\nimport UIKit\n\nclass CompassViewModel: NSObject, ObservableObject, CLLocationManagerDelegate {\n    private var locationManager = CLLocationManager()\n    @Published var heading: Double = 0\n    private var hasHapticked = false\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.startUpdatingHeading()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateHeading newHeading: CLHeading) {\n        self.heading = newHeading.magneticHeading\n        \n        // Haptic feedback logic for North\n        if (heading > 355 || heading < 5) {\n            if !hasHapticked {\n                let generator = UIImpactFeedbackGenerator(style: .medium)\n                generator.impactOccurred()\n                hasHapticked = true\n            }\n        } else {\n            hasHapticked = false\n        }\n    }\n}\n\nstruct CompassView: View {\n    @StateObject var viewModel = CompassViewModel()\n\n    var body: some View {\n        VStack {\n            Text(\"Heading: \\(Int(viewModel.heading))\u00b0\")\n                .font(.largeTitle)\n                .padding()\n            \n            Image(systemName: \"location.north.fill\")\n                .resizable()\n                .frame(width: 100, height: 100)\n                .rotationEffect(Angle(degrees: -viewModel.heading))\n                .foregroundColor((viewModel.heading > 355 || viewModel.heading < 5) ? .red : .primary)\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI view using AVFoundation that displays a live camera preview suitable for scanning QR codes.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreviewView: UIViewRepresentable {\n    func makeUIView(context: Context) -> UIView {\n        let view = UIView(frame: UIScreen.main.bounds)\n        \n        let captureSession = AVCaptureSession()\n        guard let videoCaptureDevice = AVCaptureDevice.default(for: .video) else { return view }\n        let videoInput: AVCaptureDeviceInput\n\n        do {\n            videoInput = try AVCaptureDeviceInput(device: videoCaptureDevice)\n        } else { return view }\n\n        if (captureSession.canAddInput(videoInput)) {\n            captureSession.addInput(videoInput)\n        } else { return view }\n\n        let videoPreviewLayer = AVCaptureVideoPreviewLayer(session: captureSession)\n        videoPreviewLayer.frame = view.layer.bounds\n        videoPreviewLayer.videoGravity = .resizeAspectFill\n        view.layer.addSublayer(videoPreviewLayer)\n\n        // Run on background thread to avoid UI blocking\n        DispatchQueue.global(qos: .userInitiated).async {\n            captureSession.startRunning()\n        }\n\n        return view\n    }\n\n    func updateUIView(_ uiView: UIView, context: Context) {}\n}"}
{"instruction": "Create a SwiftUI view that uses CoreMotion to move a circle around the screen based on the device's accelerometer tilt.", "output": "import SwiftUI\nimport CoreMotion\n\nstruct TiltBallView: View {\n    @State private var position = CGPoint(x: 200, y: 400)\n    let motionManager = CMMotionManager()\n    let timer = Timer.publish(every: 0.02, on: .main, in: .common).autoconnect()\n\n    var body: some View {\n        GeometryReader { geo in\n            Circle()\n                .fill(Color.blue)\n                .frame(width: 50, height: 50)\n                .position(position)\n                .onReceive(timer) { _ in\n                    if motionManager.isAccelerometerAvailable {\n                        motionManager.startAccelerometerUpdates()\n                        if let data = motionManager.accelerometerData {\n                            // Amplify tilt for movement\n                            let dx = CGFloat(data.acceleration.x * 20.0)\n                            let dy = CGFloat(data.acceleration.y * -20.0) // Invert Y\n                            \n                            var newX = position.x + dx\n                            var newY = position.y + dy\n                            \n                            // Boundary checks\n                            newX = max(25, min(geo.size.width - 25, newX))\n                            newY = max(25, min(geo.size.height - 25, newY))\n                            \n                            self.position = CGPoint(x: newX, y: newY)\n                        }\n                    }\n                }\n        }\n    }\n}"}
{"instruction": "Develop a SwiftUI View that visualizes microphone audio levels using a series of animated bars (Bar Chart style visualization).", "output": "import SwiftUI\nimport AVFoundation\n\nstruct AudioVisualizerView: View {\n    // Mocking the data for brevity, normally driven by AVAudioRecorder.averagePower\n    @State private var audioLevels: [CGFloat] = Array(repeating: 10.0, count: 10)\n    let timer = Timer.publish(every: 0.1, on: .main, in: .common).autoconnect()\n\n    var body: some View {\n        HStack(spacing: 4) {\n            ForEach(0..<10, id: \\.self) { index in\n                RoundedRectangle(cornerRadius: 2)\n                    .fill(Color.green)\n                    .frame(width: 20, height: audioLevels[index])\n                    .animation(.spring(), value: audioLevels[index])\n            }\n        }\n        .onReceive(timer) { _ in\n            // Simulate audio updates\n            updateLevels()\n        }\n    }\n\n    func updateLevels() {\n        // In a real app, read from AVAudioRecorder\n        for i in 0..<audioLevels.count {\n            audioLevels[i] = CGFloat.random(in: 10...100)\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI view that utilizes `CoreMotion` to display real-time accelerometer data (X, Y, Z) on screen.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private var motionManager = CMMotionManager()\n    @Published var x = 0.0\n    @Published var y = 0.0\n    @Published var z = 0.0\n\n    init() {\n        startAccelerometer()\n    }\n\n    func startAccelerometer() {\n        if motionManager.isAccelerometerAvailable {\n            motionManager.accelerometerUpdateInterval = 0.1\n            motionManager.startAccelerometerUpdates(to: .main) { [weak self] data, error in\n                guard let data = data else { return }\n                self?.x = data.acceleration.x\n                self?.y = data.acceleration.y\n                self?.z = data.acceleration.z\n            }\n        }\n    }\n}\n\nstruct AccelerometerView: View {\n    @StateObject var motion = MotionManager()\n\n    var body: some View {\n        VStack(spacing: 20) {\n            Text(\"Accelerometer Data\").font(.headline)\n            Text(\"X: \\(motion.x, specifier: \"%.2f\")\")\n            Text(\"Y: \\(motion.y, specifier: \"%.2f\")\")\n            Text(\"Z: \\(motion.z, specifier: \"%.2f\")\")\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI `UIViewRepresentable` to display a native `WKWebView` that loads a specific URL.", "output": "import SwiftUI\nimport WebKit\n\nstruct WebView: UIViewRepresentable {\n    let url: URL\n\n    func makeUIView(context: Context) -> WKWebView {\n        return WKWebView()\n    }\n\n    func updateUIView(_ uiView: WKWebView, context: Context) {\n        let request = URLRequest(url: url)\n        uiView.load(request)\n    }\n}\n\n// Usage Example\nstruct BrowserView: View {\n    var body: some View {\n        WebView(url: URL(string: \"https://www.apple.com\")!)\n            .edgesIgnoringSafeArea(.all)\n    }\n}"}
{"instruction": "Create a Swift function using `CoreHaptics` to play a transient haptic event (like a sharp tap) on supported iOS devices.", "output": "import CoreHaptics\nimport UIKit\n\nclass HapticManager {\n    private var engine: CHHapticEngine?\n\n    init() {\n        prepareHaptics()\n    }\n\n    func prepareHaptics() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        do {\n            engine = try CHHapticEngine()\n            try engine?.start()\n        } catch {\n            print(\"Haptic engine error: \\(error.localizedDescription)\")\n        }\n    }\n\n    func playTap() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        \n        let intensity = CHHapticEventParameter(parameterID: .hapticIntensity, value: 1.0)\n        let sharpness = CHHapticEventParameter(parameterID: .hapticSharpness, value: 1.0)\n        let event = CHHapticEvent(eventType: .hapticTransient, parameters: [intensity, sharpness], relativeTime: 0)\n\n        do {\n            let pattern = try CHHapticPattern(events: [event], parameters: [])\n            let player = try engine?.makePlayer(with: pattern)\n            try player?.start(atTime: 0)\n        } catch {\n            print(\"Failed to play pattern: \\(error.localizedDescription)\")\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI view that authenticates a user using FaceID or TouchID via the `LocalAuthentication` framework.", "output": "import SwiftUI\nimport LocalAuthentication\n\nstruct BiometricAuthView: View {\n    @State private var isUnlocked = false\n    \n    var body: some View {\n        VStack {\n            if isUnlocked {\n                Text(\"Welcome, User!\").font(.largeTitle)\n            } else {\n                Text(\"Locked\").font(.title)\n                Button(\"Authenticate\") {\n                    authenticate()\n                }\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(8)\n            }\n        }\n    }\n\n    func authenticate() {\n        let context = LAContext()\n        var error: NSError?\n\n        if context.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &error) {\n            let reason = \"Identify yourself to unlock the app.\"\n\n            context.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: reason) { success, authenticationError in\n                DispatchQueue.main.async {\n                    if success {\n                        self.isUnlocked = true\n                    } else {\n                        // Handle authentication failure\n                        print(\"Authentication failed\")\n                    }\n                }\n            }\n        } else {\n            // No biometrics available\n            print(\"Biometrics not available\")\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI View that triggers a heavy impact haptic feedback when a button is pressed.", "output": "import SwiftUI\nimport UIKit\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            let generator = UIImpactFeedbackGenerator(style: .heavy)\n            generator.impactOccurred()\n        }) {\n            Text(\"Trigger Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(10)\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI ObservableObject that reads the device Accelerometer data using CoreMotion.", "output": "import CoreMotion\nimport SwiftUI\n\nclass MotionManager: ObservableObject {\n    private var motionManager = CMMotionManager()\n    @Published var x = 0.0\n    @Published var y = 0.0\n    @Published var z = 0.0\n\n    init() {\n        startAccelerometer()\n    }\n\n    func startAccelerometer() {\n        if motionManager.isAccelerometerAvailable {\n            motionManager.accelerometerUpdateInterval = 0.1\n            motionManager.startAccelerometerUpdates(to: .main) { [weak self] (data, error) in\n                guard let data = data else { return }\n                self?.x = data.acceleration.x\n                self?.y = data.acceleration.y\n                self?.z = data.acceleration.z\n            }\n        }\n    }\n}"}
{"instruction": "Create a custom native SwiftUI Shape that draws a sine wave.", "output": "import SwiftUI\n\nstruct SineWaveShape: Shape {\n    var frequency: Double = 1.0\n    var amplitude: CGFloat = 50\n\n    func path(in rect: CGRect) -> Path {\n        var path = Path()\n        let width = rect.width\n        let height = rect.height\n        let midHeight = height / 2\n\n        path.move(to: CGPoint(x: 0, y: midHeight))\n\n        for x in stride(from: 0, to: width, by: 1) {\n            let relativeX = x / width\n            let sine = sin(relativeX * frequency * 2 * .pi)\n            let y = midHeight + (CGFloat(sine) * amplitude)\n            path.addLine(to: CGPoint(x: x, y: y))\n        }\n\n        return path\n    }\n}"}
{"instruction": "Implement a simple Swift class conforming to CLLocationManagerDelegate to request location permissions and print coordinates.", "output": "import CoreLocation\n\nclass LocationService: NSObject, CLLocationManagerDelegate {\n    let manager = CLLocationManager()\n\n    override init() {\n        super.init()\n        manager.delegate = self\n        manager.desiredAccuracy = kCLLocationAccuracyBest\n    }\n\n    func requestPermission() {\n        manager.requestWhenInUseAuthorization()\n    }\n\n    func start() {\n        manager.startUpdatingLocation()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n        if let location = locations.last {\n            print(\"Lat: \\(location.coordinate.latitude), Lon: \\(location.coordinate.longitude)\")\n        }\n    }\n\n    func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {\n        print(\"Location Error: \\(error)\")\n    }\n}"}
{"instruction": "Create a SwiftUI View that triggers a heavy impact haptic feedback when a button is pressed.", "output": "import SwiftUI\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            let generator = UIImpactFeedbackGenerator(style: .heavy)\n            generator.prepare()\n            generator.impactOccurred()\n        }) {\n            Text(\"Trigger Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(10)\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI ObservableObject that uses CoreMotion to read the device's accelerometer data.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private var motionManager = CMMotionManager()\n    @Published var x = 0.0\n    @Published var y = 0.0\n    @Published var z = 0.0\n\n    init() {\n        if motionManager.isAccelerometerAvailable {\n            motionManager.accelerometerUpdateInterval = 0.1\n            motionManager.startAccelerometerUpdates(to: .main) { [weak self] (data, error) in\n                guard let data = data else { return }\n                self?.x = data.acceleration.x\n                self?.y = data.acceleration.y\n                self?.z = data.acceleration.z\n            }\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI wrapper for `UIImagePickerController` to access the native camera.", "output": "import SwiftUI\nimport UIKit\n\nstruct CameraView: UIViewControllerRepresentable {\n    @Binding var image: UIImage?\n    @Environment(\\.presentationMode) var presentationMode\n\n    func makeUIViewController(context: Context) -> UIImagePickerController {\n        let picker = UIImagePickerController()\n        picker.delegate = context.coordinator\n        picker.sourceType = .camera\n        return picker\n    }\n\n    func updateUIViewController(_ uiViewController: UIImagePickerController, context: Context) {}\n\n    func makeCoordinator() -> Coordinator {\n        Coordinator(self)\n    }\n\n    class Coordinator: NSObject, UINavigationControllerDelegate, UIImagePickerControllerDelegate {\n        let parent: CameraView\n\n        init(_ parent: CameraView) {\n            self.parent = parent\n        }\n\n        func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey : Any]) {\n            if let uiImage = info[.originalImage] as? UIImage {\n                parent.image = uiImage\n            }\n            parent.presentationMode.wrappedValue.dismiss()\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI view that displays the device's battery level using `UIDevice`.", "output": "import SwiftUI\n\nstruct BatteryLevelView: View {\n    @State private var batteryLevel: Float = UIDevice.current.batteryLevel\n\n    var body: some View {\n        VStack {\n            Text(\"Battery Level\")\n                .font(.headline)\n            Text(\"\\(Int(batteryLevel * 100))%\")\n                .font(.largeTitle)\n                .foregroundColor(batteryLevel > 0.2 ? .green : .red)\n        }\n        .onAppear {\n            UIDevice.current.isBatteryMonitoringEnabled = true\n            self.batteryLevel = UIDevice.current.batteryLevel\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI view that utilizes CoreHaptics to trigger a complex haptic pattern when a user long-presses a circle.", "output": "import SwiftUI\nimport CoreHaptics\n\nstruct HapticCircleView: View {\n    @State private var engine: CHHapticEngine?\n\n    var body: some View {\n        Circle()\n            .fill(Color.blue)\n            .frame(width: 100, height: 100)\n            .onAppear(perform: prepareHaptics)\n            .onLongPressGesture(perform: playComplexHaptic)\n    }\n\n    func prepareHaptics() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        do {\n            engine = try CHHapticEngine()\n            try engine?.start()\n        } catch {\n            print(\"Haptic engine error: \\(error.localizedDescription)\")\n        }\n    }\n\n    func playComplexHaptic() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        \n        let intensity = CHHapticEventParameter(parameterID: .hapticIntensity, value: 1.0)\n        let sharpness = CHHapticEventParameter(parameterID: .hapticSharpness, value: 1.0)\n        let event = CHHapticEvent(eventType: .hapticTransient, parameters: [intensity, sharpness], relativeTime: 0)\n\n        do {\n            let pattern = try CHHapticPattern(events: [event], parameters: [])\n            let player = try engine?.makePlayer(with: pattern)\n            try player?.start(atTime: 0)\n        } catch {\n            print(\"Failed to play pattern: \\(error.localizedDescription)\")\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI view utilizing `CMAltimeter` to display relative altitude changes.", "output": "import SwiftUI\nimport CoreMotion\n\nstruct AltimeterView: View {\n    @State private var relativeAltitude: String = \"0.0 m\"\n    private let altimeter = CMAltimeter()\n\n    var body: some View {\n        VStack {\n            Text(\"Relative Altitude Change\")\n                .font(.headline)\n            Text(relativeAltitude)\n                .font(.largeTitle)\n                .padding()\n        }\n        .onAppear(perform: startAltimeter)\n        .onDisappear(perform: stopAltimeter)\n    }\n\n    func startAltimeter() {\n        if CMAltimeter.isRelativeAltitudeAvailable() {\n            altimeter.startRelativeAltitudeUpdates(to: .main) { data, error in\n                if let data = data {\n                    let altitude = String(format: \"%.2f m\", data.relativeAltitude.doubleValue)\n                    self.relativeAltitude = altitude\n                }\n            }\n        } else {\n            self.relativeAltitude = \"Not Available\"\n        }\n    }\n\n    func stopAltimeter() {\n        altimeter.stopRelativeAltitudeUpdates()\n    }\n}"}
{"instruction": "Create a SwiftUI implementation of a `UIViewControllerRepresentable` to wrap a native `UIImagePickerController` for selecting an image.", "output": "import SwiftUI\nimport UIKit\n\nstruct ImagePicker: UIViewControllerRepresentable {\n    @Binding var selectedImage: UIImage?\n    @Environment(\\.presentationMode) var presentationMode\n\n    class Coordinator: NSObject, UINavigationControllerDelegate, UIImagePickerControllerDelegate {\n        let parent: ImagePicker\n\n        init(_ parent: ImagePicker) {\n            self.parent = parent\n        }\n\n        func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey : Any]) {\n            if let image = info[.originalImage] as? UIImage {\n                parent.selectedImage = image\n            }\n            parent.presentationMode.wrappedValue.dismiss()\n        }\n    }\n\n    func makeCoordinator() -> Coordinator {\n        Coordinator(self)\n    }\n\n    func makeUIViewController(context: Context) -> UIImagePickerController {\n        let picker = UIImagePickerController()\n        picker.delegate = context.coordinator\n        return picker\n    }\n\n    func updateUIViewController(_ uiViewController: UIImagePickerController, context: Context) {}\n}"}
{"instruction": "Write a SwiftUI View that uses `MapKit` to display a map centered on the user's location with a tracking mode button.", "output": "import SwiftUI\nimport MapKit\n\nstruct UserLocationMapView: View {\n    @State private var region = MKCoordinateRegion(\n        center: CLLocationCoordinate2D(latitude: 37.7749, longitude: -122.4194),\n        span: MKCoordinateSpan(latitudeDelta: 0.05, longitudeDelta: 0.05)\n    )\n    @State private var trackingMode: MapUserTrackingMode = .follow\n\n    var body: some View {\n        Map(coordinateRegion: $region,\n            showsUserLocation: true,\n            userTrackingMode: $trackingMode)\n            .edgesIgnoringSafeArea(.all)\n            .overlay(\n                Button(action: {\n                    trackingMode = .follow\n                }) {\n                    Image(systemName: \"location.fill\")\n                        .padding()\n                        .background(Color.white)\n                        .clipShape(Circle())\n                        .shadow(radius: 4)\n                }\n                .padding(),\n                alignment: .bottomTrailing\n            )\n    }\n}"}
{"instruction": "SwiftUI: Create a native camera preview view using `AVFoundation` wrapped in `UIViewRepresentable`.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreview: UIViewRepresentable {\n    class VideoPreviewView: UIView {\n        override class var layerClass: AnyClass {\n             AVCaptureVideoPreviewLayer.self\n        }\n        \n        var videoPreviewLayer: AVCaptureVideoPreviewLayer {\n            return layer as! AVCaptureVideoPreviewLayer\n        }\n    }\n    \n    let session: AVCaptureSession\n    \n    func makeUIView(context: Context) -> VideoPreviewView {\n        let view = VideoPreviewView()\n        view.backgroundColor = .black\n        view.videoPreviewLayer.session = session\n        view.videoPreviewLayer.videoGravity = .resizeAspectFill\n        return view\n    }\n    \n    func updateUIView(_ uiView: VideoPreviewView, context: Context) {}\n}\n\n// Usage inside a View\n// CameraPreview(session: session)"}
{"instruction": "SwiftUI: Implement a CoreHaptics engine to play a transient haptic pattern when a button is pressed.", "output": "import SwiftUI\nimport CoreHaptics\n\nstruct HapticButtonView: View {\n    @State private var engine: CHHapticEngine?\n\n    var body: some View {\n        Button(\"Feel Impact\") {\n            playHaptic()\n        }\n        .onAppear(perform: prepareHaptics)\n    }\n\n    func prepareHaptics() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        do {\n            engine = try CHHapticEngine()\n            try engine?.start()\n        } catch {\n            print(\"Haptic engine error: \\(error.localizedDescription)\")\n        }\n    }\n\n    func playHaptic() {\n        guard let engine = engine else { return }\n        \n        let intensity = CHHapticEventParameter(parameterID: .hapticIntensity, value: 1.0)\n        let sharpness = CHHapticEventParameter(parameterID: .hapticSharpness, value: 1.0)\n        let event = CHHapticEvent(eventType: .hapticTransient, parameters: [intensity, sharpness], relativeTime: 0)\n\n        do {\n            let pattern = try CHHapticPattern(events: [event], parameters: [])\n            let player = try engine.makePlayer(with: pattern)\n            try player.start(atTime: 0)\n        } catch {\n            print(\"Failed to play pattern: \\(error.localizedDescription)\")\n        }\n    }\n}"}
{"instruction": "iOS (Swift): Set up a Geofence monitor using `CLLocationManager` that prints to console when entering a region.", "output": "import CoreLocation\n\nclass GeofenceManager: NSObject, CLLocationManagerDelegate {\n    let locationManager = CLLocationManager()\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.requestAlwaysAuthorization()\n    }\n\n    func startMonitoring(lat: Double, lon: Double, identifier: String) {\n        let center = CLLocationCoordinate2D(latitude: lat, longitude: lon)\n        let region = CLCircularRegion(center: center, radius: 100.0, identifier: identifier)\n        region.notifyOnEntry = true\n        region.notifyOnExit = false\n        \n        locationManager.startMonitoring(for: region)\n    }\n\n    func locationManager(_ manager: CLLocationManager, didEnterRegion region: CLRegion) {\n        if let region = region as? CLCircularRegion {\n            print(\"Entered region: \\(region.identifier)\")\n        }\n    }\n    \n    func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {\n        print(\"Location error: \\(error)\")\n    }\n}"}
{"instruction": "SwiftUI: Read step count data using `CMPedometer` and display it in a View.", "output": "import SwiftUI\nimport CoreMotion\n\nclass PedometerViewModel: ObservableObject {\n    private let pedometer = CMPedometer()\n    @Published var steps: Int = 0\n    @Published var isAvailable: Bool = false\n\n    init() {\n        self.isAvailable = CMPedometer.isStepCountingAvailable()\n    }\n\n    func startUpdates() {\n        guard isAvailable else { return }\n        pedometer.startUpdates(from: Date()) { data, error in\n            guard let data = data, error == nil else { return }\n            DispatchQueue.main.async {\n                self.steps = data.numberOfSteps.intValue\n            }\n        }\n    }\n}\n\nstruct PedometerView: View {\n    @StateObject var viewModel = PedometerViewModel()\n\n    var body: some View {\n        VStack {\n            Text(\"Steps: \\(viewModel.steps)\")\n                .font(.largeTitle)\n            if !viewModel.isAvailable {\n                Text(\"Pedometer not available\")\n                    .foregroundColor(.red)\n            }\n        }\n        .onAppear { viewModel.startUpdates() }\n    }\n}"}
{"instruction": "Create a SwiftUI view that triggers a 'Heavy' impact haptic feedback when a button is pressed.", "output": "import SwiftUI\nimport UIKit\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            let generator = UIImpactFeedbackGenerator(style: .heavy)\n            generator.prepare()\n            generator.impactOccurred()\n        }) {\n            Text(\"Trigger Heavy Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(10)\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI ViewModel that uses CoreMotion to read the device's Pitch, Roll, and Yaw.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionViewModel: ObservableObject {\n    private var motionManager = CMMotionManager()\n    @Published var pitch: Double = 0.0\n    @Published var roll: Double = 0.0\n    @Published var yaw: Double = 0.0\n\n    func startMotionUpdates() {\n        if motionManager.isDeviceMotionAvailable {\n            motionManager.deviceMotionUpdateInterval = 0.1\n            motionManager.startDeviceMotionUpdates(to: .main) { [weak self] (data, error) in\n                guard let data = data, error == nil else { return }\n                self?.pitch = data.attitude.pitch\n                self?.roll = data.attitude.roll\n                self?.yaw = data.attitude.yaw\n            }\n        }\n    }\n\n    func stopMotionUpdates() {\n        motionManager.stopDeviceMotionUpdates()\n    }\n}"}
{"instruction": "Create a minimal Swift `UIViewControllerRepresentable` to display a native `UIImagePickerController` (Camera) in SwiftUI.", "output": "import SwiftUI\nimport UIKit\n\nstruct CameraView: UIViewControllerRepresentable {\n    @Binding var image: UIImage?\n    @Environment(\\.presentationMode) var presentationMode\n\n    func makeUIViewController(context: Context) -> UIImagePickerController {\n        let picker = UIImagePickerController()\n        picker.sourceType = .camera\n        picker.delegate = context.coordinator\n        return picker\n    }\n\n    func updateUIViewController(_ uiViewController: UIImagePickerController, context: Context) {}\n\n    func makeCoordinator() -> Coordinator {\n        Coordinator(self)\n    }\n\n    class Coordinator: NSObject, UINavigationControllerDelegate, UIImagePickerControllerDelegate {\n        let parent: CameraView\n\n        init(_ parent: CameraView) {\n            self.parent = parent\n        }\n\n        func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey : Any]) {\n            if let uiImage = info[.originalImage] as? UIImage {\n                parent.image = uiImage\n            }\n            parent.presentationMode.wrappedValue.dismiss()\n        }\n    }\n}"}
{"instruction": "Write a Swift snippet using `CMAltimeter` to check for relative altitude changes (Barometer).", "output": "import CoreMotion\n\nlet altimeter = CMAltimeter()\n\nfunc startAltimeter() {\n    if CMAltimeter.isRelativeAltitudeAvailable() {\n        altimeter.startRelativeAltitudeUpdates(to: OperationQueue.main) { (data, error) in\n            guard let data = data, error == nil else { return }\n            print(\"Relative Altitude: \\(data.relativeAltitude) meters\")\n            print(\"Pressure: \\(data.pressure) kPa\")\n        }\n    } else {\n        print(\"Barometer not available\")\n    }\n}"}
{"instruction": "Create a SwiftUI ViewModel that uses CoreMotion to read the device's Pitch, Roll, and Yaw in real-time.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private var motionManager: CMMotionManager\n    @Published var pitch: Double = 0.0\n    @Published var roll: Double = 0.0\n    @Published var yaw: Double = 0.0\n\n    init() {\n        self.motionManager = CMMotionManager()\n        self.motionManager.deviceMotionUpdateInterval = 1.0 / 60.0\n        self.startDeviceMotion()\n    }\n\n    func startDeviceMotion() {\n        if motionManager.isDeviceMotionAvailable {\n            motionManager.startDeviceMotionUpdates(to: .main) { (data, error) in\n                guard let data = data else { return }\n                self.pitch = data.attitude.pitch\n                self.roll = data.attitude.roll\n                self.yaw = data.attitude.yaw\n            }\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI `UIViewRepresentable` to display a live camera preview using AVFoundation.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreview: UIViewRepresentable {\n    func makeUIView(context: Context) -> UIView {\n        let view = UIView(frame: UIScreen.main.bounds)\n        let captureSession = AVCaptureSession()\n        captureSession.sessionPreset = .medium\n\n        guard let videoCaptureDevice = AVCaptureDevice.default(for: .video),\n              let videoInput = try? AVCaptureDeviceInput(device: videoCaptureDevice),\n              captureSession.canAddInput(videoInput) else { return view }\n\n        captureSession.addInput(videoInput)\n\n        let previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)\n        previewLayer.frame = view.frame\n        previewLayer.videoGravity = .resizeAspectFill\n        view.layer.addSublayer(previewLayer)\n\n        DispatchQueue.global(qos: .background).async {\n            captureSession.startRunning()\n        }\n\n        return view\n    }\n\n    func updateUIView(_ uiView: UIView, context: Context) {}\n}"}
{"instruction": "Create a simple SwiftUI view that triggers the device's haptic feedback engine (heavy impact) when a button is pressed.", "output": "import SwiftUI\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            let generator = UIImpactFeedbackGenerator(style: .heavy)\n            generator.prepare()\n            generator.impactOccurred()\n        }) {\n            Text(\"Trigger Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(10)\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI view that displays the user's current location on a Map using MapKit.", "output": "import SwiftUI\nimport MapKit\n\nstruct LocationMapView: View {\n    // State to hold region, centered on coordinates with a span\n    @State private var region = MKCoordinateRegion(\n        center: CLLocationCoordinate2D(latitude: 37.7749, longitude: -122.4194),\n        span: MKCoordinateSpan(latitudeDelta: 0.05, longitudeDelta: 0.05)\n    )\n\n    var body: some View {\n        Map(coordinateRegion: $region, \n            showsUserLocation: true, \n            userTrackingMode: .constant(.follow))\n            .edgesIgnoringSafeArea(.all)\n            .onAppear {\n                // Ensure CLLocationManager requests authorization elsewhere in the app\n            }\n    }\n}"}
{"instruction": "Create a SwiftUI ObservableObject that streams Accelerometer data using CoreMotion.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private let motionManager = CMMotionManager()\n    @Published var x = 0.0\n    @Published var y = 0.0\n    @Published var z = 0.0\n\n    func startUpdates() {\n        if motionManager.isAccelerometerAvailable {\n            motionManager.accelerometerUpdateInterval = 0.1\n            motionManager.startAccelerometerUpdates(to: .main) { [weak self] (data, error) in\n                guard let data = data else { return }\n                self?.x = data.acceleration.x\n                self?.y = data.acceleration.y\n                self?.z = data.acceleration.z\n            }\n        }\n    }\n\n    func stopUpdates() {\n        motionManager.stopAccelerometerUpdates()\n    }\n}"}
{"instruction": "Wrap a standard UIKit MKMapView into a SwiftUI view using UIViewRepresentable.", "output": "import SwiftUI\nimport MapKit\n\nstruct MapView: UIViewRepresentable {\n    func makeUIView(context: Context) -> MKMapView {\n        let mapView = MKMapView()\n        mapView.showsUserLocation = true\n        return mapView\n    }\n\n    func updateUIView(_ uiView: MKMapView, context: Context) {\n        // Update the view if needed\n    }\n}"}
{"instruction": "Create a function in SwiftUI to play a transient haptic pattern using CoreHaptics.", "output": "import CoreHaptics\n\nclass HapticManager {\n    private var engine: CHHapticEngine?\n\n    init() {\n        prepareHaptics()\n    }\n\n    func prepareHaptics() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        do {\n            engine = try CHHapticEngine()\n            try engine?.start()\n        } catch {\n            print(\"Haptic engine error: \\(error.localizedDescription)\")\n        }\n    }\n\n    func playComplexHaptic() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        \n        let intensity = CHHapticEventParameter(parameterID: .hapticIntensity, value: 1.0)\n        let sharpness = CHHapticEventParameter(parameterID: .hapticSharpness, value: 1.0)\n        let event = CHHapticEvent(eventType: .hapticTransient, parameters: [intensity, sharpness], relativeTime: 0)\n\n        do {\n            let pattern = try CHHapticPattern(events: [event], parameters: [])\n            let player = try engine?.makePlayer(with: pattern)\n            try player?.start(atTime: 0)\n        } catch {\n            print(\"Failed to play pattern: \\(error.localizedDescription)\")\n        }\n    }\n}"}
{"instruction": "Create a Swift class to handle 'When In Use' location authorization and updates using CoreLocation.", "output": "import CoreLocation\n\nclass LocationService: NSObject, ObservableObject, CLLocationManagerDelegate {\n    private let locationManager = CLLocationManager()\n    @Published var location: CLLocation?\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.desiredAccuracy = kCLLocationAccuracyBest\n    }\n\n    func requestPermission() {\n        locationManager.requestWhenInUseAuthorization()\n    }\n\n    func startLocationUpdates() {\n        locationManager.startUpdatingLocation()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n        guard let latestLocation = locations.last else { return }\n        self.location = latestLocation\n    }\n\n    func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {\n        print(\"Location error: \\(error.localizedDescription)\")\n    }\n}"}
{"instruction": "Implement a Swift function to authenticate a user using FaceID or TouchID via LocalAuthentication.", "output": "import LocalAuthentication\n\nfunc authenticateUser(completion: @escaping (Bool, Error?) -> Void) {\n    let context = LAContext()\n    var error: NSError?\n\n    if context.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &error) {\n        let reason = \"Authenticate to access secure features\"\n\n        context.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: reason) { success, authenticationError in\n            DispatchQueue.main.async {\n                completion(success, authenticationError)\n            }\n        }\n    } else {\n        // Biometrics not available\n        completion(false, error)\n    }\n}"}
{"instruction": "Create a SwiftUI struct that wraps a native UIKit camera preview layer using `UIViewRepresentable`. This enables the display of a live camera feed within a SwiftUI view hierarchy.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreview: UIViewRepresentable {\n    class VideoPreviewView: UIView {\n        override class var layerClass: AnyClass {\n            AVCaptureVideoPreviewLayer.self\n        }\n        \n        var videoPreviewLayer: AVCaptureVideoPreviewLayer {\n            return layer as! AVCaptureVideoPreviewLayer\n        }\n    }\n\n    let session: AVCaptureSession\n\n    func makeUIView(context: Context) -> VideoPreviewView {\n        let view = VideoPreviewView()\n        view.backgroundColor = .black\n        view.videoPreviewLayer.session = session\n        view.videoPreviewLayer.videoGravity = .resizeAspectFill\n        view.videoPreviewLayer.connection?.videoOrientation = .portrait\n        return view\n    }\n\n    func updateUIView(_ uiView: VideoPreviewView, context: Context) {\n        // View updates handled by the session\n    }\n}"}
{"instruction": "Create a Swift class utilizing `CoreLocation` to request 'When In Use' authorization and start updating the user's location. Include the delegate method to handle location updates.", "output": "import CoreLocation\n\nclass LocationService: NSObject, CLLocationManagerDelegate {\n    private let locationManager = CLLocationManager()\n    var didUpdateLocation: ((CLLocation) -> Void)?\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.desiredAccuracy = kCLLocationAccuracyBest\n    }\n\n    func requestPermission() {\n        locationManager.requestWhenInUseAuthorization()\n    }\n\n    func start() {\n        locationManager.startUpdatingLocation()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n        guard let location = locations.last else { return }\n        didUpdateLocation?(location)\n    }\n\n    func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {\n        print(\"Location error: \\(error)\")\n    }\n}"}
{"instruction": "Implement a SwiftUI function to trigger native Haptic Feedback using `UIImpactFeedbackGenerator`. This allows the app to provide physical feedback to the user.", "output": "import UIKit\n\nfunc triggerHapticFeedback(style: UIImpactFeedbackGenerator.FeedbackStyle) {\n    let generator = UIImpactFeedbackGenerator(style: style)\n    generator.prepare()\n    generator.impactOccurred()\n}\n\n// Usage example inside a SwiftUI Button:\n// Button(action: {\n//     triggerHapticFeedback(style: .medium)\n// }) {\n//     Text(\"Tap Me\")\n// }"}
{"instruction": "Write a Swift function using `LocalAuthentication` to implement Biometric Authentication (FaceID/TouchID). It should handle the success and failure cases via a completion handler.", "output": "import LocalAuthentication\n\nfunc authenticateUser(completion: @escaping (Bool, String?) -> Void) {\n    let context = LAContext()\n    var error: NSError?\n\n    if context.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &error) {\n        let reason = \"Authenticate to access secure features\"\n\n        context.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: reason) { success, authenticationError in\n            DispatchQueue.main.async {\n                if success {\n                    completion(true, nil)\n                } else {\n                    completion(false, authenticationError?.localizedDescription)\n                }\n            }\n        }\n    } else {\n        completion(false, \"Biometry not available\")\n    }\n}"}
{"instruction": "Create a SwiftUI ObservableObject that monitors the device's accelerometer using CoreMotion to detect X, Y, and Z axis changes.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private let motionManager = CMMotionManager()\n    @Published var x = 0.0\n    @Published var y = 0.0\n    @Published var z = 0.0\n\n    init() {\n        startAccelerometers()\n    }\n\n    func startAccelerometers() {\n        if motionManager.isAccelerometerAvailable {\n            motionManager.accelerometerUpdateInterval = 0.1\n            motionManager.startAccelerometerUpdates(to: .main) { [weak self] data, error in\n                guard let data = data, error == nil else { return }\n                self?.x = data.acceleration.x\n                self?.y = data.acceleration.y\n                self?.z = data.acceleration.z\n            }\n        }\n    }\n    \n    func stopUpdates() {\n        motionManager.stopAccelerometerUpdates()\n    }\n}"}
{"instruction": "Create a SwiftUI View that triggers a complex haptic feedback pattern using CoreHaptics when a button is pressed.", "output": "import SwiftUI\nimport CoreHaptics\n\nstruct HapticView: View {\n    @State private var engine: CHHapticEngine?\n\n    var body: some View {\n        Button(\"Feel Texture\") {\n            playHaptics()\n        }\n        .onAppear(perform: prepareHaptics)\n    }\n\n    func prepareHaptics() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        do {\n            engine = try CHHapticEngine()\n            try engine?.start()\n        } catch {\n            print(\"Haptic engine error: \\(error.localizedDescription)\")\n        }\n    }\n\n    func playHaptics() {\n        guard CHHapticEngine.capabilitiesForHardware().supportsHaptics else { return }\n        \n        var events = [CHHapticEvent]()\n        // Create a sharp tap\n        let intensity = CHHapticEventParameter(parameterID: .hapticIntensity, value: 1.0)\n        let sharpness = CHHapticEventParameter(parameterID: .hapticSharpness, value: 1.0)\n        let event = CHHapticEvent(eventType: .hapticTransient, parameters: [intensity, sharpness], relativeTime: 0)\n        events.append(event)\n\n        do {\n            let pattern = try CHHapticPattern(events: events, parameters: [])\n            let player = try engine?.makePlayer(with: pattern)\n            try player?.start(atTime: 0)\n        } catch {\n            print(\"Failed to play pattern: \\(error.localizedDescription)\")\n        }\n    }\n}"}
{"instruction": "Using Swift and AVFoundation, create a function that toggles the device flashlight (torch) on and off.", "output": "import AVFoundation\n\nfunc toggleFlashlight(on: Bool) {\n    guard let device = AVCaptureDevice.default(for: .video) else { return }\n\n    if device.hasTorch {\n        do {\n            try device.lockForConfiguration()\n            if on {\n                try device.setTorchModeOn(level: 1.0)\n            } else {\n                device.torchMode = .off\n            }\n            device.unlockForConfiguration()\n        } catch {\n            print(\"Torch could not be used\")\n        }\n    }\n}"}
{"instruction": "Create a SwiftUI View that wraps a map view to show the user's current location using MapKit.", "output": "import SwiftUI\nimport MapKit\n\nstruct LocationMapView: View {\n    @StateObject private var viewModel = MapViewModel()\n\n    var body: some View {\n        Map(coordinateRegion: $viewModel.region, showsUserLocation: true)\n            .onAppear {\n                viewModel.checkLocationAuthorization()\n            }\n    }\n}\n\nclass MapViewModel: NSObject, ObservableObject, CLLocationManagerDelegate {\n    @Published var region = MKCoordinateRegion(\n        center: CLLocationCoordinate2D(latitude: 37.7749, longitude: -122.4194),\n        span: MKCoordinateSpan(latitudeDelta: 0.05, longitudeDelta: 0.05)\n    )\n    var locationManager: CLLocationManager?\n\n    func checkLocationAuthorization() {\n        locationManager = CLLocationManager()\n        locationManager?.delegate = self\n        locationManager?.requestWhenInUseAuthorization()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n        guard let location = locations.last else { return }\n        DispatchQueue.main.async {\n            self.region = MKCoordinateRegion(\n                center: location.coordinate,\n                span: MKCoordinateSpan(latitudeDelta: 0.05, longitudeDelta: 0.05)\n            )\n        }\n    }\n}"}
{"instruction": "Create a custom circular progress view in SwiftUI that animates based on a binding double value between 0.0 and 1.0.", "output": "import SwiftUI\n\nstruct CircularProgressView: View {\n    @Binding var progress: Double\n\n    var body: some View {\n        ZStack {\n            Circle()\n                .stroke(lineWidth: 20.0)\n                .opacity(0.3)\n                .foregroundColor(Color.gray)\n\n            Circle()\n                .trim(from: 0.0, to: CGFloat(min(self.progress, 1.0)))\n                .stroke(style: StrokeStyle(lineWidth: 20.0, lineCap: .round, lineJoin: .round))\n                .foregroundColor(Color.blue)\n                .rotationEffect(Angle(degrees: 270.0))\n                .animation(.linear, value: progress)\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI View that triggers haptic feedback (medium impact) when a button is pressed.", "output": "import SwiftUI\n\nstruct HapticButtonView: View {\n    var body: some View {\n        Button(action: {\n            let impactMed = UIImpactFeedbackGenerator(style: .medium)\n            impactMed.impactOccurred()\n        }) {\n            Text(\"Press for Haptics\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(8)\n        }\n    }\n}"}
{"instruction": "Create a Swift ObservableObject that uses CoreLocation to request permission and publish the user's current location coordinates.", "output": "import Foundation\nimport CoreLocation\nimport Combine\n\nclass LocationManager: NSObject, ObservableObject, CLLocationManagerDelegate {\n    private let locationManager = CLLocationManager()\n    @Published var location: CLLocation?\n\n    override init() {\n        super.init()\n        locationManager.delegate = self\n        locationManager.desiredAccuracy = kCLLocationAccuracyBest\n        locationManager.requestWhenInUseAuthorization()\n        locationManager.startUpdatingLocation()\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n        guard let location = locations.last else { return }\n        self.location = location\n    }\n\n    func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {\n        print(\"Location error: \\(error.localizedDescription)\")\n    }\n}"}
{"instruction": "Wrap a UIKit MKMapView in a SwiftUI UIViewRepresentable to display a map.", "output": "import SwiftUI\nimport MapKit\n\nstruct MapView: UIViewRepresentable {\n    func makeUIView(context: Context) -> MKMapView {\n        let mapView = MKMapView()\n        mapView.showsUserLocation = true\n        return mapView\n    }\n\n    func updateUIView(_ uiView: MKMapView, context: Context) {\n        // Update map view configuration here if needed\n    }\n}"}
{"instruction": "Create a SwiftUI button that triggers a heavy impact haptic feedback when tapped using UIKit integration.", "output": "import SwiftUI\nimport UIKit\n\nstruct HapticButton: View {\n    var body: some View {\n        Button(action: {\n            let generator = UIImpactFeedbackGenerator(style: .heavy)\n            generator.prepare()\n            generator.impactOccurred()\n        }) {\n            Text(\"Trigger Haptic\")\n                .padding()\n                .background(Color.blue)\n                .foregroundColor(.white)\n                .cornerRadius(8)\n        }\n    }\n}"}
{"instruction": "Implement a SwiftUI `UIViewControllerRepresentable` to display a basic camera preview using `AVCaptureSession`.", "output": "import SwiftUI\nimport AVFoundation\n\nstruct CameraPreview: UIViewControllerRepresentable {\n    func makeUIViewController(context: Context) -> UIViewController {\n        let controller = UIViewController()\n        let session = AVCaptureSession()\n        \n        guard let device = AVCaptureDevice.default(for: .video),\n              let input = try? AVCaptureDeviceInput(device: device) else { return controller }\n        \n        if session.canAddInput(input) {\n            session.addInput(input)\n        }\n        \n        let previewLayer = AVCaptureVideoPreviewLayer(session: session)\n        previewLayer.videoGravity = .resizeAspectFill\n        previewLayer.frame = controller.view.bounds\n        controller.view.layer.addSublayer(previewLayer)\n        \n        DispatchQueue.global(qos: .background).async {\n            session.startRunning()\n        }\n        \n        return controller\n    }\n\n    func updateUIViewController(_ uiViewController: UIViewController, context: Context) {}\n}"}
{"instruction": "Create a SwiftUI view that uses `CMMotionManager` to display the device's pitch and roll in real-time.", "output": "import SwiftUI\nimport CoreMotion\n\nclass MotionManager: ObservableObject {\n    private var motionManager = CMMotionManager()\n    @Published var pitch: Double = 0.0\n    @Published var roll: Double = 0.0\n\n    init() {\n        motionManager.deviceMotionUpdateInterval = 0.1\n        motionManager.startDeviceMotionUpdates(to: .main) { [weak self] (data, error) in\n            guard let data = data else { return }\n            self?.pitch = data.attitude.pitch\n            self?.roll = data.attitude.roll\n        }\n    }\n}\n\nstruct MotionView: View {\n    @StateObject var motion = MotionManager()\n\n    var body: some View {\n        VStack {\n            Text(\"Pitch: \\(motion.pitch, specifier: \"%.2f\")\")\n            Text(\"Roll: \\(motion.roll, specifier: \"%.2f\")\")\n        }\n    }\n}"}
{"instruction": "Create a function in Swift to authenticate a user using FaceID or TouchID via the `LocalAuthentication` framework.", "output": "import LocalAuthentication\n\nfunc authenticateUser(completion: @escaping (Bool, Error?) -> Void) {\n    let context = LAContext()\n    var error: NSError?\n\n    if context.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &error) {\n        let reason = \"Authenticate to access secure data\"\n\n        context.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: reason) { success, authenticationError in\n            DispatchQueue.main.async {\n                completion(success, authenticationError)\n            }\n        }\n    } else {\n        completion(false, error)\n    }\n}"}
