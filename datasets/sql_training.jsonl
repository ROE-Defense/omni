{"instruction": "Write a recursive CTE to traverse an employee hierarchy. Retrieve the ID, name, and depth level of all employees reporting directly or indirectly to a manager with ID 1.", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n    -- Anchor member: Select the top-level manager\n    SELECT \n        employee_id, \n        first_name, \n        manager_id, \n        1 AS depth_level\n    FROM employees\n    WHERE manager_id = 1\n\n    UNION ALL\n\n    -- Recursive member: Join subordinates to their managers\n    SELECT \n        e.employee_id, \n        e.first_name, \n        e.manager_id, \n        eh.depth_level + 1\n    FROM employees e\n    INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM EmployeeHierarchy;"}
{"instruction": "Calculate the 7-day moving average of sales amount for each product, ordered by date. Use a Window Function.", "output": "SELECT \n    product_id,\n    sale_date,\n    sales_amount,\n    AVG(sales_amount) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_days\nFROM daily_sales\nORDER BY product_id, sale_date;"}
{"instruction": "Identify the top 3 highest-paid employees within each department using a ranking window function. Handle ties by assigning the same rank, but skipping subsequent ranks (e.g., 1, 1, 3).", "output": "WITH RankedSalaries AS (\n    SELECT \n        employee_id,\n        department_id,\n        salary,\n        RANK() OVER (\n            PARTITION BY department_id \n            ORDER BY salary DESC\n        ) AS salary_rank\n    FROM employees\n)\nSELECT \n    employee_id,\n    department_id,\n    salary\nFROM RankedSalaries\nWHERE salary_rank <= 3;"}
{"instruction": "DBA Task: Write a query to identify unused indexes in a PostgreSQL database (indexes that have not been scanned), excluding internal system schemas.", "output": "SELECT \n    schemaname, \n    relname AS table_name, \n    indexrelname AS index_name, \n    idx_scan AS number_of_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0 \n  AND indexrelid NOT IN (SELECT indrelid FROM pg_index WHERE indisunique)\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Perform a 'Gap Analysis' to find days where no orders were placed within a specific month (e.g., January 2023). Use `generate_series` to create the full calendar range.", "output": "SELECT \n    calendar_date::DATE AS missing_date\nFROM generate_series(\n    '2023-01-01'::DATE, \n    '2023-01-31'::DATE, \n    '1 day'::INTERVAL\n) AS calendar_date\nLEFT JOIN orders o ON o.order_date = calendar_date::DATE\nWHERE o.order_id IS NULL;"}
{"instruction": "Write a query to pivot monthly sales data so that months become columns (Jan, Feb, Mar) for the current year. Use filtered aggregation.", "output": "SELECT \n    product_category,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS sales_jan,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS sales_feb,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS sales_mar\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_category;"}
{"instruction": "DBA Task: Find currently running queries that have been active for more than 5 minutes, showing the user, the database, and the query text.", "output": "SELECT \n    pid,\n    usename AS username,\n    datname AS database_name,\n    state,\n    age(clock_timestamp(), query_start) AS duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle' \n  AND query NOT ILIKE '%pg_stat_activity%'\n  AND age(clock_timestamp(), query_start) > INTERVAL '5 minutes';"}
{"instruction": "Compare inventory levels between two tables (`warehouse_a` and `warehouse_b`) using a FULL OUTER JOIN. Return the SKU, stock in A, stock in B, and the difference, treating nulls as zero.", "output": "SELECT \n    COALESCE(a.sku, b.sku) AS sku,\n    COALESCE(a.quantity, 0) AS stock_a,\n    COALESCE(b.quantity, 0) AS stock_b,\n    COALESCE(a.quantity, 0) - COALESCE(b.quantity, 0) AS difference\nFROM warehouse_a a\nFULL OUTER JOIN warehouse_b b ON a.sku = b.sku\nWHERE COALESCE(a.quantity, 0) != COALESCE(b.quantity, 0);"}
{"instruction": "Calculate the time difference between consecutive user logins using the `LAG` window function.", "output": "SELECT \n    user_id,\n    login_timestamp,\n    LAG(login_timestamp) OVER (\n        PARTITION BY user_id \n        ORDER BY login_timestamp\n    ) AS previous_login,\n    login_timestamp - LAG(login_timestamp) OVER (\n        PARTITION BY user_id \n        ORDER BY login_timestamp\n    ) AS time_since_last_login\nFROM user_logins;"}
{"instruction": "DBA Task: Write a query to list all tables in the current database along with their total size (including indexes), formatted in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Calculate the total salary budget for a specific manager (ID 101), including the salaries of the manager and all their direct and indirect subordinates using a recursive CTE.", "output": "WITH RECURSIVE Hierarchy AS (\n    SELECT employee_id, salary\n    FROM employees\n    WHERE employee_id = 101\n    UNION ALL\n    SELECT e.employee_id, e.salary\n    FROM employees e\n    INNER JOIN Hierarchy h ON e.manager_id = h.employee_id\n)\nSELECT SUM(salary) AS total_budget FROM Hierarchy;"}
{"instruction": "Identify user sessions based on activity logs. A new session starts if a user is inactive for more than 30 minutes. Assign a unique session ID to each group of events per user.", "output": "WITH LaggedEvents AS (\n    SELECT \n        user_id, \n        event_time, \n        LAG(event_time) OVER (PARTITION BY user_id ORDER BY event_time) AS prev_event_time\n    FROM user_events\n),\nSessionFlags AS (\n    SELECT \n        user_id, \n        event_time,\n        CASE \n            WHEN EXTRACT(EPOCH FROM (event_time - prev_event_time)) > 1800 OR prev_event_time IS NULL THEN 1 \n            ELSE 0 \n        END AS is_new_session\n    FROM LaggedEvents\n)\nSELECT \n    user_id, \n    event_time, \n    SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY event_time) AS session_id\nFROM SessionFlags;"}
{"instruction": "Find the top 3 highest-grossing products in each category, handling ties by including all products with the same sales rank.", "output": "WITH RankedProducts AS (\n    SELECT \n        category_id, \n        product_name, \n        total_sales,\n        DENSE_RANK() OVER (PARTITION BY category_id ORDER BY total_sales DESC) as rank\n    FROM product_sales\n)\nSELECT * FROM RankedProducts WHERE rank <= 3;"}
{"instruction": "Perform a gap analysis to find all dates in the current year where no orders were placed.", "output": "SELECT calendar_date::DATE\nFROM generate_series(\n    DATE_TRUNC('year', CURRENT_DATE),\n    DATE_TRUNC('year', CURRENT_DATE) + INTERVAL '1 year' - INTERVAL '1 day',\n    INTERVAL '1 day'\n) AS calendar_date\nLEFT JOIN orders o ON calendar_date = DATE(o.order_date)\nWHERE o.order_id IS NULL;"}
{"instruction": "Retrieve the 5 most recent comments for every blog post using a LATERAL join for performance optimization (PostgreSQL specific).", "output": "SELECT p.post_title, c.comment_text, c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE post_id = p.id\n    ORDER BY created_at DESC\n    LIMIT 5\n) c;"}
{"instruction": "Pivot a sales table to show total revenue per year (rows) and quarter (columns Q1-Q4) without using the crosstab extension.", "output": "SELECT \n    EXTRACT(YEAR FROM sale_date) AS sales_year,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM sale_date) = 1 THEN amount ELSE 0 END) AS Q1,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM sale_date) = 2 THEN amount ELSE 0 END) AS Q2,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM sale_date) = 3 THEN amount ELSE 0 END) AS Q3,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM sale_date) = 4 THEN amount ELSE 0 END) AS Q4\nFROM sales\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Database Administration: List the top 10 largest tables in the database, displaying their size in a human-readable format.", "output": "SELECT \n    relname AS table_name, \n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Calculate the month-over-month retention rate. Count users who signed up in a specific month (Cohort) and returned to make a purchase in the subsequent month.", "output": "WITH MonthlyCohorts AS (\n    SELECT DATE_TRUNC('month', signup_date) AS cohort_month, user_id\n    FROM users\n),\nUserActivity AS (\n    SELECT DISTINCT user_id, DATE_TRUNC('month', purchase_date) AS activity_month\n    FROM purchases\n)\nSELECT \n    c.cohort_month,\n    COUNT(DISTINCT c.user_id) AS total_signups,\n    COUNT(DISTINCT a.user_id) AS retained_users,\n    ROUND(COUNT(DISTINCT a.user_id)::NUMERIC / COUNT(DISTINCT c.user_id), 2) AS retention_rate\nFROM MonthlyCohorts c\nLEFT JOIN UserActivity a \n    ON c.user_id = a.user_id \n    AND a.activity_month = c.cohort_month + INTERVAL '1 month'\nGROUP BY c.cohort_month\nORDER BY c.cohort_month;"}
{"instruction": "Database Administration: Identify queries that are currently blocked and waiting for locks, showing both the blocked and blocking query details.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocked_activity.query    AS blocked_query,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query   AS blocking_query\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate a 7-day moving average of daily sales revenue for each store.", "output": "SELECT \n    store_id, \n    sale_date, \n    revenue,\n    AVG(revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7d\nFROM daily_sales;"}
{"instruction": "Write a recursive CTE to generate a hierarchical organizational chart showing employee names and their depth level in the hierarchy, starting from the CEO (where manager_id is NULL).", "output": "WITH RECURSIVE OrgChart AS (\n  SELECT employee_id, name, manager_id, 1 AS level\n  FROM employees\n  WHERE manager_id IS NULL\n  UNION ALL\n  SELECT e.employee_id, e.name, e.manager_id, o.level + 1\n  FROM employees e\n  INNER JOIN OrgChart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM OrgChart ORDER BY level, manager_id;"}
{"instruction": "Create a query to calculate the 7-day moving average of daily sales revenue using window functions.", "output": "SELECT sale_date,\n       SUM(revenue) AS daily_revenue,\n       AVG(SUM(revenue)) OVER (\n           ORDER BY sale_date \n           ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n       ) AS moving_average_7d\nFROM sales\nGROUP BY sale_date\nORDER BY sale_date;"}
{"instruction": "Identify 'islands' in a dataset of sequential IDs. Find the start and end of every consecutive sequence of numbers in the table 'tickets'.", "output": "WITH Cte AS (\n    SELECT id, id - ROW_NUMBER() OVER (ORDER BY id) AS grp\n    FROM tickets\n)\nSELECT MIN(id) AS sequence_start, MAX(id) AS sequence_end\nFROM Cte\nGROUP BY grp\nORDER BY sequence_start;"}
{"instruction": "Write a PostgreSQL administration query to find the size of all tables in the current database, including indexes and toast data, sorted by size descending.", "output": "SELECT \n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Use a LATERAL JOIN to find the top 3 most recent comments for each blog post without aggregating the entire comments table first.", "output": "SELECT p.title, c.comment_text, c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE post_id = p.id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c;"}
{"instruction": "Perform a pivot operation using the FILTER clause to count the number of 'Pending', 'Shipped', and 'Delivered' orders per customer.", "output": "SELECT customer_id,\n       COUNT(*) FILTER (WHERE status = 'Pending') AS pending_count,\n       COUNT(*) FILTER (WHERE status = 'Shipped') AS shipped_count,\n       COUNT(*) FILTER (WHERE status = 'Delivered') AS delivered_count\nFROM orders\nGROUP BY customer_id;"}
{"instruction": "Find the top 3 employees by salary within each department using the DENSE_RANK window function.", "output": "WITH RankedEmployees AS (\n    SELECT name, department_id, salary,\n           DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT * FROM RankedEmployees WHERE rank <= 3;"}
{"instruction": "Write a query to identify Day 1 Retention: Calculate the percentage of users who logged in exactly one day after their signup date.", "output": "SELECT \n    s.signup_date,\n    COUNT(DISTINCT s.user_id) AS new_users,\n    COUNT(DISTINCT l.user_id) AS retained_users,\n    (COUNT(DISTINCT l.user_id)::FLOAT / NULLIF(COUNT(DISTINCT s.user_id), 0)) * 100 AS retention_rate\nFROM users s\nLEFT JOIN logins l \n    ON s.user_id = l.user_id \n    AND l.login_timestamp >= s.signup_date + INTERVAL '1 day'\n    AND l.login_timestamp < s.signup_date + INTERVAL '2 days'\nGROUP BY s.signup_date;"}
{"instruction": "Write a PostgreSQL query to detect currently blocked processes and identify the blocking queries.", "output": "SELECT \n    activity.pid,\n    activity.usename,\n    activity.query AS blocked_query,\n    blocking.pid AS blocking_pid,\n    blocking.query AS blocking_query\nFROM pg_stat_activity AS activity\nJOIN pg_stat_activity AS blocking \n    ON blocking.pid = ANY(pg_blocking_pids(activity.pid));"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation: Insert a new product into inventory, but if the product_id already exists, add the new quantity to the existing quantity.", "output": "INSERT INTO inventory (product_id, quantity, last_updated)\nVALUES (105, 50, NOW())\nON CONFLICT (product_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Write a recursive Common Table Expression (CTE) in PostgreSQL to generate a hierarchical view of an organization. Given an 'employees' table with 'id', 'name', and 'manager_id', return the hierarchy path (e.g., 'CEO > VP > Manager > Employee') and the depth level for every employee.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Select top-level managers (those with no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        name AS path, \n        1 AS level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the anchor with employees\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        eh.path || ' > ' || e.name,\n        eh.level + 1\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.id\n)\nSELECT * FROM employee_hierarchy ORDER BY path;"}
{"instruction": "Using window functions, calculate the 7-day moving average of daily sales. The output should include the date, daily total, and the moving average, ordered by date.", "output": "SELECT \n    sale_date,\n    SUM(amount) AS daily_total,\n    AVG(SUM(amount)) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM sales\nGROUP BY sale_date\nORDER BY sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login activity. Write a query to find the start date, end date, and number of consecutive days a user logged in without missing a day.", "output": "WITH grouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS consecutive_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a PostgreSQL DBA query to identify unused indexes. The query should return the schema, table name, index name, and size of indexes that have never been scanned.", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as scan_count\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\nAND indexrelname NOT LIKE '%pkey' -- Exclude primary keys\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Perform a 'Cohort Analysis' to calculate user retention. Group users by their signup month (cohort) and calculate the percentage of users who were active in subsequent months.", "output": "WITH cohorts AS (\n    SELECT user_id, DATE_TRUNC('month', signup_date) AS cohort_month\n    FROM users\n),\nactivity AS (\n    SELECT user_id, DATE_TRUNC('month', activity_date) AS activity_month\n    FROM user_logs\n    GROUP BY 1, 2\n)\nSELECT \n    c.cohort_month,\n    a.activity_month,\n    EXTRACT(EPOCH FROM (a.activity_month - c.cohort_month))/2592000 AS month_number,\n    COUNT(DISTINCT c.user_id) AS active_users,\n    ROUND(COUNT(DISTINCT c.user_id)::NUMERIC / MAX(total_cohort.size), 2) AS retention_rate\nFROM cohorts c\nJOIN activity a ON c.user_id = a.user_id\nJOIN (SELECT cohort_month, COUNT(*) as size FROM cohorts GROUP BY 1) total_cohort \n  ON c.cohort_month = total_cohort.cohort_month\nGROUP BY 1, 2\nORDER BY 1, 2;"}
{"instruction": "Use a LATERAL JOIN to find the top 3 highest-paid employees in every department without using a window function in the WHERE clause.", "output": "SELECT \n    d.department_name,\n    e.employee_name,\n    e.salary\nFROM departments d\nCROSS JOIN LATERAL (\n    SELECT employee_name, salary\n    FROM employees\n    WHERE department_id = d.id\n    ORDER BY salary DESC\n    LIMIT 3\n) e\nORDER BY d.department_name, e.salary DESC;"}
{"instruction": "Write a complex query using a FULL OUTER JOIN to reconcile inventory records between two different systems (Table A and Table B). Return items missing from either system or items where the stock quantity differs.", "output": "SELECT \n    COALESCE(a.sku, b.sku) AS sku,\n    a.quantity AS qty_system_a,\n    b.quantity AS qty_system_b,\n    CASE \n        WHEN a.sku IS NULL THEN 'Missing in A'\n        WHEN b.sku IS NULL THEN 'Missing in B'\n        ELSE 'Quantity Mismatch'\n    END AS discrepancy_type\nFROM inventory_system_a a\nFULL OUTER JOIN inventory_system_b b ON a.sku = b.sku\nWHERE a.sku IS NULL \n   OR b.sku IS NULL \n   OR a.quantity <> b.quantity;"}
{"instruction": "Write a PostgreSQL query to parse a JSONB column named 'attributes' in a 'products' table. The goal is to aggregate the total sales quantity for each 'color' attribute found inside the JSON objects.", "output": "SELECT \n    attributes ->> 'color' AS product_color,\n    SUM(oi.quantity) AS total_sold\nFROM products p\nJOIN order_items oi ON p.id = oi.product_id\nWHERE attributes ? 'color'\nGROUP BY attributes ->> 'color'\nORDER BY total_sold DESC;"}
{"instruction": "Write a DBA query to detect currently blocking queries in PostgreSQL. The output should show the blocked PID, the blocking PID, and the actual query text causing the block.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query AS blocked_query,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate the Year-Over-Year (YoY) growth percentage for monthly revenue using the LAG window function. The result should show the current month, current revenue, previous year's revenue for the same month, and the growth percentage.", "output": "WITH monthly_revenue AS (\n    SELECT \n        DATE_TRUNC('month', payment_date) AS rev_month,\n        SUM(amount) AS revenue\n    FROM payments\n    GROUP BY 1\n)\nSELECT \n    rev_month,\n    revenue AS current_revenue,\n    LAG(revenue, 12) OVER (ORDER BY rev_month) AS prev_year_revenue,\n    ROUND(\n        ((revenue - LAG(revenue, 12) OVER (ORDER BY rev_month)) \n        / LAG(revenue, 12) OVER (ORDER BY rev_month)) * 100, \n    2) AS yoy_growth_pct\nFROM monthly_revenue\nORDER BY rev_month;"}
{"instruction": "Write a recursive Common Table Expression (CTE) query to retrieve an entire organizational hierarchy (all subordinates at all levels) for a manager with employee_id = 1. The table 'employees' contains 'id', 'name', and 'manager_id'.", "output": "WITH RECURSIVE org_chart AS (\n    SELECT id, name, manager_id, 1 AS level\n    FROM employees\n    WHERE id = 1\n    UNION ALL\n    SELECT e.id, e.name, e.manager_id, oc.level + 1\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.id\n)\nSELECT * FROM org_chart ORDER BY level, id;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product using window functions. The table 'daily_sales' has columns 'product_id', 'sale_date', and 'amount'.", "output": "SELECT \n    product_id,\n    sale_date,\n    amount,\n    AVG(amount) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nORDER BY product_id, sale_date;"}
{"instruction": "Identify 'islands' of consecutive login days for users. Write a query to find the start date, end date, and number of consecutive days a user logged in. Table 'user_logins' contains 'user_id' and 'login_date'.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS start_date,\n    MAX(login_date) AS end_date,\n    COUNT(*) AS consecutive_days\nFROM grouped_dates\nGROUP BY user_id, grp\nHAVING COUNT(*) > 1\nORDER BY user_id, start_date;"}
{"instruction": "Find the top 3 highest-paid employees in each department. If there is a tie in salary, they should share the rank, and the next rank should be skipped (use RANK). Table 'employees' has 'dept_id', 'name', and 'salary'.", "output": "WITH ranked_employees AS (\n    SELECT \n        dept_id,\n        name,\n        salary,\n        RANK() OVER (PARTITION BY dept_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT * \nFROM ranked_employees \nWHERE rank_num <= 3;"}
{"instruction": "Database Administration (PostgreSQL): Write a query to list the top 10 largest tables in the current database, showing the schema, table name, and pretty-printed total size (including indexes).", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot monthly sales data from rows to columns (Cross-tabulation) for the year 2023 without using a specific PIVOT function (ANSI SQL approach). Show total sales for Jan, Feb, and Mar per product. Table 'sales' has 'product_id', 'sale_date', and 'amount'.", "output": "SELECT \n    product_id,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 1 THEN amount ELSE 0 END) AS jan_sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 2 THEN amount ELSE 0 END) AS feb_sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 3 THEN amount ELSE 0 END) AS mar_sales\nFROM sales\nWHERE sale_date >= '2023-01-01' AND sale_date <= '2023-03-31'\nGROUP BY product_id;"}
{"instruction": "Database Administration (PostgreSQL): Identify currently active queries that have been running for more than 5 minutes, excluding the query checking for them.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    age(clock_timestamp(), query_start) as duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND age(clock_timestamp(), query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Perform a 'Gap Analysis' to find missing order IDs in a sequence. Assuming 'orders' table has a sequential integer primary key 'order_id', find the start and end of any gap in the sequence.", "output": "WITH gaps AS (\n    SELECT \n        order_id + 1 AS gap_start,\n        LEAD(order_id) OVER (ORDER BY order_id) - 1 AS gap_end\n    FROM orders\n)\nSELECT gap_start, gap_end\nFROM gaps\nWHERE gap_end >= gap_start;"}
{"instruction": "Compare two tables, 'source_data' and 'target_data' (both having columns 'id' and 'val'), to find discrepancies. Return rows that exist in one but not the other, or where the values differ.", "output": "SELECT \n    COALESCE(s.id, t.id) AS id,\n    s.val AS source_val,\n    t.val AS target_val,\n    CASE \n        WHEN s.id IS NULL THEN 'Missing in Source'\n        WHEN t.id IS NULL THEN 'Missing in Target'\n        ELSE 'Value Mismatch'\n    END AS issue_type\nFROM source_data s\nFULL OUTER JOIN target_data t ON s.id = t.id\nWHERE s.id IS NULL \n   OR t.id IS NULL \n   OR s.val <> t.val;"}
{"instruction": "PostgreSQL JSONB: Given a table 'events' with a JSONB column 'payload' containing an array of items under the key 'items' (e.g., {'items': [{'id': 1, 'qty': 2}, {'id': 2, 'qty': 1}]}), calculate the total quantity sold per item ID across all events.", "output": "SELECT \n    item ->> 'id' AS item_id,\n    SUM((item ->> 'qty')::int) AS total_qty\nFROM events,\n     jsonb_array_elements(payload -> 'items') AS item\nGROUP BY item ->> 'id';"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to calculate the 7-day moving average of sales revenue for each product category, ordered by date.", "output": "WITH daily_sales AS (\n    SELECT\n        category_id,\n        sale_date,\n        SUM(revenue) as total_daily_revenue\n    FROM sales\n    GROUP BY category_id, sale_date\n)\nSELECT\n    category_id,\n    sale_date,\n    total_daily_revenue,\n    AVG(total_daily_revenue) OVER (\n        PARTITION BY category_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_day\nFROM daily_sales\nORDER BY category_id, sale_date;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of an organization from an 'employees' table (id, name, manager_id), showing the hierarchy level and path from the top-level manager.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Top-level managers (no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 as level, \n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the previous level\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        o.level + 1,\n        o.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.id\n)\nSELECT * FROM org_chart\nORDER BY path;"}
{"instruction": "Write a query to identify 'Gaps and Islands' in user login data to find the longest streak of consecutive daily logins for each user.", "output": "WITH grouped_dates AS (\n    SELECT\n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n    GROUP BY user_id, login_date -- Ensure uniqueness per day\n),\nstreaks AS (\n    SELECT\n        user_id,\n        COUNT(*) as streak_length,\n        MIN(login_date) as streak_start,\n        MAX(login_date) as streak_end\n    FROM grouped_dates\n    GROUP BY user_id, grp\n)\nSELECT\n    user_id,\n    MAX(streak_length) as longest_streak\nFROM streaks\nGROUP BY user_id;"}
{"instruction": "Perform a complex join to find customers who have purchased 'Product A' but have NEVER purchased 'Product B'.", "output": "SELECT DISTINCT c.customer_id, c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nWHERE p.product_name = 'Product A'\nAND NOT EXISTS (\n    SELECT 1\n    FROM orders o2\n    JOIN order_items oi2 ON o2.order_id = oi2.order_id\n    JOIN products p2 ON oi2.product_id = p2.product_id\n    WHERE o2.customer_id = c.customer_id\n    AND p2.product_name = 'Product B'\n);"}
{"instruction": "Write a PostgreSQL DBA query to list the top 10 largest tables in the database, including their total size (data + indexes) in a human-readable format.", "output": "SELECT\n    schemaname as schema,\n    relname as table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) as total_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL JOIN to retrieve the 3 most recent comments for every blog post without using a correlated subquery in the SELECT clause.", "output": "SELECT \n    p.post_id,\n    p.title,\n    r.comment_text,\n    r.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments c\n    WHERE c.post_id = p.post_id\n    ORDER BY c.created_at DESC\n    LIMIT 3\n) r;"}
{"instruction": "Pivot a sales table (columns: year, month, amount) to display months as columns and years as rows using conditional aggregation.", "output": "SELECT\n    year,\n    SUM(CASE WHEN month = 1 THEN amount ELSE 0 END) AS Jan,\n    SUM(CASE WHEN month = 2 THEN amount ELSE 0 END) AS Feb,\n    SUM(CASE WHEN month = 3 THEN amount ELSE 0 END) AS Mar,\n    SUM(CASE WHEN month = 4 THEN amount ELSE 0 END) AS Apr,\n    -- ... continue for remaining months\n    SUM(CASE WHEN month = 12 THEN amount ELSE 0 END) AS Dec,\n    SUM(amount) AS Total_Yearly\nFROM monthly_sales\nGROUP BY year\nORDER BY year;"}
{"instruction": "Write a PostgreSQL query to extract data from a JSONB column 'attributes' to find the average rating for products where the color is 'Red'.", "output": "SELECT \n    AVG((attributes ->> 'rating')::NUMERIC) as average_rating\nFROM products\nWHERE attributes @> '{\"color\": \"Red\"}';"}
{"instruction": "Use Window Functions to find the top 3 highest-paid employees per department, handling ties using DENSE_RANK.", "output": "WITH ranked_employees AS (\n    SELECT\n        employee_id,\n        name,\n        department_id,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_pos\n    FROM employees\n)\nSELECT \n    department_id,\n    name,\n    salary,\n    rank_pos\nFROM ranked_employees\nWHERE rank_pos <= 3;"}
{"instruction": "Write a DBA query to identify queries that have been running for more than 5 minutes and are currently active.", "output": "SELECT\n    pid,\n    usename,\n    state,\n    now() - query_start as duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active'\nAND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Write a query using window functions to calculate the running total of sales and a 3-day moving average of sales for each region, ordered by date.", "output": "SELECT \n    region,\n    sale_date,\n    daily_sales,\n    SUM(daily_sales) OVER (\n        PARTITION BY region \n        ORDER BY sale_date\n    ) AS running_total,\n    AVG(daily_sales) OVER (\n        PARTITION BY region \n        ORDER BY sale_date \n        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_3_day\nFROM regional_sales\nORDER BY region, sale_date;"}
{"instruction": "Create a Recursive CTE to traverse an employee hierarchy (adjacency list model) and return the organizational tree with depth levels for a specific manager ID.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select the manager\n    SELECT \n        employee_id, \n        manager_id, \n        full_name, \n        0 AS depth,\n        CAST(full_name AS TEXT) AS path\n    FROM employees\n    WHERE employee_id = 101 -- Root Manager ID\n\n    UNION ALL\n\n    -- Recursive member: select subordinates\n    SELECT \n        e.employee_id, \n        e.manager_id, \n        e.full_name, \n        o.depth + 1,\n        o.path || ' -> ' || e.full_name\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM org_chart\nORDER BY path;"}
{"instruction": "Find the top 3 selling products in each category, handling ties by including all products with the same rank (using DENSE_RANK).", "output": "WITH ranked_products AS (\n    SELECT \n        category_name,\n        product_name,\n        total_sales,\n        DENSE_RANK() OVER (\n            PARTITION BY category_name \n            ORDER BY total_sales DESC\n        ) AS rank_num\n    FROM product_sales_summary\n)\nSELECT * \nFROM ranked_products\nWHERE rank_num <= 3;"}
{"instruction": "Use a CTE and `generate_series` to fill in gaps in a time-series report. The result should show 0 sales for days where no records exist in the source table.", "output": "WITH date_range AS (\n    SELECT generate_series(\n        '2023-01-01'::date, \n        '2023-01-31'::date, \n        '1 day'::interval\n    )::date AS report_date\n)\nSELECT \n    d.report_date,\n    COALESCE(SUM(s.amount), 0) AS total_sales\nFROM date_range d\nLEFT JOIN sales s ON s.sale_date = d.report_date\nGROUP BY d.report_date\nORDER BY d.report_date;"}
{"instruction": "Write a PostgreSQL DBA query to identify the disk size of all tables in the 'public' schema, including their indexes, formatted in human-readable units.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nWHERE schemaname = 'public'\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Calculate the time difference between a user's consecutive login events using the `LAG` window function to analyze session frequency.", "output": "SELECT \n    user_id,\n    login_time,\n    LAG(login_time) OVER (\n        PARTITION BY user_id \n        ORDER BY login_time\n    ) AS previous_login,\n    login_time - LAG(login_time) OVER (\n        PARTITION BY user_id \n        ORDER BY login_time\n    ) AS time_since_last_login\nFROM user_logins\nORDER BY user_id, login_time;"}
{"instruction": "Use a `LATERAL` join to efficiently retrieve the most recent order for every customer without using a window function or subquery in the SELECT clause.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n     recent_order.order_id,\n    recent_order.order_date,\n    recent_order.total_amount\nFROM customers c\nLEFT JOIN LATERAL (\n    SELECT *\n    FROM orders o\n    WHERE o.customer_id = c.customer_id\n    ORDER BY o.order_date DESC\n    LIMIT 1\n) AS recent_order ON true;"}
{"instruction": "Perform a Pivot Table operation using the `FILTER` clause (PostgreSQL) to display total sales for specific years (2021, 2022, 2023) as columns for each product.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(YEAR FROM sale_date) = 2021) AS sales_2021,\n    SUM(amount) FILTER (WHERE EXTRACT(YEAR FROM sale_date) = 2022) AS sales_2022,\n    SUM(amount) FILTER (WHERE EXTRACT(YEAR FROM sale_date) = 2023) AS sales_2023\nFROM sales\nGROUP BY product_name\nORDER BY product_name;"}
{"instruction": "Write a DBA query to detect currently active queries that have been running for more than 5 minutes, including the user and the process ID (PID).", "output": "SELECT \n    pid,\n    usename AS username,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > interval '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Extract data from a JSONB column where the JSON structure is an array of objects. Calculate the total quantity of items purchased per order where the JSON column is `order_details` containing `[{'item': 'A', 'qty': 2}, ...]`.", "output": "SELECT \n    order_id,\n    SUM((item_element->>'qty')::int) AS total_quantity\nFROM orders,\n     LATERAL jsonb_array_elements(order_details) AS item_element\nGROUP BY order_id;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to calculate the running total of sales for each customer, but only strictly for customers who have placed more than 5 orders in total.", "output": "WITH frequent_shoppers AS (\n    SELECT customer_id \n    FROM orders \n    GROUP BY customer_id \n    HAVING COUNT(*) > 5\n)\nSELECT \n    o.customer_id,\n    o.order_date,\n    o.order_amount,\n    SUM(o.order_amount) OVER (PARTITION BY o.customer_id ORDER BY o.order_date) AS running_total\nFROM orders o\nJOIN frequent_shoppers fs ON o.customer_id = fs.customer_id\nORDER BY o.customer_id, o.order_date;"}
{"instruction": "Create a recursive CTE to generate a hierarchical organization chart showing the employee name, their manager's name, and their depth level in the hierarchy.", "output": "WITH RECURSIVE org_hierarchy AS (\n    -- Anchor member: Top-level managers (no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to those above\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oh.level + 1,\n        oh.path || ' -> ' || e.name\n    FROM employees e\n    JOIN org_hierarchy oh ON e.manager_id = oh.id\n)\nSELECT * FROM org_hierarchy ORDER BY path;"}
{"instruction": "Write a PostgreSQL administration query to list all tables in the current database along with their total size (including indexes), sorted by size from largest to smallest.", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_total_relation_size(relid) AS size_bytes\nFROM pg_catalog.pg_statio_user_tables\nORDER BY size_bytes DESC;"}
{"instruction": "Use the `DENSE_RANK()` window function to identify the top 3 highest-paid employees within each department. The result should handle ties (e.g., if two people share the highest salary, they are both rank 1, and the next highest is rank 2).", "output": "WITH ranked_salaries AS (\n    SELECT \n        employee_name,\n        department_id,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_in_dept\n    FROM employees\n)\nSELECT * \nFROM ranked_salaries \nWHERE rank_in_dept <= 3;"}
{"instruction": "Write a query to solve the 'Gaps and Islands' problem: Identify consecutive days a user logged into the system. Return the user_id, the start date of the streak, the end date of the streak, and the length of the streak.", "output": "WITH grouped_logins AS (\n    SELECT \n        user_id, \n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id, \n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as consecutive_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a `LATERAL` join to retrieve every product category and exactly the 2 most recent reviews associated with that category.", "output": "SELECT \n    c.category_name,\n    r.review_text,\n    r.rating,\n    r.created_at\nFROM categories c\nCROSS JOIN LATERAL (\n    SELECT review_text, rating, created_at\n    FROM reviews\n    WHERE category_id = c.id\n    ORDER BY created_at DESC\n    LIMIT 2\n) r;"}
{"instruction": "Write a query using the `FILTER` clause (PostgreSQL specific aggregation) to pivot data, showing total revenue for the current year alongside specific columns for 'Electronics' revenue and 'Clothing' revenue.", "output": "SELECT \n    EXTRACT(MONTH FROM order_date) AS month,\n    SUM(amount) AS total_revenue,\n    SUM(amount) FILTER (WHERE category = 'Electronics') AS electronics_revenue,\n    SUM(amount) FILTER (WHERE category = 'Clothing') AS clothing_revenue\nFROM sales\nWHERE EXTRACT(YEAR FROM order_date) = 2023\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Identify products that have not been sold in the last 6 months but were sold at least once in the 6 months prior to that (churned products).", "output": "SELECT p.product_name\nFROM products p\n-- Ensure it was sold in the previous period (12 months ago to 6 months ago)\nJOIN sales s_old ON p.id = s_old.product_id \n    AND s_old.sale_date BETWEEN NOW() - INTERVAL '12 months' AND NOW() - INTERVAL '6 months'\n-- Ensure it was NOT sold in the recent period (last 6 months)\nLEFT JOIN sales s_new ON p.id = s_new.product_id \n    AND s_new.sale_date >= NOW() - INTERVAL '6 months'\nWHERE s_new.product_id IS NULL\nGROUP BY p.product_name;"}
{"instruction": "Write a database administration query to find currently running queries that have been active for more than 5 minutes, excluding idle connections.", "output": "SELECT \n    pid, \n    usename, \n    application_name, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes';"}
{"instruction": "Query a JSONB column named `attributes` in a `products` table to find the average weight of products where the color key in the JSON is set to 'Red'.", "output": "SELECT \n    AVG((attributes->>'weight')::numeric) as average_red_weight\nFROM products\nWHERE attributes @> '{\"color\": \"Red\"}';"}
{"instruction": "Write a query using a Recursive CTE to generate a hierarchical view of an employee organization chart, showing the employee name, their manager, and their depth level in the hierarchy.", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n    -- Anchor member: select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        eh.level + 1,\n        eh.path || ' > ' || e.name\n    FROM employees e\n    INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM EmployeeHierarchy ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales using a window function.", "output": "SELECT \n    sale_date,\n    total_revenue,\n    AVG(total_revenue) OVER (\n        ORDER BY sale_date\n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_days\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Identify 'gaps' in a sequence of ID numbers in the 'invoices' table to find missing invoice numbers.", "output": "SELECT \n    start_id + 1 AS gap_start, \n    end_id - 1 AS gap_end\nFROM (\n    SELECT \n        id AS start_id, \n        LEAD(id) OVER (ORDER BY id) AS end_id\n    FROM invoices\n) subquery\nWHERE end_id - start_id > 1;"}
{"instruction": "Use a LATERAL join to retrieve the top 3 most recent orders for every customer found in the 'customers' table.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE user_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Pivot a sales table using conditional aggregation to show total sales per product for Q1 (January, February, March) as separate columns.", "output": "SELECT \n    product_id,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 1 THEN amount ELSE 0 END) AS sales_jan,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 2 THEN amount ELSE 0 END) AS sales_feb,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 3 THEN amount ELSE 0 END) AS sales_mar,\n    SUM(amount) AS q1_total\nFROM sales\nWHERE sale_date >= '2023-01-01' AND sale_date <= '2023-03-31'\nGROUP BY product_id;"}
{"instruction": "PostgreSQL Admin: Write a query to list the top 10 largest tables in the database, including their index size, formatted in a human-readable size (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Find the user ID and email of customers who have purchased product A but have NEVER purchased product B using EXCEPT or NOT EXISTS.", "output": "SELECT user_id, email \nFROM users u\nJOIN orders o ON u.user_id = o.user_id\nJOIN order_items oi ON o.order_id = oi.order_id\nWHERE oi.product_id = 'Product_A_ID'\n\nEXCEPT\n\nSELECT u.user_id, email \nFROM users u\nJOIN orders o ON u.user_id = o.user_id\nJOIN order_items oi ON o.order_id = oi.order_id\nWHERE oi.product_id = 'Product_B_ID';"}
{"instruction": "PostgreSQL Admin: Identify currently active queries running for longer than 5 minutes.", "output": "SELECT \n    pid, \n    now() - pg_stat_activity.query_start AS duration, \n    usename, \n    query, \n    state\nFROM pg_stat_activity\nWHERE (now() - pg_stat_activity.query_start) > interval '5 minutes'\nAND state = 'active'\nORDER BY duration DESC;"}
{"instruction": "Aggregate data from a PostgreSQL JSONB column: Calculate the total revenue per 'category' extracted from a JSONB 'attributes' column.", "output": "SELECT \n    attributes->>'category' AS category,\n    SUM((attributes->>'price')::NUMERIC) AS total_revenue\nFROM products\nWHERE attributes ? 'category'\nGROUP BY attributes->>'category'\nORDER BY total_revenue DESC;"}
{"instruction": "Perform a cohort analysis: Calculate the retention rate by counting how many users who signed up in a specific month made a purchase in subsequent months.", "output": "WITH monthly_cohorts AS (\n    SELECT \n        user_id, \n        DATE_TRUNC('month', signup_date) AS cohort_month\n    FROM users\n),\nuser_activities AS (\n    SELECT \n        user_id, \n        DATE_TRUNC('month', activity_date) AS activity_month\n    FROM activities\n)\nSELECT \n    c.cohort_month,\n    a.activity_month,\n    COUNT(DISTINCT c.user_id) AS active_users,\n    EXTRACT(MONTH FROM age(a.activity_month, c.cohort_month)) AS month_lag\nFROM monthly_cohorts c\nJOIN user_activities a ON c.user_id = a.user_id\nWHERE a.activity_month >= c.cohort_month\nGROUP BY c.cohort_month, a.activity_month\nORDER BY c.cohort_month, a.activity_month;"}
{"instruction": "Write a query using a Recursive CTE to traverse an organizational hierarchy. The query should return the employee ID, name, manager ID, and their hierarchical depth (level) starting from the top-level manager (where manager_id is NULL).", "output": "WITH RECURSIVE org_hierarchy AS (\n    -- Anchor member: Top-level managers\n    SELECT id, name, manager_id, 1 AS level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the previous level\n    SELECT e.id, e.name, e.manager_id, oh.level + 1\n    FROM employees e\n    INNER JOIN org_hierarchy oh ON e.manager_id = oh.id\n)\nSELECT * FROM org_hierarchy\nORDER BY level, id;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product using a Window Function. The result should include the date, product_id, daily sales, and the moving average.", "output": "SELECT \n    sale_date,\n    product_id,\n    daily_sales_amount,\n    AVG(daily_sales_amount) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7d\nFROM daily_sales_summary\nORDER BY product_id, sale_date;"}
{"instruction": "Identify 'Churned' users using Set Operations. Find users who placed an order in the previous month (e.g., January 2023) but have NOT placed an order in the current month (e.g., February 2023).", "output": "SELECT user_id \nFROM orders \nWHERE order_date >= '2023-01-01' AND order_date < '2023-02-01'\n\nEXCEPT\n\nSELECT user_id \nFROM orders \nWHERE order_date >= '2023-02-01' AND order_date < '2023-03-01';"}
{"instruction": "Perform a 'Gaps and Islands' analysis to find consecutive active login days for users. Group consecutive dates into a single streak period.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id, \n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id, \n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_length\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a LATERAL join to retrieve the top 3 most recent orders for every customer without using a window function in the select list.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE user_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Pivot row data into columns (Cross-tabulation) using ANSI SQL conditional aggregation to show total sales per product for Q1 (January, February, March).", "output": "SELECT \n    product_id,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 1 THEN amount ELSE 0 END) AS jan_sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 2 THEN amount ELSE 0 END) AS feb_sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 3 THEN amount ELSE 0 END) AS mar_sales,\n    SUM(amount) AS q1_total\nFROM sales\nWHERE sale_date BETWEEN '2023-01-01' AND '2023-03-31'\nGROUP BY product_id;"}
{"instruction": "Fill data gaps in a time series report. Use `generate_series` (PostgreSQL) to create a list of all days in a month and left join sales data to ensure days with zero sales appear in the result as 0.", "output": "SELECT \n    d.day AS report_date,\n    COALESCE(SUM(s.amount), 0) AS total_sales\nFROM generate_series('2023-01-01'::date, '2023-01-31'::date, '1 day') AS d(day)\nLEFT JOIN sales s ON s.sale_date = d.day\nGROUP BY d.day\nORDER BY d.day;"}
{"instruction": "Database Administration: Write a query to list the top 10 largest tables in the current PostgreSQL database, showing total size (including indexes) and table-only size.", "output": "SELECT\n    schemaname AS schema,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Calculate the percentage change in monthly revenue compared to the previous month using Window Functions (LAG).", "output": "WITH monthly_revenue AS (\n    SELECT \n        DATE_TRUNC('month', order_date) AS month_start,\n        SUM(amount) AS revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT \n    month_start,\n    revenue,\n    LAG(revenue) OVER (ORDER BY month_start) AS prev_month_revenue,\n    ROUND(\n        ((revenue - LAG(revenue) OVER (ORDER BY month_start)) / \n        NULLIF(LAG(revenue) OVER (ORDER BY month_start), 0)) * 100, \n    2) AS pct_growth\nFROM monthly_revenue;"}
{"instruction": "Database Administration: Identify currently running queries that have been active for more than 5 minutes, excluding idle connections.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) AS duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle' \n  AND query NOT ILIKE '%pg_stat_activity%'\n  AND query_start < clock_timestamp() - INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Write a recursive Common Table Expression (CTE) query to generate a hierarchical view of employees and their managers, including the depth of the hierarchy (level) for each employee.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        first_name, \n        last_name, \n        manager_id, \n        1 AS level,\n        CAST(first_name || ' ' || last_name AS TEXT) AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join the CTE to find subordinates\n    SELECT \n        e.employee_id, \n        e.first_name, \n        e.last_name, \n        e.manager_id, \n        eh.level + 1,\n        eh.path || ' > ' || e.first_name || ' ' || e.last_name\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy\nORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of sales amount for each day, ordered by date. Assume the table 'sales' has columns 'sale_date' and 'amount'.", "output": "SELECT \n    sale_date,\n    SUM(amount) as daily_total,\n    AVG(SUM(amount)) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_days\nFROM sales\nGROUP BY sale_date\nORDER BY sale_date;"}
{"instruction": "Use a LATERAL JOIN to retrieve the top 3 most recent orders for every customer efficiently, without using a correlated subquery in the SELECT list.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nLEFT JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o ON TRUE\nORDER BY c.customer_id, o.order_date DESC;"}
{"instruction": "Solve the 'Gaps and Islands' problem to find consecutive login streaks for users. Identify groups of consecutive days where a user logged in.", "output": "WITH grouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtracting the row number (in days) from the date creates a constant date value \n        -- for consecutive sequences (Islands)\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Create a query to fill in missing dates in a time-series report. Generate a list of all days in the current month and join it with a 'sales' table to show 0 instead of NULL for days with no sales.", "output": "SELECT \n    d.day::DATE AS report_date,\n    COALESCE(SUM(s.amount), 0) AS total_sales\nFROM \n    generate_series(\n        DATE_TRUNC('month', CURRENT_DATE), \n        DATE_TRUNC('month', CURRENT_DATE) + INTERVAL '1 month' - INTERVAL '1 day',\n        INTERVAL '1 day'\n    ) AS d(day)\nLEFT JOIN sales s ON s.sale_date = d.day::DATE\nGROUP BY d.day\nORDER BY d.day;"}
{"instruction": "Pivot a dataset using PostgreSQL's FILTER clause to display total revenue per product category for Q1, Q2, Q3, and Q4 in a single row per year.", "output": "SELECT \n    EXTRACT(YEAR FROM order_date) AS sales_year,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM order_date) = 1) AS q1_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM order_date) = 2) AS q2_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM order_date) = 3) AS q3_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM order_date) = 4) AS q4_revenue\nFROM orders\nGROUP BY EXTRACT(YEAR FROM order_date)\nORDER BY sales_year;"}
{"instruction": "Write a DBA query to identify currently active queries that are being blocked by other transactions (lock contention) in PostgreSQL.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Analyze a 'books' table containing a JSONB column 'metadata' (which contains an array of tags). Write a query to count the occurrences of every unique tag across all books.", "output": "SELECT \n    tag,\n    COUNT(*) as frequency\nFROM books,\nLATERAL jsonb_array_elements_text(metadata -> 'tags') AS tag\nGROUP BY tag\nORDER BY frequency DESC;"}
{"instruction": "Delete duplicate rows from a table named 'contacts' based on the email address, keeping only the entry with the highest ID (most recently added).", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY id DESC) as rn\n        FROM contacts\n    ) t\n    WHERE t.rn > 1\n);"}
{"instruction": "Write a DBA query to find all indexes in the public schema that have never been used (scan count is zero), ordering by the size of the index.", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as scan_count\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0\n  AND schemaname = 'public'\n  AND NOT indisunique -- Usually don't want to drop unique constraints even if unused for lookups\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to find the top 3 highest-grossing products within each product category for the year 2023.", "output": "WITH ProductSales AS (\n    SELECT \n        p.category_id,\n        p.product_name,\n        SUM(o.quantity * o.unit_price) as total_revenue\n    FROM products p\n    JOIN order_items o ON p.product_id = o.product_id\n    JOIN orders ord ON o.order_id = ord.order_id\n    WHERE ord.order_date >= '2023-01-01' AND ord.order_date <= '2023-12-31'\n    GROUP BY p.category_id, p.product_name\n),\nRankedSales AS (\n    SELECT \n        category_id,\n        product_name,\n        total_revenue,\n        DENSE_RANK() OVER (PARTITION BY category_id ORDER BY total_revenue DESC) as rank\n    FROM ProductSales\n)\nSELECT * \nFROM RankedSales\nWHERE rank <= 3;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical organizational chart showing the path from the CEO (manager_id IS NULL) down to every employee.", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id,\n        name,\n        manager_id,\n        name::TEXT as hierarchy_path,\n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.employee_id,\n        e.name,\n        e.manager_id,\n        (o.hierarchy_path || ' -> ' || e.name) as hierarchy_path,\n        o.level + 1\n    FROM employees e\n    INNER JOIN OrgChart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM OrgChart\nORDER BY hierarchy_path;"}
{"instruction": "Calculate the 7-day moving average of daily sales using a Window Function, handling days with no sales by assuming zero (requires generating a date series).", "output": "WITH DateSeries AS (\n    SELECT generate_series(MIN(order_date), MAX(order_date), '1 day')::DATE as day\n    FROM orders\n),\nDailySales AS (\n    SELECT \n        ds.day,\n        COALESCE(SUM(o.total_amount), 0) as daily_revenue\n    FROM DateSeries ds\n    LEFT JOIN orders o ON ds.day = o.order_date\n    GROUP BY ds.day\n)\nSELECT \n    day,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY day \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM DailySales\nORDER BY day;"}
{"instruction": "Perform a 'Gaps and Islands' analysis to find consecutive days a user logged in. Return the user_id, start date, end date, and length of the streak.", "output": "WITH GroupedDates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtracting a sequence of days from the date creates a constant value for consecutive dates\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM GroupedDates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a LATERAL JOIN to retrieve the 3 most recent orders for every customer who lives in 'New York', without using a window function in the select list.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    recent_orders.order_id,\n    recent_orders.order_date,\n    recent_orders.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT \n        o.order_id, \n        o.order_date, \n        o.total_amount\n    FROM orders o\n    WHERE o.customer_id = c.customer_id\n    ORDER BY o.order_date DESC\n    LIMIT 3\n) AS recent_orders\nWHERE c.city = 'New York';"}
{"instruction": "Database Administration: Write a query to identify currently active queries that have been running for more than 5 minutes, excluding the current session's query.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) as duration,\n    query\nFROM pg_stat_activity\nWHERE \n    state = 'active' \n    AND age(clock_timestamp(), query_start) > INTERVAL '5 minutes'\n    AND pid <> pg_backend_pid()\nORDER BY duration DESC;"}
{"instruction": "Database Administration: Find the top 5 largest tables in the database, including the size of their indexes, and format the output in human-readable size (e.g., MB, GB).", "output": "SELECT \n    schemaname,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 5;"}
{"instruction": "Pivot monthly sales data from rows to columns (Cross-tabulation) for the year 2023 without using the crosstab() extension function.", "output": "SELECT \n    product_id,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 1 THEN amount ELSE 0 END) AS Jan,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 2 THEN amount ELSE 0 END) AS Feb,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 3 THEN amount ELSE 0 END) AS Mar,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 4 THEN amount ELSE 0 END) AS Apr,\n    -- ... continue for May through Dec\n    SUM(amount) as Total_Yearly\nFROM sales\nWHERE order_date >= '2023-01-01' AND order_date <= '2023-12-31'\nGROUP BY product_id\nORDER BY Total_Yearly DESC;"}
{"instruction": "Perform an 'Upsert' (Insert on Conflict) operation. Insert a new user record, but if the email already exists, update the last_login timestamp instead.", "output": "INSERT INTO users (username, email, last_login, created_at)\nVALUES ('john_doe', 'john@example.com', NOW(), NOW())\nON CONFLICT (email) \nDO UPDATE SET \n    last_login = EXCLUDED.last_login,\n    username = EXCLUDED.username;"}
{"instruction": "Database Administration: Identify blocking queries. Find the PIDs and queries that are blocking other transactions.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Write a query using a Recursive CTE to generate an organizational hierarchy. The output should show the employee's name, their manager's name, their depth in the hierarchy (level), and a breadcrumb path of management IDs from the top level down to the employee.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(employee_id AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || '->' || CAST(e.employee_id AS TEXT)\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product category. The result should include the date, category, daily sales, and the moving average, ordered by category and date.", "output": "SELECT \n    sale_date,\n    category,\n    SUM(amount) as daily_sales,\n    AVG(SUM(amount)) OVER (\n        PARTITION BY category \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM sales\nGROUP BY sale_date, category\nORDER BY category, sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login data. Find the start date, end date, and length of consecutive daily login streaks for every user.", "output": "WITH grouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtract row_number from date to create a constant value for consecutive groups\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "PostgreSQL Administration: List the top 10 largest tables in the current database, displaying the schema, table name, size of the table data only, and the total size including indexes and toast data in a human-readable format.", "output": "SELECT\n    schemaname AS schema,\n    relname AS table_name,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot a transactional table to display total sales per region (rows) for each quarter (columns) of the current year using PostgreSQL's FILTER clause for conditional aggregation.", "output": "SELECT \n    region,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS q2_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS q3_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS q4_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY region\nORDER BY region;"}
{"instruction": "Find customers who have purchased 'Product A' but have NEVER purchased 'Product B'. Use a set operation or NOT EXISTS clause for efficiency.", "output": "SELECT DISTINCT c.customer_id, c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nWHERE p.product_name = 'Product A'\nAND NOT EXISTS (\n    SELECT 1 \n    FROM orders o2\n    JOIN order_items oi2 ON o2.order_id = oi2.order_id\n    JOIN products p2 ON oi2.product_id = p2.product_id\n    WHERE o2.customer_id = c.customer_id\n    AND p2.product_name = 'Product B'\n);"}
{"instruction": "PostgreSQL Administration: Identify currently running queries that have been active for more than 5 minutes, excluding the current session and idle connections. Return the PID, duration, user, and the query text.", "output": "SELECT \n    pid, \n    now() - query_start AS duration, \n    usename, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes' \n  AND pid <> pg_backend_pid();"}
{"instruction": "Calculate the Year-Over-Year (YoY) growth percentage for monthly revenue using the LAG window function.", "output": "WITH monthly_revenue AS (\n    SELECT \n        DATE_TRUNC('month', sale_date) as sales_month,\n        SUM(amount) as revenue\n    FROM sales\n    GROUP BY 1\n)\nSELECT \n    sales_month,\n    revenue,\n    LAG(revenue, 12) OVER (ORDER BY sales_month) as revenue_prev_year,\n    ROUND(\n        ((revenue - LAG(revenue, 12) OVER (ORDER BY sales_month)) / \n        NULLIF(LAG(revenue, 12) OVER (ORDER BY sales_month), 0)) * 100, \n    2) as yoy_growth_pct\nFROM monthly_revenue;"}
{"instruction": "Perform a complex update: Increase the salary of employees by 10% if they are in a department located in 'New York' and have a performance rating higher than the average rating of their specific department.", "output": "UPDATE employees e\nSET salary = salary * 1.10\nFROM departments d\nWHERE e.department_id = d.department_id\n  AND d.location = 'New York'\n  AND e.performance_rating > (\n      SELECT AVG(e2.performance_rating)\n      FROM employees e2\n      WHERE e2.department_id = e.department_id\n  );"}
{"instruction": "Use a JSONB query to find all rows where a JSON column 'attributes' contains a key 'specs' which has an array containing the value 'wireless', and expand that array into rows.", "output": "SELECT \n    product_id, \n    product_name, \n    jsonb_array_elements_text(attributes -> 'specs') as spec_item\nFROM products\nWHERE attributes @> '{\"specs\": [\"wireless\"]}'\n-- Optional: if you specifically want to filter the output rows to only show the matching element\nAND EXISTS (\n    SELECT 1 \n    FROM jsonb_array_elements_text(attributes -> 'specs') elem \n    WHERE elem = 'wireless'\n);"}
{"instruction": "Write a query using a Recursive CTE to find the management hierarchy for a specific employee (ID 105). Display the path of employee names from the top-level manager down to the specific employee.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: select the employee\n    SELECT \n        employee_id, \n        manager_id, \n        full_name, \n        1 as level,\n        full_name::TEXT as path\n    FROM employees\n    WHERE employee_id = 105\n    \n    UNION ALL\n    \n    -- Recursive member: join with managers\n    SELECT \n        e.employee_id, \n        e.manager_id, \n        e.full_name, \n        eh.level + 1,\n        e.full_name || ' -> ' || eh.path\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.employee_id = eh.manager_id\n)\nSELECT path \nFROM employee_hierarchy \nORDER BY level DESC \nLIMIT 1;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for the current year, ensuring rows exist for every date using `generate_series`.", "output": "WITH date_range AS (\n    SELECT generate_series(\n        DATE_TRUNC('year', CURRENT_DATE), \n        DATE_TRUNC('year', CURRENT_DATE) + INTERVAL '1 year' - INTERVAL '1 day', \n        INTERVAL '1 day'\n    )::DATE AS day_date\n),\ndaily_sales AS (\n    SELECT \n        transaction_date::DATE AS sale_day, \n        SUM(amount) AS total_revenue\n    FROM sales\n    WHERE transaction_date >= DATE_TRUNC('year', CURRENT_DATE)\n    GROUP BY 1\n)\nSELECT \n    d.day_date,\n    COALESCE(ds.total_revenue, 0) as revenue,\n    AVG(COALESCE(ds.total_revenue, 0)) OVER (\n        ORDER BY d.day_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM date_range d\nLEFT JOIN daily_sales ds ON d.day_date = ds.sale_day\nORDER BY d.day_date;"}
{"instruction": "Identify the top 3 highest-paid employees within each department using a window function, handling ties with `DENSE_RANK`.", "output": "WITH ranked_employees AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_pos\n    FROM employees\n)\nSELECT * \nFROM ranked_employees \nWHERE rank_pos <= 3;"}
{"instruction": "DBA Task: List the top 10 largest tables in the PostgreSQL database, displaying the size of the table data, the size of indexes, and the total size in a human-readable format.", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_indexes_size(relid)) AS index_size,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot monthly sales data from rows to columns (Jan, Feb, Mar) for the year 2023 using the PostgreSQL `FILTER` clause.", "output": "SELECT \n    product_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nWHERE sale_date >= '2023-01-01' AND sale_date <= '2023-03-31'\nGROUP BY product_id;"}
{"instruction": "Use a `LATERAL` join to retrieve the 2 most recent orders for every customer who signed up in the last month.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 2\n) o\nWHERE c.signup_date >= (CURRENT_DATE - INTERVAL '1 month');"}
{"instruction": "Calculate the Year-Over-Year (YoY) growth percentage for monthly revenue.", "output": "WITH monthly_stats AS (\n    SELECT \n        DATE_TRUNC('month', payment_date) AS month_start,\n        SUM(amount) as current_revenue\n    FROM payments\n    GROUP BY 1\n),\nyoy_calc AS (\n    SELECT \n        month_start,\n        current_revenue,\n        LAG(current_revenue, 12) OVER (ORDER BY month_start) as prev_year_revenue\n    FROM monthly_stats\n)\nSELECT \n    month_start,\n    current_revenue,\n    prev_year_revenue,\n    ROUND(((current_revenue - prev_year_revenue) / NULLIF(prev_year_revenue, 0)) * 100, 2) as growth_pct\nFROM yoy_calc\nWHERE prev_year_revenue IS NOT NULL;"}
{"instruction": "DBA Task: Identify currently running queries that have been active for more than 5 minutes, excluding the current query itself.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Remove duplicate rows from a table based on `email` and `username`, keeping only the entry with the latest `created_at` timestamp using `ctid` (PostgreSQL specific physical row location).", "output": "DELETE FROM users\nWHERE ctid IN (\n    SELECT ctid\n    FROM (\n        SELECT \n            ctid,\n            ROW_NUMBER() OVER (PARTITION BY email, username ORDER BY created_at DESC) as rn\n        FROM users\n    ) t\n    WHERE rn > 1\n);"}
{"instruction": "Extract specific keys from a JSONB column. Find all users where the 'attributes' JSONB column contains a key 'preferences' with a nested key 'theme' set to 'dark'.", "output": "SELECT \n    user_id, \n    username, \n    attributes -> 'preferences' ->> 'language' as language\nFROM users\nWHERE attributes @> '{\"preferences\": {\"theme\": \"dark\"}}';"}
{"instruction": "Write a recursive CTE to generate a hierarchical organization chart showing employee names and their distance (level) from the top manager.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Select the top manager (who has no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 as level,\n        CAST(name AS TEXT) as path\n    FROM employees \n    WHERE manager_id IS NULL\n    \n    UNION ALL\n    \n    -- Recursive member: Join subordinates to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day rolling average of daily sales revenue using a window function.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS rolling_7_day_avg\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Identify the top 3 highest-paid employees in each department using ranking window functions.", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM RankedSalaries\nWHERE rank_num <= 3;"}
{"instruction": "Perform a gap analysis to find missing sequential Invoice IDs in a table.", "output": "SELECT \n    invoice_id + 1 AS gap_start,\n    next_id - 1 AS gap_end\nFROM (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) AS next_id\n    FROM invoices\n) sub\nWHERE next_id > invoice_id + 1;"}
{"instruction": "DBA Task: List the top 10 largest tables in a PostgreSQL database including their indexes, formatted in human-readable size.", "output": "SELECT\n    schemaname AS schema,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL join to fetch the 3 most recent comments for every blog post without using a correlated subquery in the SELECT list.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_text,\n    c.created_at\nFROM posts p\nLEFT JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c ON true\nORDER BY p.post_id, c.created_at DESC;"}
{"instruction": "Pivot monthly sales data from rows to columns (Jan, Feb, Mar) for the current year using conditional aggregation (FILTER).", "output": "SELECT \n    product_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY product_id;"}
{"instruction": "Calculate Year-Over-Year (YoY) growth percentage for annual revenue.", "output": "WITH AnnualStats AS (\n    SELECT \n        EXTRACT(YEAR FROM sale_date) as year,\n        SUM(amount) as total_revenue\n    FROM sales\n    GROUP BY 1\n)\nSELECT \n    year,\n    total_revenue,\n    LAG(total_revenue) OVER (ORDER BY year) as prev_year_revenue,\n    ROUND(\n        ((total_revenue - LAG(total_revenue) OVER (ORDER BY year)) / \n        LAG(total_revenue) OVER (ORDER BY year)::NUMERIC) * 100, 2\n    ) as yoy_growth_percent\nFROM AnnualStats;"}
{"instruction": "DBA Task: Identify currently active queries running for longer than 5 minutes.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Delete duplicate rows from a table based on specific columns (email, category), keeping only the entry with the latest ID.", "output": "DELETE FROM users\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email, category ORDER BY id DESC) as r_num\n        FROM users\n    ) t\n    WHERE t.r_num > 1\n);"}
{"instruction": "Write a query using a Recursive CTE to generate a hierarchical view of employees and their managers, including the depth level of each employee in the organizational tree.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees with their managers from the previous level\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        o.level + 1,\n        o.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily revenue for the current year using Window Functions.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_days\nFROM (\n    SELECT \n        DATE(created_at) as sale_date, \n        SUM(amount) as daily_revenue\n    FROM sales\n    WHERE EXTRACT(YEAR FROM created_at) = EXTRACT(YEAR FROM CURRENT_DATE)\n    GROUP BY DATE(created_at)\n) daily_sales\nORDER BY sale_date;"}
{"instruction": "Find the top 3 products by sales volume within each product category using `DENSE_RANK`.", "output": "WITH category_sales AS (\n    SELECT \n        p.category_id,\n        p.product_name,\n        SUM(s.quantity) as total_quantity\n    FROM products p\n    JOIN order_items s ON p.product_id = s.product_id\n    GROUP BY p.category_id, p.product_name\n),\nranked_products AS (\n    SELECT \n        category_id,\n        product_name,\n        total_quantity,\n        DENSE_RANK() OVER (PARTITION BY category_id ORDER BY total_quantity DESC) as rank\n    FROM category_sales\n)\nSELECT * \nFROM ranked_products \nWHERE rank <= 3;"}
{"instruction": "Identify 'gaps' in a sequence of invoice IDs (finding missing invoice numbers) using `LEAD`.", "output": "WITH ordered_invoices AS (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) as next_invoice_id\n    FROM invoices\n)\nSELECT \n    invoice_id + 1 as gap_start,\n    next_invoice_id - 1 as gap_end\nFROM ordered_invoices\nWHERE next_invoice_id - invoice_id > 1;"}
{"instruction": "Perform a 'pivot' operation using conditional aggregation to display total sales per month (Jan-Dec) as columns for each year.", "output": "SELECT \n    EXTRACT(YEAR FROM order_date) AS sales_year,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 1 THEN amount ELSE 0 END) AS jan,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 2 THEN amount ELSE 0 END) AS feb,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 3 THEN amount ELSE 0 END) AS mar,\n    -- ... continue for remaining months ...\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 12 THEN amount ELSE 0 END) AS dec,\n    SUM(amount) AS total_year\nFROM orders\nGROUP BY EXTRACT(YEAR FROM order_date)\nORDER BY sales_year;"}
{"instruction": "Write a PostgreSQL administration query to identify unused indexes (indexes that have not been scanned) to optimize storage.", "output": "SELECT \n    schemaname, \n    relname AS table_name, \n    indexrelname AS index_name, \n    idx_scan AS number_of_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\nAND indexrelname NOT LIKE '%_pkey'\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Reconcile inventory data between two tables (System A and System B) using a Full Outer Join to find discrepancies in quantities.", "output": "SELECT \n    COALESCE(a.sku, b.sku) AS sku,\n    a.quantity AS sys_a_qty,\n    b.quantity AS sys_b_qty,\n    CASE \n        WHEN a.sku IS NULL THEN 'Missing in A'\n        WHEN b.sku IS NULL THEN 'Missing in B'\n        WHEN a.quantity <> b.quantity THEN 'Mismatch'\n        ELSE 'Match'\n    END AS status\nFROM inventory_system_a a\nFULL OUTER JOIN inventory_system_b b ON a.sku = b.sku\nWHERE a.quantity IS DISTINCT FROM b.quantity;"}
{"instruction": "Calculate the time difference between consecutive user actions (session analysis) using `LAG`.", "output": "SELECT \n    user_id,\n    event_type,\n    event_timestamp,\n    LAG(event_timestamp) OVER (PARTITION BY user_id ORDER BY event_timestamp) as previous_event_time,\n    event_timestamp - LAG(event_timestamp) OVER (PARTITION BY user_id ORDER BY event_timestamp) as time_since_last_event\nFROM user_logs\nORDER BY user_id, event_timestamp;"}
{"instruction": "PostgreSQL specific: Extract specific keys from a JSONB column and aggregate them (e.g., count product attributes stored as JSON).", "output": "SELECT \n    attributes ->> 'color' AS color,\n    attributes ->> 'size' AS size,\n    COUNT(*)\nFROM products\nWHERE attributes IS NOT NULL\nGROUP BY attributes ->> 'color', attributes ->> 'size'\nORDER BY count DESC;"}
{"instruction": "Write a PostgreSQL administration query to find currently active queries that are running for more than 5 minutes.", "output": "SELECT \n    pid,\n    usename,\n    application_name,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active'\nAND now() - query_start > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Write a Recursive CTE to generate a hierarchical organization chart showing the employee name, their manager's ID, and their depth level in the hierarchy, starting from the CEO (where manager_id is NULL).", "output": "WITH RECURSIVE org_hierarchy AS (\n    -- Anchor member: Select top-level employees (CEO)\n    SELECT \n        employee_id, \n        full_name, \n        manager_id, \n        1 AS hierarchy_level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.employee_id, \n        e.full_name, \n        e.manager_id, \n        oh.hierarchy_level + 1\n    FROM employees e\n    INNER JOIN org_hierarchy oh ON e.manager_id = oh.employee_id\n)\nSELECT * FROM org_hierarchy\nORDER BY hierarchy_level, full_name;"}
{"instruction": "Calculate the 7-day rolling moving average of daily revenue for the 'sales' table using Window Functions.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date\n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS seven_day_moving_average\nFROM (\n    SELECT \n        DATE(created_at) as sale_date, \n        SUM(amount) as daily_revenue\n    FROM sales\n    GROUP BY 1\n) daily_sales\nORDER BY sale_date;"}
{"instruction": "Identify 'Islands and Gaps' in a sequence of invoice IDs to find missing invoice numbers.", "output": "WITH gaps AS (\n    SELECT \n        invoice_id AS gap_start,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) AS next_invoice_id\n    FROM invoices\n)\nSELECT \n    gap_start + 1 AS missing_range_start,\n    next_invoice_id - 1 AS missing_range_end\nFROM gaps\nWHERE next_invoice_id - gap_start > 1;"}
{"instruction": "Perform a user retention analysis by calculating the percentage of users active in the current month who were also active in the previous month.", "output": "WITH monthly_active_users AS (\n    SELECT DISTINCT \n        user_id, \n        DATE_TRUNC('month', event_time) AS activity_month\n    FROM user_events\n)\nSELECT \n    curr.activity_month,\n    COUNT(curr.user_id) AS current_active_users,\n    COUNT(prev.user_id) AS retained_users,\n    ROUND((COUNT(prev.user_id)::NUMERIC / COUNT(curr.user_id)) * 100, 2) AS retention_rate\nFROM monthly_active_users curr\nLEFT JOIN monthly_active_users prev \n    ON curr.user_id = prev.user_id \n    AND prev.activity_month = curr.activity_month - INTERVAL '1 month'\nGROUP BY curr.activity_month\nORDER BY curr.activity_month;"}
{"instruction": "Use a LATERAL JOIN to retrieve the top 3 most recent orders for every customer without using a window function in the main projection.", "output": "SELECT \n    c.customer_name,\n    recent_orders.order_id,\n    recent_orders.order_date,\n    recent_orders.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders o\n    WHERE o.customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 3\n) AS recent_orders;"}
{"instruction": "Pivot a table of employee statuses into columns (Active, On Leave, Terminated) per department using the FILTER clause (PostgreSQL specific aggregation).", "output": "SELECT \n    department_id,\n    COUNT(*) FILTER (WHERE status = 'Active') AS active_count,\n    COUNT(*) FILTER (WHERE status = 'On Leave') AS on_leave_count,\n    COUNT(*) FILTER (WHERE status = 'Terminated') AS terminated_count\nFROM employees\nGROUP BY department_id;"}
{"instruction": "DBA Task: Identify queries that are currently waiting on locks and the specific blocking PID (Process ID) causing the wait.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocked_activity.query AS blocked_query,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Extract data from a JSONB column to sum the quantity of items sold where the product attributes contain a specific tag.", "output": "SELECT \n    elem->>'product_name' AS product_name,\n    SUM((elem->>'quantity')::INT) AS total_quantity\nFROM orders,\nLATERAL jsonb_array_elements(order_details) AS elem\nWHERE \n    order_details @> '[{\"tags\": [\"clearance\"]}]'\nGROUP BY 1\nORDER BY 2 DESC;"}
{"instruction": "DBA Task: List the top 10 largest tables in the database including their indexes and toast data.", "output": "SELECT\n    schemaname || '.' || relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_toast_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation: Insert a new inventory record, or update the quantity if the product_id already exists.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_updated)\nVALUES (101, 1, 50, NOW())\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to identify the top 3 highest-grossing products within each product category based on total sales revenue.", "output": "WITH ProductSales AS (\n    SELECT \n        p.category_id,\n        p.product_name,\n        SUM(s.quantity * s.unit_price) as total_revenue\n    FROM products p\n    JOIN sales s ON p.product_id = s.product_id\n    GROUP BY p.category_id, p.product_name\n),\nRankedSales AS (\n    SELECT \n        category_id,\n        product_name,\n        total_revenue,\n        RANK() OVER (PARTITION BY category_id ORDER BY total_revenue DESC) as rank_in_category\n    FROM ProductSales\n)\nSELECT * \nFROM RankedSales\nWHERE rank_in_category <= 3;"}
{"instruction": "Construct a Recursive CTE to generate a hierarchical view of employees, showing the employee ID, name, manager ID, and their depth level in the organization tree, starting from the top-level manager (where manager_id is NULL).", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: Top level management\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 as level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Subordinates\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    JOIN OrgChart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM OrgChart\nORDER BY path;"}
{"instruction": "Write a PostgreSQL administration query to identify currently active queries that have been running for more than 5 minutes, excluding the current query itself.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    query_start, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > interval '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for the current year using a Window Function with a frame clause.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales_summary\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "Solve the 'Gaps and Islands' problem: Identify consecutive days where a user logged in. Group these consecutive streaks together and return the user_id, start_date, end_date, and length of the streak.", "output": "WITH DatedLogins AS (\n    SELECT DISTINCT user_id, login_date\n    FROM user_logins\n),\nGroups AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a grouping identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM DatedLogins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM Groups\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a CROSS JOIN LATERAL (PostgreSQL specific) to fetch the 3 most recent comments for every blog post without using a window function in the select list.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_id,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_id, comment_text, created_at\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c;"}
{"instruction": "Perform a pivot operation using conditional aggregation (FILTER clause) to display total sales per product for each quarter of the year 2023.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS Q1_Sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS Q2_Sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS Q3_Sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS Q4_Sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_name;"}
{"instruction": "Write a query to find 'High Value Churned Customers': Customers who have spent more than $10,000 lifetime but have not placed an order in the last 6 months.", "output": "SELECT \n    c.customer_id,\n    c.email,\n    MAX(o.order_date) as last_order_date,\n    SUM(o.total_amount) as lifetime_value\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nGROUP BY c.customer_id, c.email\nHAVING SUM(o.total_amount) > 10000\n   AND MAX(o.order_date) < CURRENT_DATE - INTERVAL '6 months';"}
{"instruction": "Write a PostgreSQL administration query to find unused indexes (indexes that have not been scanned) to optimize database storage and performance.", "output": "SELECT \n    schemaname, \n    relname AS table_name, \n    indexrelname AS index_name, \n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as scan_count\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Query a JSONB column named 'attributes' to find all products that are colored 'Red' and have a 'size' property, then unpack the 'tags' JSON array into individual rows.", "output": "SELECT \n    product_id,\n    attributes ->> 'color' as color,\n    jsonb_array_elements_text(attributes -> 'tags') as tag\nFROM products\nWHERE attributes @> '{\"color\": \"Red\"}' \n  AND attributes ? 'size';"}
{"instruction": "Write a query to calculate the running total of sales and a 7-day moving average of sales amount for each region, ordered by sale date.", "output": "SELECT \n    region, \n    sale_date, \n    amount,\n    SUM(amount) OVER (\n        PARTITION BY region \n        ORDER BY sale_date\n    ) AS running_total,\n    AVG(amount) OVER (\n        PARTITION BY region \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM sales_data\nORDER BY region, sale_date;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of employees, showing the path from the CEO (manager_id IS NULL) to each employee and their hierarchy level.", "output": "WITH RECURSIVE emp_hierarchy AS (\n    -- Anchor member: CEO\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Subordinates\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        h.level + 1,\n        h.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN emp_hierarchy h ON e.manager_id = h.employee_id\n)\nSELECT * FROM emp_hierarchy\nORDER BY path;"}
{"instruction": "Identify products where the total quantity ordered in the current month exceeds the current stock level. Include products with zero stock.", "output": "SELECT \n    p.product_id,\n    p.product_name,\n    p.stock_quantity,\n    COALESCE(SUM(o.quantity), 0) AS total_ordered\nFROM products p\nLEFT JOIN order_items o ON p.product_id = o.product_id\nLEFT JOIN orders ord ON o.order_id = ord.order_id\nWHERE \n    ord.order_date >= DATE_TRUNC('month', CURRENT_DATE)\n    OR ord.order_date IS NULL\nGROUP BY p.product_id, p.product_name, p.stock_quantity\nHAVING COALESCE(SUM(o.quantity), 0) > p.stock_quantity;"}
{"instruction": "Write a PostgreSQL query to identify and delete duplicate rows from a 'user_logs' table based on 'user_id' and 'log_time', keeping only the entry with the highest 'log_id'.", "output": "DELETE FROM user_logs\nWHERE log_id IN (\n    SELECT log_id\n    FROM (\n        SELECT \n            log_id,\n            ROW_NUMBER() OVER (\n                PARTITION BY user_id, log_time \n                ORDER BY log_id DESC\n            ) as rn\n        FROM user_logs\n    ) t\n    WHERE t.rn > 1\n);"}
{"instruction": "Use a Lateral Join to find the top 3 most recent purchases for every user who has made a purchase in the last year.", "output": "SELECT \n    u.user_id, \n    u.email, \n    p.purchase_id, \n    p.amount, \n    p.purchase_date\nFROM users u\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM purchases \n    WHERE user_id = u.user_id\n    ORDER BY purchase_date DESC\n    LIMIT 3\n) p\nWHERE u.last_active_date >= NOW() - INTERVAL '1 year';"}
{"instruction": "Perform a 'Gaps and Islands' analysis to find consecutive days a user has logged in. Return the user_id, start date of the streak, end date of the streak, and the length of the streak.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id, \n        login_date,\n        -- Create a grouping identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM distinct_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Pivot monthly sales data for the year 2023 to display months as columns (Jan, Feb, Mar) for each product category using PostgreSQL FILTER syntax.", "output": "SELECT \n    category,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY category;"}
{"instruction": "DBA Task: List the top 10 largest tables in the PostgreSQL database, including the size of their indexes, formatted in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "DBA Task: Identify currently active queries that have been running for more than 5 minutes, including the user, database, and the query text.", "output": "SELECT \n    pid, \n    usename, \n    datname, \n    state, \n    now() - query_start AS duration, \n    query\nFROM pg_stat_activity\nWHERE \n    state = 'active' \n    AND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Calculate the retention rate by cohort. Group users by their sign-up month and calculate what percentage of those users placed an order in the subsequent month.", "output": "WITH cohorts AS (\n    SELECT \n        user_id, \n        DATE_TRUNC('month', signup_date) AS cohort_month\n    FROM users\n),\nactivity AS (\n    SELECT DISTINCT \n        user_id, \n        DATE_TRUNC('month', order_date) AS activity_month\n    FROM orders\n)\nSELECT \n    c.cohort_month,\n    COUNT(DISTINCT c.user_id) AS total_users,\n    COUNT(DISTINCT a.user_id) AS retained_users,\n    ROUND((COUNT(DISTINCT a.user_id)::NUMERIC / COUNT(DISTINCT c.user_id)) * 100, 2) AS retention_rate\nFROM cohorts c\nLEFT JOIN activity a \n    ON c.user_id = a.user_id \n    AND a.activity_month = c.cohort_month + INTERVAL '1 month'\nGROUP BY c.cohort_month\nORDER BY c.cohort_month;"}
{"instruction": "Write a query using a Window Function to calculate the 7-day moving average of daily sales for each product, ordered by date.", "output": "SELECT \n    product_id,\n    sale_date,\n    daily_sales,\n    AVG(daily_sales) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM sales_data;"}
{"instruction": "Use a Recursive CTE to generate a full hierarchical path string (e.g., 'CEO > VP > Manager') for an employee organization chart where employees reference a manager_id.", "output": "WITH RECURSIVE org_chart AS (\n    -- Base case: Top level managers (no manager_id)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        name::TEXT AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive step: Join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        o.path || ' > ' || e.name\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM org_chart;"}
{"instruction": "Write a PostgreSQL administration query to find the total size (data + indexes) of the 10 largest tables in the current database.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Identify 'islands' of consecutive login days for users. Group consecutive dates into a single range (Start Date to End Date).", "output": "WITH dated_logins AS (\n    SELECT \n        user_id, \n        login_date,\n        -- Create a value that remains constant for consecutive dates\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS range_start,\n    MAX(login_date) AS range_end,\n    COUNT(*) AS consecutive_days\nFROM dated_logins\nGROUP BY user_id, grp\nORDER BY user_id, range_start;"}
{"instruction": "Use a LATERAL join (PostgreSQL specific) to retrieve the top 3 most recent orders for every customer, without using a window function in the main select list.", "output": "SELECT \n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Perform a cohort analysis: Calculate the percentage of users who signed up in a specific month and made a purchase in the subsequent month.", "output": "WITH monthly_signups AS (\n    SELECT user_id, DATE_TRUNC('month', signup_date) AS cohort_month\n    FROM users\n),\nsubsequent_purchases AS (\n    SELECT DISTINCT user_id, DATE_TRUNC('month', purchase_date) AS purchase_month\n    FROM purchases\n)\nSELECT \n    m.cohort_month,\n    COUNT(m.user_id) AS total_signups,\n    COUNT(s.user_id) AS retained_users,\n    (COUNT(s.user_id)::FLOAT / COUNT(m.user_id)) * 100 AS retention_rate\nFROM monthly_signups m\nLEFT JOIN subsequent_purchases s \n    ON m.user_id = s.user_id \n    AND s.purchase_month = m.cohort_month + INTERVAL '1 month'\nGROUP BY m.cohort_month\nORDER BY m.cohort_month;"}
{"instruction": "Write a query to identify potential duplicate profiles by matching users with the same email address but different case sensitivity, using lower() and aggregation.", "output": "SELECT \n    LOWER(email) AS normalized_email,\n    ARRAY_AGG(id) AS duplicate_ids,\n    COUNT(*) AS count\nFROM users\nGROUP BY LOWER(email)\nHAVING COUNT(*) > 1;"}
{"instruction": "Find the top 2 highest-paid employees per department using the DENSE_RANK() window function to handle salary ties.", "output": "WITH ranked_employees AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT * \nFROM ranked_employees\nWHERE rank <= 2;"}
{"instruction": "Write a PostgreSQL DBA query to identify currently running queries that have been active for more than 5 minutes.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) as duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle'\n  AND query_start < clock_timestamp() - INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Create a pivot table view of sales data, summing revenue by year (rows) and quarter (columns) using filtered aggregation (CASE WHEN).", "output": "SELECT \n    EXTRACT(YEAR FROM order_date) AS sales_year,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM order_date) = 1 THEN amount ELSE 0 END) AS Q1,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM order_date) = 2 THEN amount ELSE 0 END) AS Q2,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM order_date) = 3 THEN amount ELSE 0 END) AS Q3,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM order_date) = 4 THEN amount ELSE 0 END) AS Q4,\n    SUM(amount) AS total_year\nFROM orders\nGROUP BY EXTRACT(YEAR FROM order_date)\nORDER BY sales_year;"}
{"instruction": "Write a recursive Common Table Expression (CTE) to generate an organizational hierarchy chart. Given a table 'employees' with columns 'id', 'name', and 'manager_id', output the employee name, their manager's name, and their hierarchy level (depth), where the CEO (manager_id is NULL) is level 1.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE with employees to find direct reports\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.id\n)\nSELECT \n    oc.name AS employee_name,\n    m.name AS manager_name,\n    oc.level,\n    oc.path\nFROM org_chart oc\nLEFT JOIN employees m ON oc.manager_id = m.id\nORDER BY oc.path;"}
{"instruction": "Identify 'islands' of consecutive activity. Given a 'user_logins' table with 'user_id' and 'login_date', write a query to find the start date, end date, and length (in days) of every consecutive daily login streak for each user.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        -- Consecutive dates will result in the same constant date value\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_length\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Calculate the Year-over-Year (YoY) percentage growth of total sales for each month. The source table 'sales' has 'created_at' and 'amount'. Use window functions to compare the current month's sales with the same month in the previous year.", "output": "WITH monthly_sales AS (\n    SELECT \n        DATE_TRUNC('month', created_at) as sales_month,\n        SUM(amount) as total_revenue\n    FROM sales\n    GROUP BY 1\n),\nyoy_comparison AS (\n    SELECT \n        sales_month,\n        total_revenue,\n        -- Retrieve revenue from exactly 12 months ago\n        LAG(total_revenue, 12) OVER (ORDER BY sales_month) as prev_year_revenue\n    FROM monthly_sales\n)\nSELECT \n    sales_month,\n    total_revenue,\n    prev_year_revenue,\n    ROUND(\n        ((total_revenue - prev_year_revenue) / NULLIF(prev_year_revenue, 0)) * 100, \n        2\n    ) as yoy_growth_percentage\nFROM yoy_comparison\nWHERE prev_year_revenue IS NOT NULL\nORDER BY sales_month DESC;"}
{"instruction": "DBA Task: Write a PostgreSQL query to identify unused indexes in the database to help optimize storage and write performance. Exclude primary keys and unique constraints.", "output": "SELECT \n    schemaname || '.' || relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as index_scans\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0        -- Index has never been scanned\n  AND NOT indisunique     -- Exclude unique indexes (often constraints)\n  AND NOT indisprimary    -- Exclude primary keys\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Calculate a 7-day moving average of stock prices for each ticker symbol. The table 'stock_prices' contains 'ticker', 'date', and 'close_price'. Ensure the window frame handles the first 6 days correctly (partial averages).", "output": "SELECT \n    ticker,\n    date,\n    close_price,\n    AVG(close_price) OVER (\n        PARTITION BY ticker \n        ORDER BY date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7d\nFROM stock_prices\nORDER BY ticker, date;"}
{"instruction": "Using PostgreSQL specific syntax, flatten a JSONB column containing arrays to aggregate data. Given table 'books' with a column 'data' (JSONB) containing a key 'tags' (e.g., {'tags': ['sci-fi', 'drama']}), count the total number of books per tag.", "output": "SELECT \n    tag,\n    COUNT(*) as book_count\nFROM books,\n     -- LATERAL join allows us to reference the 'books' table columns inside the function\n     LATERAL jsonb_array_elements_text(data -> 'tags') as tag\nGROUP BY tag\nORDER BY book_count DESC;"}
{"instruction": "DBA Task: Identify currently running queries that are blocked by other transactions, along with the Process ID (PID) and the query text of the blocking transaction.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocked_activity.query AS blocked_query,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity \n    ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity \n    ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Perform a Pivot (Cross-Tabulation) without using specific PIVOT functions (standard ANSI SQL approach). Given a 'payments' table with 'payment_date' and 'amount', display the total revenue per year with separate columns for Q1, Q2, Q3, and Q4.", "output": "SELECT \n    EXTRACT(YEAR FROM payment_date) as payment_year,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM payment_date) = 1 THEN amount ELSE 0 END) as Q1_Revenue,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM payment_date) = 2 THEN amount ELSE 0 END) as Q2_Revenue,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM payment_date) = 3 THEN amount ELSE 0 END) as Q3_Revenue,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM payment_date) = 4 THEN amount ELSE 0 END) as Q4_Revenue,\n    SUM(amount) as Total_Yearly_Revenue\nFROM payments\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Use a LATERAL JOIN to retrieve the top 3 most recent comments for every blog post. The tables are 'posts' (id, title) and 'comments' (id, post_id, body, created_at).", "output": "SELECT \n    p.title,\n    recent_comments.body,\n    recent_comments.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT body, created_at\n    FROM comments c\n    WHERE c.post_id = p.id\n    ORDER BY c.created_at DESC\n    LIMIT 3\n) AS recent_comments;"}
{"instruction": "Calculate User Retention using Set Operations and CTEs. Determine the retention rate of users who signed up in January 2023 and were also active (logged in) in February 2023.", "output": "WITH jan_cohort AS (\n    SELECT DISTINCT user_id \n    FROM users \n    WHERE signup_date >= '2023-01-01' AND signup_date < '2023-02-01'\n),\nfeb_active AS (\n    SELECT DISTINCT user_id \n    FROM user_logs \n    WHERE login_date >= '2023-02-01' AND login_date < '2023-03-01'\n),\nretained_users AS (\n    SELECT user_id FROM jan_cohort\n    INTERSECT\n    SELECT user_id FROM feb_active\n)\nSELECT \n    (SELECT COUNT(*) FROM jan_cohort) as cohort_size,\n    (SELECT COUNT(*) FROM retained_users) as retained_count,\n    ROUND(\n        (SELECT COUNT(*)::NUMERIC FROM retained_users) / \n        NULLIF((SELECT COUNT(*) FROM jan_cohort), 0) * 100, \n    2) as retention_rate;"}
{"instruction": "Write a query using a Recursive CTE to generate an organizational hierarchy chart. The output should show the employee name, their manager's name, and their hierarchical level (depth) within the organization, starting from the CEO (who has no manager).", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name,\n        manager_id, \n        CAST(name AS TEXT) as path,\n        1 as level\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE to employees to find subordinates\n    SELECT \n        e.employee_id, \n        e.name,\n        e.manager_id, \n        oc.path || ' -> ' || e.name,\n        oc.level + 1\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT \n    name as employee_name,\n    path as hierarchy_path,\n    level\nFROM org_chart\nORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product, along with the running total of sales for the current month. Use Window Functions.", "output": "SELECT \n    product_id,\n    sale_date,\n    daily_sales,\n    -- 7-day moving average (current row + 6 previous days)\n    AVG(daily_sales) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days,\n    -- Running total reset every month\n    SUM(daily_sales) OVER (\n        PARTITION BY product_id, DATE_TRUNC('month', sale_date) \n        ORDER BY sale_date\n    ) AS monthly_running_total\nFROM product_sales\nORDER BY product_id, sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login data. Specifically, find periods of consecutive days where a user logged in, defining the start date, end date, and the length of the streak.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        -- If dates are consecutive, the difference remains constant\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a PostgreSQL DBA query to identify currently active queries that have been running for more than 5 minutes, excluding the query inspecting the process list itself.", "output": "SELECT \n    pid,\n    usename AS username,\n    datname AS database_name,\n    client_addr,\n    application_name,\n    state,\n    age(clock_timestamp(), query_start) AS duration,\n    query\nFROM pg_stat_activity\nWHERE \n    state = 'active' \n    AND (now() - query_start) > INTERVAL '5 minutes'\n    AND pid <> pg_backend_pid()\nORDER BY duration DESC;"}
{"instruction": "Perform a 'Lateral Join' to retrieve the top 3 most recent orders for every customer, without using a window function in the main select list (optimizing for cases where you only need a small slice per outer row).", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT \n        order_id, \n        order_date, \n        total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nORDER BY c.customer_id, o.order_date DESC;"}
{"instruction": "Pivot a sales table using PostgreSQL's `FILTER` clause to display total sales for each product category for the first quarter (Jan, Feb, Mar) in a single row per category.", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_total\nFROM sales\nWHERE sale_date >= '2023-01-01' AND sale_date <= '2023-03-31'\nGROUP BY category_name;"}
{"instruction": "Write a DBA query to check the size of all tables in the current database, including indexes and toast data, formatted in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size_idx_toast\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Delete duplicate rows from a table named `contacts` based on the `email` column, keeping only the row with the latest `created_at` timestamp. Use a CTE with `ctid` (Postgres physical location ID) or `ROW_NUMBER`.", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY created_at DESC) as rn\n        FROM contacts\n    ) t\n    WHERE t.rn > 1\n);"}
{"instruction": "Perform a Cohort Analysis: Calculate the retention rate. Find the percentage of users who signed up in January and made a purchase in each subsequent month.", "output": "WITH jan_cohort AS (\n    SELECT user_id \n    FROM users \n    WHERE DATE_TRUNC('month', signup_date) = '2023-01-01'\n),\nmonthly_activity AS (\n    SELECT \n        DATE_TRUNC('month', purchase_date) as activity_month,\n        COUNT(DISTINCT p.user_id) as active_users\n    FROM purchases p\n    JOIN jan_cohort c ON p.user_id = c.user_id\n    GROUP BY 1\n)\nSELECT \n    activity_month,\n    active_users,\n    ROUND((active_users::numeric / (SELECT COUNT(*) FROM jan_cohort) * 100), 2) as retention_rate\nFROM monthly_activity\nORDER BY activity_month;"}
{"instruction": "Write a query to identify blocking locks in PostgreSQL. The output should show the blocked PID, the blocking PID, and the query being blocked.", "output": "SELECT \n    bl.pid AS blocked_pid,\n    a.usename AS blocked_user,\n    ka.query AS blocking_statement,\n    now() - ka.query_start AS blocking_duration,\n    kl.pid AS blocking_pid,\n    ka.usename AS blocking_user,\n    a.query AS blocked_statement,\n    now() - a.query_start AS blocked_duration\nFROM pg_catalog.pg_locks bl\nJOIN pg_catalog.pg_stat_activity a ON a.pid = bl.pid\nJOIN pg_catalog.pg_locks kl ON kl.transactionid = bl.transactionid AND kl.pid != bl.pid\nJOIN pg_catalog.pg_stat_activity ka ON ka.pid = kl.pid\nWHERE NOT bl.granted;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a window function to find the top 3 sales representatives by total revenue within each sales region.", "output": "WITH RegionSales AS (\n    SELECT \n        r.region_name,\n        s.rep_id,\n        SUM(s.amount) AS total_revenue\n    FROM sales s\n    JOIN regions r ON s.region_id = r.id\n    GROUP BY r.region_name, s.rep_id\n),\nRankedSales AS (\n    SELECT \n        region_name,\n        rep_id,\n        total_revenue,\n        DENSE_RANK() OVER (PARTITION BY region_name ORDER BY total_revenue DESC) as rank\n    FROM RegionSales\n)\nSELECT * \nFROM RankedSales \nWHERE rank <= 3;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical path string (e.g., 'CEO -> VP -> Manager') for every employee in an organization table containing 'id', 'name', and 'manager_id'.", "output": "WITH RECURSIVE EmployeePath AS (\n    -- Anchor member: employees with no manager (top level)\n    SELECT \n        id, \n        name, \n        manager_id, \n        name::TEXT AS hierarchy_path\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join subordinates to managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        ep.hierarchy_path || ' -> ' || e.name\n    FROM employees e\n    JOIN EmployeePath ep ON e.manager_id = ep.id\n)\nSELECT * FROM EmployeePath;"}
{"instruction": "Write a PostgreSQL query to identify customers who have purchased 'Product A' but have never purchased 'Product B' using NOT EXISTS.", "output": "SELECT DISTINCT c.customer_id, c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nWHERE oi.product_id = 'Product A'\nAND NOT EXISTS (\n    SELECT 1 \n    FROM orders o2\n    JOIN order_items oi2 ON o2.order_id = oi2.order_id\n    WHERE o2.customer_id = c.customer_id \n    AND oi2.product_id = 'Product B'\n);"}
{"instruction": "Calculate the 7-day moving average of daily active users using a window function with a frame clause.", "output": "SELECT \n    log_date,\n    daily_active_users,\n    AVG(daily_active_users) OVER (\n        ORDER BY log_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7d\nFROM daily_metrics\nORDER BY log_date;"}
{"instruction": "Write a database administration query for PostgreSQL to list the top 5 largest tables in the current database, including their total size on disk (indexes included), formatted neatly.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 5;"}
{"instruction": "Perform a 'gap analysis' to find missing sequence numbers in a table 'invoices' with column 'invoice_id' ranging from 1 to the maximum ID found in the table.", "output": "SELECT s.i AS missing_id\nFROM generate_series(1, (SELECT MAX(invoice_id) FROM invoices)) s(i)\nLEFT JOIN invoices inv ON s.i = inv.invoice_id\nWHERE inv.invoice_id IS NULL;"}
{"instruction": "Write a PostgreSQL query to pivot monthly sales data into columns (January, February, March) for the current year using the FILTER clause.", "output": "SELECT \n    product_category,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY product_category;"}
{"instruction": "Implement a 'Sessionization' query. Group user clickstream events into sessions where a new session starts if there is a gap of more than 30 minutes between events.", "output": "WITH LaggedEvents AS (\n    SELECT \n        user_id, \n        event_timestamp,\n        LAG(event_timestamp) OVER (PARTITION BY user_id ORDER BY event_timestamp) AS prev_timestamp\n    FROM user_events\n),\nNewSessionFlags AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        CASE \n            WHEN prev_timestamp IS NULL OR EXTRACT(EPOCH FROM (event_timestamp - prev_timestamp)) > 1800 \n            THEN 1 ELSE 0 \n        END AS is_new_session\n    FROM LaggedEvents\n)\nSELECT \n    user_id,\n    event_timestamp,\n    SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY event_timestamp) AS session_id\nFROM NewSessionFlags;"}
{"instruction": "Write a DBA query to identify currently blocking queries and the queries waiting to be executed in PostgreSQL.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query AS blocked_statement,\n    blocking_activity.query AS blocking_statement\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Update the price of products by 10%, but only for products belonging to categories where the average product price is greater than 500. Use UPDATE with a JOIN/FROM clause.", "output": "UPDATE products p\nSET price = price * 1.10\nFROM (\n    SELECT category_id\n    FROM products\n    GROUP BY category_id\n    HAVING AVG(price) > 500\n) expensive_cats\nWHERE p.category_id = expensive_cats.category_id;"}
{"instruction": "Write a Recursive CTE to generate a hierarchical organization chart showing the path from the top-level manager down to every employee.", "output": "WITH RECURSIVE org_chart AS (\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        name::TEXT as path,\n        1 as level\n    FROM employees \n    WHERE manager_id IS NULL\n    \n    UNION ALL\n    \n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        o.path || ' -> ' || e.name,\n        o.level + 1\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Identify the top 3 highest-paid employees in each department using window functions, handling ties with DENSE_RANK.", "output": "WITH ranked_employees AS (\n    SELECT \n        department_id, \n        name, \n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT * \nFROM ranked_employees \nWHERE rank <= 3;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for the current year.", "output": "SELECT \n    sale_date, \n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7d\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "Solve the 'Gaps and Islands' problem to find consecutive login streaks for users.", "output": "WITH dates AS (\n    SELECT DISTINCT user_id, login_date\n    FROM user_logins\n),\ngrouped_dates AS (\n    SELECT \n        user_id, \n        login_date,\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM dates\n)\nSELECT \n    user_id, \n    MIN(login_date) as streak_start, \n    MAX(login_date) as streak_end, \n    COUNT(*) as streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_days DESC;"}
{"instruction": "Use a LATERAL join to retrieve the 5 most recent orders for every customer who has signed up in the last month.", "output": "SELECT \n    c.customer_id, \n    c.name, \n    o.order_id, \n    o.order_date, \n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders \n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 5\n) o\nWHERE c.signup_date >= CURRENT_DATE - INTERVAL '1 month';"}
{"instruction": "Perform a Pivot (Crosstab) manually using conditional aggregation to show total sales per product category for Q1 (Jan, Feb, Mar).", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nGROUP BY category_name;"}
{"instruction": "PostgreSQL Administration: List all tables in the current database along with their total size (including indexes) in a human-readable format.", "output": "SELECT\n    schemaname as schema,\n    relname as table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) as total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "PostgreSQL Administration: Identify currently active queries that have been running for more than 5 minutes.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    query_start, \n    now() - query_start as duration, \n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND now() - query_start > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Delete duplicate rows from a table based on the 'email' column, keeping only the row with the lowest ID.", "output": "DELETE FROM users\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY id ASC) as row_num\n        FROM users\n    ) t\n    WHERE t.row_num > 1\n);"}
{"instruction": "Query a JSONB column to unnest an array of objects and filter results where a specific key's value exceeds a threshold.", "output": "SELECT \n    order_id,\n    elem->>'product_name' as product,\n    (elem->>'price')::numeric as price\nFROM orders,\nLATERAL jsonb_array_elements(order_details->'items') as elem\nWHERE (elem->>'price')::numeric > 100;"}
{"instruction": "Write a Recursive CTE to traverse an employee hierarchy (adjacency list model) to find the management chain for a specific employee ID, including the depth level.", "output": "WITH RECURSIVE management_chain AS (\n    -- Anchor member: start with the specific employee\n    SELECT \n        employee_id, \n        manager_id, \n        full_name,\n        0 AS depth\n    FROM employees\n    WHERE employee_id = 105\n\n    UNION ALL\n\n    -- Recursive member: join to the manager\n    SELECT \n        e.employee_id, \n        e.manager_id, \n        e.full_name,\n        mc.depth + 1\n    FROM employees e\n    INNER JOIN management_chain mc ON e.employee_id = mc.manager_id\n)\nSELECT * FROM management_chain;"}
{"instruction": "Calculate the 7-day rolling average of daily sales for each product using a Window Function, handling gaps in dates if necessary by assuming rows exist for every day.", "output": "SELECT \n    sale_date,\n    product_id,\n    daily_sales,\n    AVG(daily_sales) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS rolling_7_day_avg\nFROM daily_product_sales\nORDER BY product_id, sale_date;"}
{"instruction": "Identify the top 3 highest-paid employees within each department. If there is a tie in salary, the ranking should not skip numbers (use DENSE_RANK).", "output": "WITH ranked_employees AS (\n    SELECT \n        employee_id,\n        department_id,\n        salary,\n        DENSE_RANK() OVER (\n            PARTITION BY department_id \n            ORDER BY salary DESC\n        ) as rank_in_dept\n    FROM employees\n)\nSELECT * \nFROM ranked_employees\nWHERE rank_in_dept <= 3;"}
{"instruction": "Perform a 'Gap Analysis' to find missing sequence numbers in the 'invoice_id' column of the 'invoices' table.", "output": "SELECT \n    invoice_id + 1 AS gap_start,\n    next_id - 1 AS gap_end\nFROM (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) AS next_id\n    FROM invoices\n) sub\nWHERE next_id > invoice_id + 1;"}
{"instruction": "Pivot a sales table (columns: month, category, amount) to display categories as columns and months as rows using standard SQL (CASE statements).", "output": "SELECT \n    DATE_TRUNC('month', sale_date) AS sales_month,\n    SUM(CASE WHEN category = 'Electronics' THEN amount ELSE 0 END) AS electronics_sales,\n    SUM(CASE WHEN category = 'Clothing' THEN amount ELSE 0 END) AS clothing_sales,\n    SUM(CASE WHEN category = 'Home' THEN amount ELSE 0 END) AS home_sales\nFROM sales\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Use a LATERAL JOIN to retrieve the most recent 3 comments for every blog post without using a correlated subquery in the SELECT clause.", "output": "SELECT \n    p.post_id,\n    p.title,\n    r.comment_text,\n    r.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments c\n    WHERE c.post_id = p.post_id\n    ORDER BY c.created_at DESC\n    LIMIT 3\n) r;"}
{"instruction": "DBA Task: List all tables in the current PostgreSQL database along with their total size (including indexes), formatted in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "DBA Task: Identify currently running queries that have been active for more than 5 minutes, excluding idle connections.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle'\n  AND now() - query_start > interval '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Extract data from a JSONB column 'attributes' to find all products colored 'Red' and aggregate their stock count.", "output": "SELECT \n    attributes ->> 'color' AS product_color,\n    SUM((attributes ->> 'stock_count')::INT) AS total_stock\nFROM products\nWHERE attributes @> '{\"color\": \"Red\"}'\nGROUP BY attributes ->> 'color';"}
{"instruction": "Delete duplicate rows from a table 'user_logs' based on 'user_id' and 'log_timestamp', keeping only the row with the lowest internal ID (ctid).", "output": "DELETE FROM user_logs\nWHERE ctid NOT IN (\n    SELECT MIN(ctid)\n    FROM user_logs\n    GROUP BY user_id, log_timestamp\n);"}
{"instruction": "Write a recursive Common Table Expression (CTE) query to generate a hierarchical view of an organization. The table 'employees' has columns 'id', 'name', and 'manager_id'. The output should show the employee's name, their level in the hierarchy (1 for top-level managers), and a path string showing the reporting chain (e.g., 'CEO > VP > Manager').", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Top-level managers (no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 AS level,\n        name::TEXT AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the previous level\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' > ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Write a query to find the top 3 highest-paid employees in each department. Use a window function to handle ties appropriately (if two people have the same salary, they should share the rank, and the next rank should skip numbers, i.e., use RANK()).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        name,\n        salary,\n        RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank\n    FROM employees\n)\nSELECT \n    department_id,\n    name,\n    salary\nFROM RankedSalaries\nWHERE salary_rank <= 3;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product. The output should include the date, product_id, daily sales, and the moving average rounded to 2 decimal places.", "output": "SELECT \n    sale_date,\n    product_id,\n    daily_sales,\n    ROUND(\n        AVG(daily_sales) OVER (\n            PARTITION BY product_id \n            ORDER BY sale_date \n            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n        ), 2\n    ) AS moving_avg_7_days\nFROM product_sales\nORDER BY product_id, sale_date;"}
{"instruction": "Write a PostgreSQL administration query to identify currently active queries that have been running for more than 5 minutes, excluding the query you are currently running.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) as duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND query_start < clock_timestamp() - INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Perform a 'Gap Analysis' on a table named 'invoices' with a sequential integer column 'invoice_num'. Identify missing invoice numbers in the sequence between the minimum and maximum existing invoice numbers.", "output": "SELECT \n    s.i AS missing_invoice_num\nFROM generate_series(\n    (SELECT MIN(invoice_num) FROM invoices), \n    (SELECT MAX(invoice_num) FROM invoices)\n) s(i)\nWHERE NOT EXISTS (\n    SELECT 1 FROM invoices WHERE invoice_num = s.i\n);"}
{"instruction": "Write a query using PostgreSQL JSONB operators. Given a table 'orders' with a JSONB column 'metadata', find all orders where the customer bought a 'Laptop' (contained within a 'items' JSON array) and the total order weight (key 'weight' in JSON) is greater than 5.", "output": "SELECT \n    order_id, \n    metadata\nFROM orders\nWHERE \n    metadata @> '{\"items\": [\"Laptop\"]}' \n    AND (metadata ->> 'weight')::NUMERIC > 5;"}
{"instruction": "Pivot a table 'monthly_revenue' (columns: year, month, revenue) to display years as rows and months as columns (Jan, Feb, Mar) with the total revenue for each.", "output": "SELECT \n    year,\n    SUM(CASE WHEN month = 'Jan' THEN revenue ELSE 0 END) AS Jan_Revenue,\n    SUM(CASE WHEN month = 'Feb' THEN revenue ELSE 0 END) AS Feb_Revenue,\n    SUM(CASE WHEN month = 'Mar' THEN revenue ELSE 0 END) AS Mar_Revenue\nFROM monthly_revenue\nGROUP BY year\nORDER BY year;"}
{"instruction": "Write an 'Upsert' query (Insert on Conflict) for a 'user_preferences' table. Try to insert a new preference for a user. If the (user_id, pref_key) unique constraint conflicts, update the 'pref_value' and set 'updated_at' to the current timestamp instead.", "output": "INSERT INTO user_preferences (user_id, pref_key, pref_value, updated_at)\nVALUES (101, 'theme', 'dark', NOW())\nON CONFLICT (user_id, pref_key) \nDO UPDATE SET \n    pref_value = EXCLUDED.pref_value,\n    updated_at = NOW();"}
{"instruction": "Write a query to identify duplicate rows in a 'contacts' table based on 'email' and 'phone', keeping only the entry with the lowest 'id'.", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email, phone ORDER BY id ASC) as r_num\n        FROM contacts\n    ) t\n    WHERE t.r_num > 1\n);"}
{"instruction": "Write a DBA query to find unused indexes in the current PostgreSQL database to help optimize storage and write performance.", "output": "SELECT \n    schemaname || '.' || relname AS table_name,\n    indexrelname AS index_name,\n    idx_scan AS index_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0 \n  AND indisunique IS FALSE\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to calculate the cumulative (running) total of sales for each salesperson, ordered by sale date.", "output": "WITH SalesData AS (\n    SELECT \n        salesperson_id,\n        sale_date,\n        sale_amount\n    FROM sales\n)\nSELECT \n    salesperson_id,\n    sale_date,\n    sale_amount,\n    SUM(sale_amount) OVER (\n        PARTITION BY salesperson_id \n        ORDER BY sale_date\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ) as running_total\nFROM SalesData\nORDER BY salesperson_id, sale_date;"}
{"instruction": "Create a Recursive CTE to generate an organizational hierarchy chart showing the path from the top manager down to every employee.", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as hierarchy_path,\n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        o.hierarchy_path || ' -> ' || e.name,\n        o.level + 1\n    FROM employees e\n    INNER JOIN OrgChart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM OrgChart\nORDER BY hierarchy_path;"}
{"instruction": "Write a query to find the top 3 highest-paid employees in each department. Handle ties by including all employees with the same salary rank (use DENSE_RANK).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (\n            PARTITION BY department_id \n            ORDER BY salary DESC\n        ) as rank_num\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM RankedSalaries\nWHERE rank_num <= 3\nORDER BY department_id, rank_num;"}
{"instruction": "Use a PostgreSQL specific `CROSS JOIN LATERAL` to find the most recent order for every customer without using a correlated subquery in the SELECT clause or a Window function.", "output": "SELECT \n    c.customer_name,\n    l.order_date,\n    l.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_date, total_amount\n    FROM orders o\n    WHERE o.customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 1\n) l;"}
{"instruction": "Write a query to calculate a 7-day moving average of daily website visits using Window Functions.", "output": "SELECT \n    visit_date,\n    daily_visits,\n    AVG(daily_visits) OVER (\n        ORDER BY visit_date\n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_average_7_days\nFROM web_traffic\nORDER BY visit_date;"}
{"instruction": "Perform a gap analysis using `generate_series` to find all dates in the current month where no orders were placed.", "output": "SELECT \n    calendar_date::date\nFROM generate_series(\n    DATE_TRUNC('month', CURRENT_DATE),\n    DATE_TRUNC('month', CURRENT_DATE) + INTERVAL '1 month' - INTERVAL '1 day',\n    INTERVAL '1 day'\n) AS calendar_date\nLEFT JOIN orders o ON o.order_date = calendar_date::date\nWHERE o.order_id IS NULL;"}
{"instruction": "Write a query to pivot a table of monthly sales data so that months become columns (Jan, Feb, Mar) for each product using conditional aggregation.", "output": "SELECT \n    product_id,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 1 THEN amount ELSE 0 END) AS Jan_Sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 2 THEN amount ELSE 0 END) AS Feb_Sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 3 THEN amount ELSE 0 END) AS Mar_Sales\nFROM sales\nWHERE sale_date BETWEEN '2023-01-01' AND '2023-03-31'\nGROUP BY product_id;"}
{"instruction": "Database Administration: Write a query to list the top 10 largest tables in the current PostgreSQL database, showing both table size and total size (including indexes), formatted in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_relation_size(C.oid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(C.oid)) AS total_size\nFROM pg_class C\nLEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)\nWHERE nspname NOT IN ('pg_catalog', 'information_schema')\nAND C.relkind <> 'i'\nAND nspname !~ '^pg_toast'\nORDER BY pg_total_relation_size(C.oid) DESC\nLIMIT 10;"}
{"instruction": "Write a query to delete duplicate rows from a table based on a specific column (e.g., email), keeping only the entry with the highest ID.", "output": "DELETE FROM users\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (\n                PARTITION BY email \n                ORDER BY id DESC\n            ) as row_num\n        FROM users\n    ) t\n    WHERE t.row_num > 1\n);"}
{"instruction": "Database Administration: Identify currently active queries that have been running for more than 5 minutes.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \nAND now() - query_start > interval '5 minutes' \nORDER BY duration DESC;"}
{"instruction": "Write a query using a Recursive CTE to generate an organizational chart path (e.g., 'CEO -> VP -> Manager -> Employee') for every employee in the 'employees' table.", "output": "WITH RECURSIVE org_path AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        op.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_path op ON e.manager_id = op.employee_id\n)\nSELECT * FROM org_path ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue, ordered by date.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) :: NUMERIC(10,2) AS moving_avg_7_days\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Identify 'islands' of consecutive login days for users to determine current login streaks. Return the user_id, start date of the streak, end date of the streak, and the length of the streak.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Find the top 3 most recent orders for every customer using a LATERAL join for performance optimization (PostgreSQL specific).", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT \n        order_id, \n        order_date, \n        total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Perform a gap analysis to find all dates in the current month where no sales occurred. Use PostgreSQL's generate_series function.", "output": "SELECT \n    calendar_date::DATE as missing_date\nFROM \n    generate_series(\n        DATE_TRUNC('month', CURRENT_DATE), \n        DATE_TRUNC('month', CURRENT_DATE) + INTERVAL '1 month' - INTERVAL '1 day',\n        INTERVAL '1 day'\n    ) as calendar_date\nLEFT JOIN sales s ON s.sale_date = calendar_date::DATE\nWHERE s.sale_date IS NULL;"}
{"instruction": "Write a database administration query to list the top 10 largest tables in the current database, including their associated indexes, formatted in a human-readable size (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot monthly sales data from rows to columns (Jan, Feb, Mar, etc.) for the current year using conditional aggregation.", "output": "SELECT \n    product_id,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 1 THEN amount ELSE 0 END) AS jan_sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 2 THEN amount ELSE 0 END) AS feb_sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 3 THEN amount ELSE 0 END) AS mar_sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 4 THEN amount ELSE 0 END) AS apr_sales\n    -- Continue for remaining months...\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY product_id;"}
{"instruction": "Rank employees by salary within their respective departments, but also calculate the difference between an employee's salary and the department's average salary.", "output": "SELECT \n    employee_id,\n    department_id,\n    salary,\n    RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_in_dept,\n    salary - AVG(salary) OVER (PARTITION BY department_id) as diff_from_avg\nFROM employees;"}
{"instruction": "Identify currently active queries that have been running for more than 5 minutes to detect potential performance bottlenecks or locks.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) as duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle' \n  AND age(clock_timestamp(), query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Parse a JSONB column named 'attributes' to count the frequency of specific keys (tags) across all products.", "output": "SELECT \n    tag,\n    COUNT(*) as frequency\nFROM products,\nLATERAL jsonb_array_elements_text(attributes->'tags') as tag\nGROUP BY tag\nORDER BY frequency DESC;"}
{"instruction": "Write a Recursive CTE to generate a hierarchical view of employees. The output should show the employee's name, their manager's name, and their 'level' in the organization (depth), starting from the CEO (where manager_id is NULL).", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the hierarchy with employees reporting to the previous level\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        eh.level + 1,\n        eh.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM EmployeeHierarchy\nORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for each product category using Window Functions. The result should include the date, category, daily revenue, and the moving average.", "output": "SELECT \n    sale_date,\n    category,\n    revenue,\n    AVG(revenue) OVER (\n        PARTITION BY category \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nORDER BY category, sale_date;"}
{"instruction": "Identify 'Churn Risk' users. Find users who have placed at least 5 orders in the past but have not placed any orders in the last 6 months. Use a complex join strategy or set operations.", "output": "SELECT \n    u.user_id,\n    u.email,\n    COUNT(o.order_id) as total_past_orders,\n    MAX(o.order_date) as last_order_date\nFROM users u\nJOIN orders o ON u.user_id = o.user_id\nGROUP BY u.user_id, u.email\nHAVING \n    COUNT(o.order_id) >= 5\n    AND MAX(o.order_date) < CURRENT_DATE - INTERVAL '6 months';"}
{"instruction": "Solve the 'Gaps and Islands' problem. Given a table of user login dates, identify streaks of consecutive days a user logged in. Return the user_id, start_date, end_date, and the length of the streak.", "output": "WITH GroupedLogins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        -- Consecutive dates will result in the same 'group_id' date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS group_id\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_days\nFROM GroupedLogins\nGROUP BY user_id, group_id\nORDER BY user_id, streak_start;"}
{"instruction": "Use a LATERAL JOIN (PostgreSQL specific) to retrieve the top 3 most expensive products for every specific supplier efficiently, without using a subquery in the SELECT clause.", "output": "SELECT \n    s.supplier_name,\n    p.product_name,\n    p.price\nFROM suppliers s\nCROSS JOIN LATERAL (\n    SELECT product_name, price\n    FROM products\n    WHERE supplier_id = s.supplier_id\n    ORDER BY price DESC\n    LIMIT 3\n) p;"}
{"instruction": "Perform a Pivot (Crosstab) manually using conditional aggregation to show total sales per month (Jan-Dec) for the current year, with one row per sales representative.", "output": "SELECT \n    sales_rep_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    -- ... continue for months 4 through 11 ...\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 12) AS dec_sales,\n    SUM(amount) AS total_annual_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY sales_rep_id;"}
{"instruction": "Database Administration: Write a query to identify unused indexes in a PostgreSQL database. This helps in cleaning up the database to improve write performance and save storage.", "output": "SELECT \n    schemaname || '.' || relname AS table_name,\n    indexrelname AS index_name,\n    idx_scan AS index_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0 -- Index has never been used for scanning\nAND indexrelname NOT LIKE '%_pkey' -- Exclude primary keys\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Perform an 'Upsert' (Insert or Update). Insert a new inventory record for a product. If the product_id already exists, update the quantity by adding the new amount to the existing stock and update the last_restock_date.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_restock_date)\nVALUES (105, 1, 50, CURRENT_DATE)\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_restock_date = EXCLUDED.last_restock_date;"}
{"instruction": "Parse JSONB data in PostgreSQL. Given a table 'events' with a JSONB column 'payload', find all events where the payload contains a specific key-value pair (e.g., 'action': 'click') and expand a nested JSON array 'tags' into separate rows.", "output": "SELECT \n    event_id,\n    payload ->> 'user_id' AS user_id,\n    jsonb_array_elements_text(payload -> 'tags') AS tag\nFROM events\nWHERE payload @> '{\"action\": \"click\"}' -- Efficient containment check using GIN index\nAND payload -> 'tags' IS NOT NULL;"}
{"instruction": "Database Administration: List the top 10 largest tables in the current database, including the size of their associated indexes and toast data.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_toast_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and window functions to identify the top 3 sales representatives by revenue for each region. The output should include the region, rank, sales representative's name, and total revenue.", "output": "WITH RegionalSales AS (\n    SELECT \n        r.region_name,\n        s.rep_name,\n        SUM(o.amount) as total_revenue\n    FROM sales_reps s\n    JOIN orders o ON s.id = o.rep_id\n    JOIN regions r ON s.region_id = r.id\n    GROUP BY r.region_name, s.rep_name\n)\nSELECT \n    region_name,\n    RANK() OVER (PARTITION BY region_name ORDER BY total_revenue DESC) as rank,\n    rep_name,\n    total_revenue\nFROM RegionalSales\nWHERE RANK() OVER (PARTITION BY region_name ORDER BY total_revenue DESC) <= 3;"}
{"instruction": "Create a Recursive CTE to traverse an employee organizational hierarchy. Given an 'employees' table with 'id', 'name', and 'manager_id', return a list of all subordinates (direct and indirect) under a specific manager with ID 1, including their depth in the hierarchy.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select the manager\n    SELECT \n        id, \n        name, \n        manager_id, \n        0 as hierarchy_level\n    FROM employees\n    WHERE id = 1\n    \n    UNION ALL\n    \n    -- Recursive member: join to find subordinates\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oc.hierarchy_level + 1\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.id\n)\nSELECT * FROM org_chart;"}
{"instruction": "Calculate the 7-day moving average of daily active users (DAU) using a window function. The table 'user_logins' contains 'login_date' and 'user_id'.", "output": "WITH daily_counts AS (\n    SELECT \n        login_date,\n        COUNT(DISTINCT user_id) as daily_users\n    FROM user_logins\n    GROUP BY login_date\n)\nSELECT \n    login_date,\n    daily_users,\n    AVG(daily_users) OVER (\n        ORDER BY login_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM daily_counts\nORDER BY login_date;"}
{"instruction": "Use a LATERAL join to retrieve the 3 most recent comments for every blog post. The schema consists of a 'posts' table and a 'comments' table.", "output": "SELECT \n    p.title,\n    recent_comments.comment_text,\n    recent_comments.created_at\nFROM posts p\nLEFT JOIN LATERAL (\n    SELECT \n        comment_text, \n        created_at\n    FROM comments c\n    WHERE c.post_id = p.id\n    ORDER BY created_at DESC\n    LIMIT 3\n) AS recent_comments ON true;"}
{"instruction": "Write a PostgreSQL DBA query to list all currently active queries that have been running for more than 5 minutes, including the username and the query text.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > interval '5 minutes';"}
{"instruction": "Solve the 'Gaps and Islands' problem to find consecutive login streaks. Identify periods where a user logged in every single day without a break.", "output": "WITH dates_grouped AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n    GROUP BY user_id, login_date\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM dates_grouped\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Generate a pivot table report summing total sales amount per category for the first quarter (Jan, Feb, Mar) using the PostgreSQL FILTER clause.", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) AS q1_total\nFROM sales\nWHERE sale_date BETWEEN '2023-01-01' AND '2023-03-31'\nGROUP BY category_name;"}
{"instruction": "Find customers who have purchased 'Product A' but have never purchased 'Product B' using the EXCEPT set operator.", "output": "SELECT customer_id \nFROM orders \nWHERE product_name = 'Product A'\nEXCEPT\nSELECT customer_id \nFROM orders \nWHERE product_name = 'Product B';"}
{"instruction": "Write a DBA query to check the total size (including indexes and toast data) of the 10 largest tables in the current PostgreSQL database.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Calculate the year-over-year growth percentage for monthly sales using the LAG window function.", "output": "WITH monthly_stats AS (\n    SELECT \n        DATE_TRUNC('month', sale_date) as sales_month,\n        SUM(amount) as revenue\n    FROM sales\n    GROUP BY 1\n)\nSELECT \n    sales_month,\n    revenue,\n    LAG(revenue, 12) OVER (ORDER BY sales_month) as prev_year_revenue,\n    ROUND(\n        ((revenue - LAG(revenue, 12) OVER (ORDER BY sales_month)) / \n        NULLIF(LAG(revenue, 12) OVER (ORDER BY sales_month), 0)) * 100, 2\n    ) as yoy_growth_percentage\nFROM monthly_stats;"}
{"instruction": "Write a recursive CTE query to generate a hierarchical view of employees, showing the employee's name, their manager's name, and their distance from the top-level hierarchy (level). Assume an 'employees' table with 'id', 'name', and 'manager_id'.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Top-level managers (no manager_id)\n    SELECT \n        id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as path, \n        1 as level\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        eh.path || ' -> ' || e.name,\n        eh.level + 1\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.id\n)\nSELECT * FROM employee_hierarchy ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product using window functions. The result should include the product_id, sale_date, daily_total, and moving_average.", "output": "SELECT \n    product_id,\n    sale_date,\n    daily_total,\n    AVG(daily_total) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_day\nFROM daily_sales_summary\nORDER BY product_id, sale_date;"}
{"instruction": "Identify 'Churned High-Value Customers'. Find customers who spent over $10,000 in total lifetime value but have not placed an order in the last 6 months.", "output": "WITH CustomerTotals AS (\n    SELECT \n        c.customer_id,\n        c.email,\n        SUM(o.total_amount) as lifetime_value,\n        MAX(o.order_date) as last_order_date\n    FROM customers c\n    JOIN orders o ON c.customer_id = o.customer_id\n    GROUP BY c.customer_id, c.email\n)\nSELECT \n    customer_id,\n    email,\n    lifetime_value,\n    last_order_date\nFROM CustomerTotals\nWHERE lifetime_value > 10000\n  AND last_order_date < CURRENT_DATE - INTERVAL '6 months';"}
{"instruction": "Perform a 'Gaps and Islands' analysis to find missing sequence numbers in the 'invoices' table where the 'invoice_id' is expected to be sequential.", "output": "SELECT \n    invoice_id + 1 AS gap_start,\n    next_id - 1 AS gap_end\nFROM (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) AS next_id\n    FROM invoices\n) sub\nWHERE next_id > invoice_id + 1;"}
{"instruction": "Create a pivot table view manually using conditional aggregation to show total sales per region (North, South, East, West) for each year.", "output": "SELECT \n    EXTRACT(YEAR FROM order_date) AS sales_year,\n    SUM(CASE WHEN region = 'North' THEN amount ELSE 0 END) AS north_sales,\n    SUM(CASE WHEN region = 'South' THEN amount ELSE 0 END) AS south_sales,\n    SUM(CASE WHEN region = 'East' THEN amount ELSE 0 END) AS east_sales,\n    SUM(CASE WHEN region = 'West' THEN amount ELSE 0 END) AS west_sales\nFROM regional_sales\nGROUP BY EXTRACT(YEAR FROM order_date)\nORDER BY sales_year;"}
{"instruction": "DBA Task: Write a query to list the top 10 largest tables in the PostgreSQL database, including the size of their indexes, formatted in a human-readable size (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Find the top 3 highest-paid employees in each department using DENSE_RANK to handle salary ties appropriately.", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM RankedSalaries\nWHERE rank_num <= 3;"}
{"instruction": "DBA Task: Identify currently running queries that have been active for more than 5 minutes, excluding idle connections.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state != 'idle' \n  AND now() - query_start > interval '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation. Insert a new user record, but if the email already exists, update the 'last_login' timestamp instead.", "output": "INSERT INTO users (username, email, last_login)\nVALUES ('jdoe', 'jdoe@example.com', NOW())\nON CONFLICT (email) \nDO UPDATE SET \n    last_login = EXCLUDED.last_login,\n    username = EXCLUDED.username;"}
{"instruction": "PostgreSQL JSONB: Select specific rows where a JSONB column 'attributes' contains a key 'color' set to 'red' and extract the 'size' property as a separate column.", "output": "SELECT \n    product_id,\n    product_name,\n    attributes ->> 'size' AS size\nFROM products\nWHERE attributes @> '{\"color\": \"red\"}';"}
{"instruction": "Write a query using a Recursive CTE to generate an organizational hierarchy chart. The table 'employees' contains 'id', 'name', and 'manager_id'. The output should show the employee name, their level in the hierarchy, and the path from the top-level manager to them.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select top-level managers (no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 AS level, \n        CAST(name AS TEXT) AS path\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        o.level + 1, \n        o.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Create a query to calculate the 7-day moving average of sales revenue per region, ordered by date. Use window functions.", "output": "SELECT \n    region,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY region \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM region_sales\nORDER BY region, sale_date;"}
{"instruction": "Write a PostgreSQL administration query to find the size of all tables in the current database, including indexes, and display them in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Use a LATERAL JOIN to find the top 3 most recent orders for every customer. The 'customers' table needs to be joined with the 'orders' table efficiently.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, amount\n    FROM orders\n    WHERE orders.customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Write a query to identify gaps in a time series. Given a table 'daily_logins', generate a list of dates within the current month where no logins were recorded. Use 'generate_series'.", "output": "WITH date_range AS (\n    SELECT generate_series(\n        DATE_TRUNC('month', CURRENT_DATE),\n        DATE_TRUNC('month', CURRENT_DATE) + INTERVAL '1 month' - INTERVAL '1 day',\n        INTERVAL '1 day'\n    )::DATE AS day\n)\nSELECT d.day\nFROM date_range d\nLEFT JOIN daily_logins l ON d.day = l.login_date\nWHERE l.login_date IS NULL\nORDER BY d.day;"}
{"instruction": "Create a query that pivots data using conditional aggregation (FILTER). Transform a table of 'monthly_sales' (product, month, amount) into a format with columns: Product, Jan_Sales, Feb_Sales, Mar_Sales.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS Jan_Sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS Feb_Sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS Mar_Sales\nFROM monthly_sales\nGROUP BY product_name\nORDER BY product_name;"}
{"instruction": "Write a query to find the top 3 highest-paid employees in each department. If there is a tie in salary, they should share the same rank, and the next rank should not be skipped (Dense Rank).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT * \nFROM RankedSalaries \nWHERE rank <= 3;"}
{"instruction": "Write a PostgreSQL query to identify currently active queries that have been running for more than 5 minutes, excluding the current session's query.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid()\nORDER BY duration DESC;"}
{"instruction": "Perform a complex update using a CTE. Update the 'customer_status' to 'VIP' for all customers who are in the top 10% of spenders based on the 'orders' table.", "output": "WITH TopSpenders AS (\n    SELECT customer_id\n    FROM (\n        SELECT \n            customer_id,\n            NTILE(10) OVER (ORDER BY SUM(total_amount) DESC) as percentile\n        FROM orders\n        GROUP BY customer_id\n    ) sub\n    WHERE percentile = 1\n)\nUPDATE customers\nSET customer_status = 'VIP'\nWHERE customer_id IN (SELECT customer_id FROM TopSpenders);"}
{"instruction": "Write a query to analyze session churn. Calculate the time difference (in days) between a user's current order and their previous order using LAG().", "output": "SELECT \n    user_id,\n    order_id,\n    order_date,\n    LAG(order_date) OVER (PARTITION BY user_id ORDER BY order_date) AS previous_order_date,\n    order_date - LAG(order_date) OVER (PARTITION BY user_id ORDER BY order_date) AS days_since_last_order\nFROM orders\nORDER BY user_id, order_date;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each store using Window Functions.", "output": "SELECT \n    store_id,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Use a Recursive CTE to generate a hierarchical view of employees and their managers, including the depth level of each employee in the organization.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Top-level managers (no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the hierarchy found so far\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        eh.level + 1,\n        eh.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy ORDER BY path;"}
{"instruction": "Identify 'Islands' of consecutive login days for users (Gap and Island problem) to find periods of continuous activity.", "output": "WITH grouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as start_date,\n    MAX(login_date) as end_date,\n    COUNT(*) as consecutive_days\nFROM grouped_logins\nGROUP BY user_id, grp\nHAVING COUNT(*) >= 3\nORDER BY user_id, start_date;"}
{"instruction": "Find the top 3 highest-paid employees in each department using `DENSE_RANK()`.", "output": "WITH ranked_employees AS (\n    SELECT \n        employee_id,\n        name,\n        department_id,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT * \nFROM ranked_employees \nWHERE rank <= 3;"}
{"instruction": "DBA Task: List the top 10 largest tables in a PostgreSQL database, including the size of indexes and TOAST data.", "output": "SELECT\n    schemaname as schema,\n    relname as table,\n    pg_size_pretty(pg_total_relation_size(relid)) as total_size,\n    pg_size_pretty(pg_relation_size(relid)) as data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) as external_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot monthly sales data from rows to columns (Cross-tabulation) for the year 2023 using standard SQL aggregation filters.", "output": "SELECT \n    product_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 4) AS apr_sales\n    -- ... continue for remaining months\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_id;"}
{"instruction": "Use a `LATERAL` join to retrieve the 3 most recent orders for every customer without using a correlated subquery in the SELECT clause.", "output": "SELECT \n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "DBA Task: Identify currently running queries that have been active for more than 5 minutes.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    age(clock_timestamp(), query_start) as duration,\n    query \nFROM pg_stat_activity \nWHERE state != 'idle' \n  AND query NOT ILIKE '%pg_stat_activity%'\n  AND query_start < clock_timestamp() - INTERVAL '5 minutes';"}
{"instruction": "Calculate the cumulative distribution and percentage contribution of revenue for each product within its category.", "output": "SELECT \n    category,\n    product_name,\n    revenue,\n    SUM(revenue) OVER (PARTITION BY category ORDER BY revenue DESC) as running_total,\n    SUM(revenue) OVER (PARTITION BY category) as category_total,\n    ROUND(\n        (revenue / SUM(revenue) OVER (PARTITION BY category)) * 100, \n        2\n    ) as percent_share_of_category\nFROM product_sales\nORDER BY category, revenue DESC;"}
{"instruction": "Find rows in `table_a` that do not have a matching key in `table_b` using `NOT EXISTS` (Anti-Join pattern).", "output": "SELECT a.*\nFROM table_a a\nWHERE NOT EXISTS (\n    SELECT 1 \n    FROM table_b b \n    WHERE b.foreign_key_id = a.id\n);"}
{"instruction": "Write a recursive CTE to generate a hierarchical view of employees, showing the path from the CEO (manager_id IS NULL) down to each employee, including their depth in the organization.", "output": "WITH RECURSIVE org_chart AS (\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS depth,\n        name::TEXT AS path\n    FROM employees\n    WHERE manager_id IS NULL\n    \n    UNION ALL\n    \n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.depth + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average and the running total of sales for each product, ordered by date.", "output": "SELECT \n    product_id,\n    sale_date,\n    daily_sales,\n    AVG(daily_sales) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days,\n    SUM(daily_sales) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date\n    ) AS running_total\nFROM product_sales\nORDER BY product_id, sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login data to find the longest consecutive streak of daily logins for each user.", "output": "WITH distinct_logins AS (\n    SELECT DISTINCT user_id, login_date::DATE \n    FROM user_logins\n),\ngroups AS (\n    SELECT \n        user_id,\n        login_date,\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM distinct_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_days\nFROM groups\nGROUP BY user_id, grp\nORDER BY streak_days DESC;"}
{"instruction": "Write a PostgreSQL administration query to list currently locked queries and the process IDs (PIDs) that are blocking them.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocked_activity.query AS blocked_query,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity \n    ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity \n    ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Use a LATERAL JOIN to retrieve the top 3 most recent orders for every customer, ensuring customers without orders are excluded.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Calculate the Month-Over-Month (MoM) percentage growth in revenue for the current year.", "output": "WITH monthly_revenue AS (\n    SELECT \n        DATE_TRUNC('month', payment_date) AS month,\n        SUM(amount) AS revenue\n    FROM payments\n    WHERE payment_date >= DATE_TRUNC('year', CURRENT_DATE)\n    GROUP BY 1\n)\nSELECT \n    month,\n    revenue,\n    LAG(revenue) OVER (ORDER BY month) AS prev_month_revenue,\n    ROUND(\n        ((revenue - LAG(revenue) OVER (ORDER BY month)) / NULLIF(LAG(revenue) OVER (ORDER BY month), 0)) * 100, \n        2\n    ) AS growth_percentage\nFROM monthly_revenue;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation: Insert a new inventory record, but if the product_id already exists, add the new quantity to the existing quantity.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_updated)\nVALUES (105, 2, 50, NOW())\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Find the top 10 largest tables in the PostgreSQL database, including the size of their indexes, formatted in a human-readable size.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot a table of student test scores (student_id, subject, score) so that each subject becomes a column (Math, Science, History) for each student.", "output": "SELECT \n    student_id,\n    MAX(CASE WHEN subject = 'Math' THEN score END) AS math_score,\n    MAX(CASE WHEN subject = 'Science' THEN score END) AS science_score,\n    MAX(CASE WHEN subject = 'History' THEN score END) AS history_score\nFROM test_scores\nGROUP BY student_id;"}
{"instruction": "Extract specific keys from a JSONB column containing user settings and filter for users who have 'dark_mode' enabled.", "output": "SELECT \n    user_id,\n    settings ->> 'theme' AS theme,\n    (settings ->> 'notifications_enabled')::BOOLEAN AS notifications\nFROM user_preferences\nWHERE settings @> '{\"dark_mode\": true}';"}
{"instruction": "Write a recursive CTE to generate a hierarchical view of employees, showing their level in the organization and path from the CEO (where manager_id is NULL) down to the specific employee.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        name::TEXT AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE to employees\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        (oc.path || ' -> ' || e.name)::TEXT\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales amounts using window functions, ensuring the window handles the first few days where 7 days of history don't exist yet.", "output": "SELECT \n    sale_date,\n    daily_total,\n    AVG(daily_total) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7d\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Find the top 3 highest-paid employees within each department. If there is a tie in salary, they should share the same rank, but the next rank should skip numbers (e.g., 1, 1, 3).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT * \nFROM RankedSalaries\nWHERE rank_num <= 3;"}
{"instruction": "DBA Task: Write a query to list the top 10 largest tables in the current PostgreSQL database, including both table data and index size, formatted in a human-readable size (e.g., MB, GB).", "output": "SELECT\n    schemaname AS schema,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL join to retrieve the 3 most recent orders for every customer who has signed up in the last month.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nWHERE c.signup_date >= NOW() - INTERVAL '1 month';"}
{"instruction": "Identify 'Gaps' in a sequence of invoice IDs. Assuming invoice_id should be sequential integers, find the start and end of any missing ranges.", "output": "WITH gaps AS (\n    SELECT \n        invoice_id + 1 AS gap_start,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) - 1 AS gap_end\n    FROM invoices\n)\nSELECT gap_start, gap_end\nFROM gaps\nWHERE gap_end >= gap_start;"}
{"instruction": "Perform an 'Upsert' (Update or Insert) operation. Insert a new inventory item, but if the item_id already exists, add the new quantity to the existing quantity instead.", "output": "INSERT INTO inventory (item_id, item_name, quantity, last_updated)\nVALUES (101, 'Widget A', 50, NOW())\nON CONFLICT (item_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Create a pivot-like report that lists every student and a single string containing all the courses they are enrolled in, separated by commas, ordered alphabetically by course name.", "output": "SELECT \n    s.student_name,\n    STRING_AGG(c.course_name, ', ' ORDER BY c.course_name) AS enrolled_courses\nFROM students s\nJOIN enrollments e ON s.student_id = e.student_id\nJOIN courses c ON e.course_id = c.course_id\nGROUP BY s.student_id, s.student_name;"}
{"instruction": "DBA Task: Identify currently active queries that have been running for more than 5 minutes, excluding the current query itself.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) as duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle'\n  AND pid <> pg_backend_pid()\n  AND query_start < clock_timestamp() - INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Analyze user retention by calculating the Month-over-Month retention rate. Calculate the percentage of users active in the previous month who also performed an action in the current month.", "output": "WITH monthly_active_users AS (\n    SELECT DISTINCT \n        user_id, \n        DATE_TRUNC('month', action_date) AS activity_month\n    FROM user_logs\n)\nSELECT \n    current_month.activity_month,\n    COUNT(DISTINCT current_month.user_id) AS active_users,\n    COUNT(DISTINCT previous_month.user_id) AS retained_users,\n    ROUND(\n        (COUNT(DISTINCT previous_month.user_id)::NUMERIC / NULLIF(COUNT(DISTINCT current_month.user_id), 0)) * 100, \n        2\n    ) AS retention_rate\nFROM monthly_active_users current_month\nLEFT JOIN monthly_active_users previous_month \n    ON current_month.user_id = previous_month.user_id \n    AND previous_month.activity_month = current_month.activity_month - INTERVAL '1 month'\nGROUP BY current_month.activity_month\nORDER BY current_month.activity_month;"}
{"instruction": "Write a recursive CTE to generate an organizational hierarchy chart showing the path from the top-level manager down to each employee.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        name::TEXT as path,\n        1 as level\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        o.path || ' -> ' || e.name,\n        o.level + 1\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales and the running total of sales for the current year using window functions.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days,\n    SUM(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ) as running_total_ytd\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "Identify 'Islands' of consecutive login days for users. Return the user_id, start_date, end_date, and count of consecutive days.", "output": "WITH dated_logins AS (\n    SELECT DISTINCT user_id, login_date FROM user_logins\n),\ngrouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM dated_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as start_date,\n    MAX(login_date) as end_date,\n    COUNT(*) as consecutive_days\nFROM grouped_logins\nGROUP BY user_id, grp\nHAVING COUNT(*) > 1\nORDER BY user_id, start_date;"}
{"instruction": "PostgreSQL DBA Task: Find the top 10 largest tables in the database, including their index size, displaying the output in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL JOIN to find the top 3 most recent orders for every customer who has placed an order in the last month, without using a subquery in the SELECT clause.", "output": "SELECT \n    c.customer_id, \n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nWHERE EXISTS (\n    SELECT 1 FROM orders check_ord \n    WHERE check_ord.customer_id = c.customer_id \n    AND check_ord.order_date >= NOW() - INTERVAL '1 month'\n);"}
{"instruction": "Perform a Cohort Analysis to calculate Month 1 Retention. (Percentage of users who signed up in Month 0 and were active in Month 1).", "output": "WITH monthly_activity AS (\n    SELECT \n        user_id, \n        DATE_TRUNC('month', activity_date) as activity_month\n    FROM user_logs\n    GROUP BY 1, 2\n),\ncohorts AS (\n    SELECT \n        user_id, \n        DATE_TRUNC('month', signup_date) as cohort_month\n    FROM users\n)\nSELECT \n    c.cohort_month,\n    COUNT(DISTINCT c.user_id) as new_users,\n    COUNT(DISTINCT ma.user_id) as retained_users,\n    ROUND(COUNT(DISTINCT ma.user_id)::NUMERIC / COUNT(DISTINCT c.user_id), 2) as retention_rate\nFROM cohorts c\nLEFT JOIN monthly_activity ma \n    ON c.user_id = ma.user_id \n    AND ma.activity_month = c.cohort_month + INTERVAL '1 month'\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "PostgreSQL DBA Task: Identify currently running queries that are being blocked by other transactions, showing the blocking PID and the blocked query.", "output": "SELECT\n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Use the FILTER clause (PostgreSQL specific pivot) to aggregate sales data, creating columns for 'Electronics', 'Clothing', and 'Home' sales per region in a single query.", "output": "SELECT \n    region,\n    SUM(amount) FILTER (WHERE category = 'Electronics') AS electronics_sales,\n    SUM(amount) FILTER (WHERE category = 'Clothing') AS clothing_sales,\n    SUM(amount) FILTER (WHERE category = 'Home') AS home_sales,\n    SUM(amount) AS total_sales\nFROM sales\nGROUP BY region\nORDER BY total_sales DESC;"}
{"instruction": "Find duplicate records based on specific columns (email and username) and generate a DELETE statement to remove all but the oldest record for each duplicate set.", "output": "DELETE FROM users\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (\n                PARTITION BY email, username \n                ORDER BY created_at ASC\n            ) as row_num\n        FROM users\n    ) t\n    WHERE t.row_num > 1\n);"}
{"instruction": "Perform a Full Outer Join to reconcile inventory between a database table and a provided shipment list, handling NULLs with COALESCE to show the final status of all items.", "output": "SELECT \n    COALESCE(db.product_id, ship.product_id) as product_id,\n    COALESCE(db.product_name, ship.product_name) as product_name,\n    db.quantity as stock_quantity,\n    ship.quantity as shipment_quantity,\n    CASE \n        WHEN db.product_id IS NULL THEN 'New Item'\n        WHEN ship.product_id IS NULL THEN 'No Shipment'\n        WHEN db.quantity != ship.quantity THEN 'Mismatch'\n        ELSE 'Match'\n    END as status\nFROM inventory_stock db\nFULL OUTER JOIN incoming_shipment ship \n    ON db.product_id = ship.product_id;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to identify the top 3 highest-earning employees within each department.", "output": "WITH RankedEmployees AS (\n    SELECT \n        employee_id,\n        first_name,\n        last_name,\n        department_id,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT \n    employee_id,\n    first_name,\n    last_name,\n    department_id,\n    salary\nFROM RankedEmployees\nWHERE rank <= 3;"}
{"instruction": "Create a recursive CTE to generate a hierarchical view of employees and their managers, showing the employee name, manager name, and their level in the hierarchy (depth).", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Top level managers (no manager)\n    SELECT \n        employee_id, \n        first_name || ' ' || last_name as employee_name,\n        manager_id,\n        NULL::text as manager_name,\n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member\n    SELECT \n        e.employee_id,\n        e.first_name || ' ' || e.last_name,\n        e.manager_id,\n        o.employee_name,\n        o.level + 1\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM org_chart ORDER BY level, manager_id;"}
{"instruction": "Write a PostgreSQL administrative query to check the size of all tables in the 'public' schema, displaying the table name, exact size, and a human-readable size format, ordered by size descending.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_total_relation_size(relid) AS size_bytes\nFROM pg_catalog.pg_statio_user_tables\nWHERE schemaname = 'public'\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue using a Window Function.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_days\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Identify 'Churned' customers using a complex LEFT JOIN and aggregation. A churned customer is defined as someone who has placed an order in the past but has not placed any orders in the last 6 months.", "output": "SELECT \n    c.customer_id,\n    c.email,\n    MAX(o.order_date) as last_order_date\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nGROUP BY c.customer_id, c.email\nHAVING MAX(o.order_date) < CURRENT_DATE - INTERVAL '6 months';"}
{"instruction": "Write a query to identify gaps in a sequence of Invoice IDs (e.g., if IDs are 1, 2, 4, 5, find that 3 is missing) using the LEAD window function.", "output": "WITH SequenceCheck AS (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) as next_invoice_id\n    FROM invoices\n)\nSELECT \n    invoice_id + 1 as missing_start,\n    next_invoice_id - 1 as missing_end\nFROM SequenceCheck\nWHERE next_invoice_id - invoice_id > 1;"}
{"instruction": "Perform a 'Sessionization' analysis. Group user events into sessions where a new session starts if there is a gap of more than 30 minutes between consecutive events for the same user.", "output": "WITH LaggedEvents AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        LAG(event_timestamp) OVER (PARTITION BY user_id ORDER BY event_timestamp) as prev_timestamp\n    FROM user_events\n),\nNewSessionFlags AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        CASE \n            WHEN prev_timestamp IS NULL OR event_timestamp > prev_timestamp + INTERVAL '30 minutes' THEN 1 \n            ELSE 0 \n        END as is_new_session\n    FROM LaggedEvents\n)\nSELECT \n    user_id,\n    event_timestamp,\n    SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY event_timestamp) as session_id\nFROM NewSessionFlags;"}
{"instruction": "Use a FULL OUTER JOIN to compare inventory lists from two different warehouses (A and B) to find products unique to A, unique to B, and those with conflicting stock quantities.", "output": "SELECT \n    COALESCE(a.product_id, b.product_id) as product_id,\n    a.stock_qty as warehouse_a_stock,\n    b.stock_qty as warehouse_b_stock,\n    CASE \n        WHEN a.product_id IS NULL THEN 'Unique to B'\n        WHEN b.product_id IS NULL THEN 'Unique to A'\n        WHEN a.stock_qty != b.stock_qty THEN 'Quantity Mismatch'\n        ELSE 'Match'\n    END as status\nFROM warehouse_a_inventory a\nFULL OUTER JOIN warehouse_b_inventory b ON a.product_id = b.product_id\nWHERE a.stock_qty IS DISTINCT FROM b.stock_qty;"}
{"instruction": "Write a PostgreSQL administrative query to detect currently blocked queries (locks) and the Process ID (PID) that is blocking them.", "output": "SELECT \n    pid,\n    usename,\n    pg_blocking_pids(pid) as blocked_by_pids,\n    query as blocked_query,\n    state,\n    age(clock_timestamp(), query_start) as duration\nFROM pg_stat_activity\nWHERE cardinality(pg_blocking_pids(pid)) > 0;"}
{"instruction": "Pivot a table of product attributes (Entity-Attribute-Value pattern) into a JSON object per product using PostgreSQL specific JSON aggregation functions.", "output": "SELECT \n    product_id,\n    jsonb_object_agg(attribute_name, attribute_value) as attributes_json\nFROM product_attributes\nGROUP BY product_id;"}
{"instruction": "Write a query to calculate the cumulative running total of sales for each salesperson, ordered by the sale date.", "output": "SELECT \n    salesperson_id,\n    sale_date,\n    sale_amount,\n    SUM(sale_amount) OVER (\n        PARTITION BY salesperson_id \n        ORDER BY sale_date\n    ) AS running_total\nFROM sales_data;"}
{"instruction": "Create a Recursive CTE to generate an organizational hierarchy chart showing the employee name, their manager, and their depth level in the organization.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Top level managers (no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the previous level\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY level, manager_id;"}
{"instruction": "Write a query to identify 'gaps' in a sequence of invoice IDs (e.g., finding missing invoice numbers).", "output": "WITH prev_next AS (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) AS next_invoice_id\n    FROM invoices\n)\nSELECT \n    invoice_id + 1 AS gap_start,\n    next_invoice_id - 1 AS gap_end\nFROM prev_next\nWHERE next_invoice_id - invoice_id > 1;"}
{"instruction": "Calculate the 7-day moving average of stock prices for each ticker symbol.", "output": "SELECT \n    ticker,\n    date,\n    close_price,\n    AVG(close_price) OVER (\n        PARTITION BY ticker \n        ORDER BY date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7d\nFROM stock_prices;"}
{"instruction": "PostgreSQL DBA Task: List the top 5 largest tables in the database, including the size of their associated indexes, formatted in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 5;"}
{"instruction": "Use a LATERAL join to retrieve the top 3 most recent orders for every user in the database without using a window function in the select list.", "output": "SELECT \n    u.user_id,\n    u.username,\n    o.order_id,\n    o.order_date,\n    o.amount\nFROM users u\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE user_id = u.user_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Write a query to pivot data to show total revenue per month for specific product categories (Electronics, Clothing, Home) using PostgreSQL's FILTER clause.", "output": "SELECT \n    DATE_TRUNC('month', order_date) AS sales_month,\n    SUM(amount) FILTER (WHERE category = 'Electronics') AS revenue_electronics,\n    SUM(amount) FILTER (WHERE category = 'Clothing') AS revenue_clothing,\n    SUM(amount) FILTER (WHERE category = 'Home') AS revenue_home\nFROM orders\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Identify and delete duplicate records from a table based on email address, keeping only the entry with the most recent created_at timestamp.", "output": "DELETE FROM users\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (\n                PARTITION BY email \n                ORDER BY created_at DESC\n            ) AS rn\n        FROM users\n    ) sub\n    WHERE rn > 1\n);"}
{"instruction": "PostgreSQL DBA Task: Find currently active queries that have been running for longer than 5 minutes.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state != 'idle' \n  AND now() - query_start > interval '5 minutes' \nORDER BY duration DESC;"}
{"instruction": "Calculate Year-Over-Year (YoY) growth percentage for total sales by year.", "output": "WITH yearly_sales AS (\n    SELECT \n        EXTRACT(YEAR FROM order_date) AS sales_year,\n        SUM(total_amount) AS total_revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT \n    sales_year,\n    total_revenue,\n    LAG(total_revenue) OVER (ORDER BY sales_year) AS prev_year_revenue,\n    ROUND(\n        (total_revenue - LAG(total_revenue) OVER (ORDER BY sales_year)) * 100.0 / \n        NULLIF(LAG(total_revenue) OVER (ORDER BY sales_year), 0), \n    2) AS yoy_growth_pct\nFROM yearly_sales;"}
{"instruction": "Write a recursive CTE to generate a hierarchical view of employees and their managers, starting from the CEO (who has no manager), showing the employee name, their level in the hierarchy, and the path of names from the root to the employee.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        name::TEXT AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the hierarchy with employees reporting to the current level\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        eh.level + 1,\n        eh.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy\nORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product category using window functions. The result should include the date, category, daily sales, and the moving average.", "output": "SELECT \n    sale_date,\n    category,\n    total_sales,\n    AVG(total_sales) OVER (\n        PARTITION BY category \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_category_sales\nORDER BY category, sale_date;"}
{"instruction": "Identify 'Churn Risk' customers. Select customers who made a purchase in 2022 but have not made any purchases in the last 6 months (relative to the current date). Use a CTE for cleaner logic.", "output": "WITH last_purchase AS (\n    SELECT \n        customer_id,\n        MAX(purchase_date) as last_date\n    FROM orders\n    GROUP BY customer_id\n),\nactive_2022 AS (\n    SELECT DISTINCT customer_id \n    FROM orders \n    WHERE EXTRACT(YEAR FROM purchase_date) = 2022\n)\nSELECT \n    c.customer_id,\n    c.email\nFROM customers c\nJOIN active_2022 a ON c.customer_id = a.customer_id\nJOIN last_purchase lp ON c.customer_id = lp.customer_id\nWHERE lp.last_date < CURRENT_DATE - INTERVAL '6 months';"}
{"instruction": "Solve the 'Gaps and Islands' problem to find consecutive login streaks for users. Group consecutive login dates together and return the user_id, start_date, end_date, and length of the streak.", "output": "WITH date_grouping AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtract row number from date to create a constant value for consecutive dates\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_days\nFROM date_grouping\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a PostgreSQL administration query to find the top 10 largest tables in the database, including their associated indexes, displaying the size in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot a sales table from rows to columns using PostgreSQL's `FILTER` clause. The source table has columns `sales_year`, `region`, and `amount`. The output should show total sales per year with separate columns for 'North', 'South', 'East', and 'West' regions.", "output": "SELECT \n    sales_year,\n    SUM(amount) FILTER (WHERE region = 'North') AS north_sales,\n    SUM(amount) FILTER (WHERE region = 'South') AS south_sales,\n    SUM(amount) FILTER (WHERE region = 'East') AS east_sales,\n    SUM(amount) FILTER (WHERE region = 'West') AS west_sales\nFROM regional_sales\nGROUP BY sales_year\nORDER BY sales_year;"}
{"instruction": "Find the top 3 highest-paid employees in each department. If there is a salary tie, they should share the same rank, and the next rank should be skipped (use `RANK()`).", "output": "WITH ranked_salaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank\n    FROM employees\n)\nSELECT * \nFROM ranked_salaries\nWHERE salary_rank <= 3;"}
{"instruction": "Write a query to delete duplicate rows from a table named `contacts` based on the `email` column, keeping only the record with the highest `id`.", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY id DESC) as rn\n        FROM contacts\n    ) sub\n    WHERE rn > 1\n);"}
{"instruction": "Query a PostgreSQL table with a JSONB column named `attributes`. Find all products where the JSON object contains a key 'color' set to 'red' and a key 'specs' containing a nested key 'weight' that is less than 10.", "output": "SELECT \n    product_id, \n    product_name, \n    attributes\nFROM products\nWHERE \n    attributes ->> 'color' = 'red'\n    AND (attributes -> 'specs' ->> 'weight')::NUMERIC < 10;"}
{"instruction": "Write a PostgreSQL administrative query to identify currently active queries that have been running for more than 5 minutes, displaying the process ID, user, start time, and the query text.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    query_start,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Write a query using a Recursive CTE to generate a hierarchical view of employees and their managers, including the depth level of each employee in the organization tree.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        first_name, \n        last_name, \n        manager_id, \n        1 AS level,\n        CAST(first_name || ' ' || last_name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join the CTE to the employees table\n    SELECT \n        e.employee_id, \n        e.first_name, \n        e.last_name, \n        e.manager_id, \n        eh.level + 1,\n        eh.path || ' > ' || e.first_name || ' ' || e.last_name\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy\nORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for each store using window functions.", "output": "SELECT \n    store_id,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Identify the top 3 highest-paid employees in each department. If there are ties in salary, they should share the rank, and the next rank should be skipped (use RANK vs DENSE_RANK logic appropriately).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank\n    FROM employees\n)\nSELECT * \nFROM RankedSalaries\nWHERE salary_rank <= 3;"}
{"instruction": "Write a PostgreSQL administration query to identify currently active queries that have been running for more than 5 minutes, along with the user and the start time.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    query_start, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes' \nORDER BY duration DESC;"}
{"instruction": "Pivot a transaction table to show total sales per year for specific product categories (Electronics, Clothing, Home) as columns using the PostgreSQL FILTER clause.", "output": "SELECT \n    EXTRACT(YEAR FROM transaction_date) AS sales_year,\n    SUM(amount) FILTER (WHERE category = 'Electronics') AS electronics_sales,\n    SUM(amount) FILTER (WHERE category = 'Clothing') AS clothing_sales,\n    SUM(amount) FILTER (WHERE category = 'Home') AS home_sales\nFROM transactions\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Find 'gaps' in a sequence of order IDs. Assuming IDs should be sequential, return the start and end of any missing ranges.", "output": "WITH leads AS (\n    SELECT \n        order_id,\n        LEAD(order_id) OVER (ORDER BY order_id) as next_order_id\n    FROM orders\n)\nSELECT \n    order_id + 1 as gap_start,\n    next_order_id - 1 as gap_end\nFROM leads\nWHERE next_order_id - order_id > 1;"}
{"instruction": "Perform a Cohort Analysis: Calculate the retention rate of users who signed up in January 2023, grouping by how many months have passed since their signup.", "output": "WITH cohort_users AS (\n    SELECT user_id, DATE_TRUNC('month', signup_date) as cohort_month\n    FROM users\n    WHERE signup_date >= '2023-01-01' AND signup_date < '2023-02-01'\n),\nuser_activities AS (\n    SELECT \n        c.user_id,\n        EXTRACT(MONTH FROM AGE(DATE_TRUNC('month', a.activity_date), c.cohort_month)) as month_number\n    FROM cohort_users c\n    JOIN activity_log a ON c.user_id = a.user_id\n    GROUP BY 1, 2\n)\nSELECT \n    month_number,\n    COUNT(DISTINCT user_id) as retained_users,\n    (COUNT(DISTINCT user_id)::FLOAT / (SELECT COUNT(*) FROM cohort_users)) * 100 as retention_percentage\nFROM user_activities\nGROUP BY month_number\nORDER BY month_number;"}
{"instruction": "Write a query to remove duplicate rows from a table named 'contacts' based on email, keeping only the entry with the highest ID.", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY id DESC) as rn\n        FROM contacts\n    ) t\n    WHERE t.rn > 1\n);"}
{"instruction": "PostgreSQL Admin: Check the disk size of all tables in the 'public' schema, including indexes, and display them in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nWHERE schemaname = 'public'\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Extract specific keys from a JSONB column. Given a table 'events' with a JSONB column 'payload' containing '{\"device\": {\"os\": \"...\", \"version\": \"...\"}}', count events by device OS.", "output": "SELECT \n    payload -> 'device' ->> 'os' AS operating_system,\n    COUNT(*) as event_count\nFROM events\nWHERE payload -> 'device' IS NOT NULL\nGROUP BY 1\nORDER BY 2 DESC;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and window functions to identify the top 3 salespeople by revenue within each sales region.", "output": "WITH RegionalSales AS (\n    SELECT \n        region_id, \n        salesperson_id, \n        SUM(amount) as total_revenue\n    FROM sales\n    GROUP BY region_id, salesperson_id\n),\nRankedSales AS (\n    SELECT \n        region_id,\n        salesperson_id,\n        total_revenue,\n        DENSE_RANK() OVER (PARTITION BY region_id ORDER BY total_revenue DESC) as rank\n    FROM RegionalSales\n)\nSELECT * \nFROM RankedSales \nWHERE rank <= 3;"}
{"instruction": "Create a recursive CTE to generate a hierarchical view of an organization, showing the path from a specific employee up to the CEO.", "output": "WITH RECURSIVE ManagementChain AS (\n    -- Anchor member: start with the specific employee\n    SELECT id, name, manager_id, 1 as level, name::text as path\n    FROM employees \n    WHERE id = 105 -- Target Employee ID\n\n    UNION ALL\n\n    -- Recursive member: join with manager\n    SELECT e.id, e.name, e.manager_id, mc.level + 1, e.name || ' -> ' || mc.path\n    FROM employees e\n    INNER JOIN ManagementChain mc ON e.id = mc.manager_id\n)\nSELECT * FROM ManagementChain;"}
{"instruction": "Calculate the 7-day moving average of daily sign-ups using a window function with a frame clause.", "output": "SELECT \n    signup_date,\n    COUNT(user_id) as daily_signups,\n    AVG(COUNT(user_id)) OVER (\n        ORDER BY signup_date\n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7d\nFROM users\nGROUP BY signup_date\nORDER BY signup_date;"}
{"instruction": "Solve the 'Gaps and Islands' problem to identify consecutive days a user logged in. Return the user_id, start date, end date, and length of the streak.", "output": "WITH GroupedDates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM GroupedDates\nGROUP BY user_id, grp\nHAVING COUNT(*) >= 2\nORDER BY user_id, streak_start;"}
{"instruction": "Perform a cohort analysis to calculate the month-over-month retention rate of users.", "output": "WITH MonthlyActivity AS (\n    SELECT \n        user_id, \n        DATE_TRUNC('month', activity_date) as activity_month\n    FROM user_logs\n    GROUP BY 1, 2\n)\nSELECT \n    previous.activity_month as cohort_month,\n    COUNT(DISTINCT previous.user_id) as total_users,\n    COUNT(DISTINCT current.user_id) as retained_users,\n    ROUND((COUNT(DISTINCT current.user_id)::numeric / COUNT(DISTINCT previous.user_id)) * 100, 2) as retention_rate\nFROM MonthlyActivity previous\nLEFT JOIN MonthlyActivity current \n    ON previous.user_id = current.user_id \n    AND previous.activity_month = current.activity_month - INTERVAL '1 month'\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Use a LATERAL join to find the 3 most recent orders for every customer without using a window function in the select list.", "output": "SELECT \n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Pivot a table using the FILTER clause to display total sales for specific product categories as columns (Electronics, Clothing, Home) per month.", "output": "SELECT \n    DATE_TRUNC('month', sale_date) as sales_month,\n    SUM(amount) FILTER (WHERE category = 'Electronics') as electronics_sales,\n    SUM(amount) FILTER (WHERE category = 'Clothing') as clothing_sales,\n    SUM(amount) FILTER (WHERE category = 'Home') as home_sales\nFROM sales\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Query specific to PostgreSQL to find the largest tables in the database, including their indexes, formatted in a human-readable size.", "output": "SELECT \n    schemaname || '.' || relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "DBA Administration: Identify queries that are currently blocked by locks held by other transactions.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocked_activity.query AS blocked_query,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Extract data from a JSONB column in PostgreSQL, finding products with a specific attribute key ('color') and expanding the tags array into rows.", "output": "SELECT \n    product_id,\n    data ->> 'name' as product_name,\n    data -> 'attributes' ->> 'color' as color,\n    tag_value\nFROM products\nCROSS JOIN LATERAL jsonb_array_elements_text(data -> 'tags') as tag_value\nWHERE data -> 'attributes' ? 'color';"}
{"instruction": "Write a recursive CTE to traverse an employee hierarchy (adjacency list model). The goal is to retrieve the full management chain for a specific employee with ID 50, listing the hierarchy level and the manager's name from bottom to top.", "output": "WITH RECURSIVE management_chain AS (\n    -- Anchor member: start with the specific employee\n    SELECT \n        employee_id, \n        manager_id, \n        full_name,\n        0 AS level\n    FROM employees\n    WHERE employee_id = 50\n\n    UNION ALL\n\n    -- Recursive member: join with the manager\n    SELECT \n        e.employee_id, \n        e.manager_id, \n        e.full_name,\n        mc.level + 1\n    FROM employees e\n    INNER JOIN management_chain mc ON e.employee_id = mc.manager_id\n)\nSELECT * FROM management_chain;"}
{"instruction": "Solve the 'Gaps and Islands' problem to identify consecutive login streaks for users. You have a table 'user_logins' with 'user_id' and 'login_date'. Return the user_id, start_date, end_date, and length of every streak of consecutive days.", "output": "WITH distinct_logins AS (\n    SELECT DISTINCT user_id, login_date \n    FROM user_logins\n),\ngrouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtracting row_number from the date creates a constant date value for consecutive sequences\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as group_id\n    FROM distinct_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_logins\nGROUP BY user_id, group_id\nORDER BY user_id, streak_start;"}
{"instruction": "Calculate the 7-day moving average and the cumulative running total of sales revenue for each day, ordered by date. Use Window Functions.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    -- Moving Average: Current row + 6 preceding rows\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days,\n    -- Running Total: Unbounded preceding to current row\n    SUM(daily_revenue) OVER (\n        ORDER BY sale_date\n    ) AS running_total\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Perform a Pivot (Cross-tabulation) to show total sales per product category for the first quarter (Jan, Feb, Mar) as separate columns. Use PostgreSQL specific 'FILTER' syntax for cleaner aggregation.", "output": "SELECT \n    product_category,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) AS q1_total\nFROM sales\nWHERE sale_date >= '2023-01-01' AND sale_date <= '2023-03-31'\nGROUP BY product_category;"}
{"instruction": "Identify unused indexes in a PostgreSQL database to optimize performance and storage. Join system catalogs to find indexes that have not been scanned.", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as index_scans\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0 \n  AND indexrelname NOT LIKE '%_pkey' -- Exclude primary keys\n  AND indexrelname NOT LIKE '%_ukey' -- Exclude unique constraints if named conventionally\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Use a LATERAL JOIN to retrieve the top 3 most recent orders for every customer in the 'customers' table without using a window function rank filter in a subquery.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Generate a report filling in missing dates with zero values. Create a date series for the current month and Left Join it with the 'daily_visits' table.", "output": "WITH date_series AS (\n    SELECT generate_series(\n        DATE_TRUNC('month', CURRENT_DATE),\n        DATE_TRUNC('month', CURRENT_DATE) + INTERVAL '1 month' - INTERVAL '1 day',\n        INTERVAL '1 day'\n    )::date AS report_date\n)\nSELECT \n    ds.report_date,\n    COALESCE(SUM(v.visit_count), 0) AS total_visits\nFROM date_series ds\nLEFT JOIN daily_visits v ON v.visit_date = ds.report_date\nGROUP BY ds.report_date\nORDER BY ds.report_date;"}
{"instruction": "Identify current blocking queries in PostgreSQL. Retrieve the PID, user, and query text of the process holding the lock and the process waiting for the lock.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation. Insert a new inventory record for a product. If the product_id already exists, update the quantity by adding the new amount to the existing stock.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_updated)\nVALUES (101, 1, 50, NOW())\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Query a JSONB column named 'attributes' in a 'products' table. Find the average rating of products where the JSON data contains a 'color' key set to 'Red' and has a 'tags' array containing 'summer'.", "output": "SELECT \n    AVG((attributes ->> 'rating')::numeric) as average_rating\nFROM products\nWHERE \n    attributes ->> 'color' = 'Red'\n    AND attributes -> 'tags' @> '[\"summer\"]';"}
{"instruction": "Write a recursive Common Table Expression (CTE) to traverse an employee hierarchy. Given a table 'employees' with columns 'id', 'name', and 'manager_id', return the full reporting chain (path of names) and the hierarchy level for a specific employee with id 105.", "output": "WITH RECURSIVE employee_path AS (\n    -- Anchor member: select the specific employee\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 AS level,\n        name::TEXT as path\n    FROM employees\n    WHERE id = 105\n\n    UNION ALL\n\n    -- Recursive member: join with the manager\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        ep.level + 1,\n        e.name || ' -> ' || ep.path\n    FROM employees e\n    INNER JOIN employee_path ep ON e.id = ep.manager_id\n)\nSELECT * FROM employee_path;"}
{"instruction": "Calculate the 3-day moving average of sales and the running total of sales for each day, partitioned by store location. The table 'daily_sales' contains 'store_id', 'sale_date', and 'revenue'.", "output": "SELECT \n    store_id,\n    sale_date,\n    revenue,\n    SUM(revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date\n    ) AS running_total,\n    AVG(revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_3_days\nFROM daily_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Identify 'Churn Risk' users. Select users who have placed more than 5 orders in the past ('orders' table), but have not placed any order in the last 90 days. Return user_id, last_order_date, and total_lifetime_orders.", "output": "WITH UserStats AS (\n    SELECT \n        user_id,\n        MAX(order_date) as last_order_date,\n        COUNT(order_id) as total_lifetime_orders\n    FROM orders\n    GROUP BY user_id\n)\nSELECT \n    user_id,\n    last_order_date,\n    total_lifetime_orders\nFROM UserStats\nWHERE total_lifetime_orders > 5\n  AND last_order_date < CURRENT_DATE - INTERVAL '90 days';"}
{"instruction": "Write a PostgreSQL DBA query to find the top 10 largest tables in the database, displaying their schema, table name, and total size (pretty printed).", "output": "SELECT\n    n.nspname AS schema_name,\n    c.relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(c.oid)) AS total_size\nFROM pg_class c\nLEFT JOIN pg_namespace n ON n.oid = c.relnamespace\nWHERE c.relkind = 'r' -- ensure it is a table\nORDER BY pg_total_relation_size(c.oid) DESC\nLIMIT 10;"}
{"instruction": "Perform a 'gap analysis' to find missing invoice numbers in a sequence. Given a table 'invoices' with a sequential integer column 'invoice_num', find all numbers missing between the minimum and maximum invoice number existing in the table.", "output": "SELECT \n    s.i AS missing_invoice_num\nFROM generate_series(\n    (SELECT MIN(invoice_num) FROM invoices), \n    (SELECT MAX(invoice_num) FROM invoices)\n) s(i)\nLEFT JOIN invoices inv ON s.i = inv.invoice_num\nWHERE inv.invoice_num IS NULL;"}
{"instruction": "Pivot monthly sales data from rows to columns. Given a table 'sales' (product_id, sales_month, amount), produce a result with one row per product and columns for Jan, Feb, and Mar sales.", "output": "SELECT \n    product_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sales_month) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sales_month) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sales_month) = 3) AS mar_sales\nFROM sales\nGROUP BY product_id;"}
{"instruction": "Use a LATERAL join to find the top 2 most recent comments for every blog post. The tables are 'posts' and 'comments' (linked by post_id).", "output": "SELECT \n    p.title,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE post_id = p.id\n    ORDER BY created_at DESC\n    LIMIT 2\n) c;"}
{"instruction": "Write a query to remove duplicate rows from a table 'user_logs' based on 'user_id' and 'log_timestamp', keeping only the entry with the highest 'log_id'.", "output": "DELETE FROM user_logs\nWHERE log_id IN (\n    SELECT log_id\n    FROM (\n        SELECT \n            log_id,\n            ROW_NUMBER() OVER (\n                PARTITION BY user_id, log_timestamp \n                ORDER BY log_id DESC\n            ) as rn\n        FROM user_logs\n    ) t\n    WHERE t.rn > 1\n);"}
{"instruction": "DBA Task: Identify currently active queries that have been running for more than 5 minutes, excluding the query inspecting the process list itself.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) as duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle'\n  AND age(clock_timestamp(), query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Calculate the year-over-year growth percentage for total revenue per category. Requires joining 'products', 'order_items', and 'orders', and using window functions to compare the current year's revenue to the previous year.", "output": "WITH yearly_revenue AS (\n    SELECT \n        p.category,\n        EXTRACT(YEAR FROM o.order_date) AS sales_year,\n        SUM(oi.quantity * oi.unit_price) AS total_revenue\n    FROM order_items oi\n    JOIN orders o ON oi.order_id = o.id\n    JOIN products p ON oi.product_id = p.id\n    GROUP BY 1, 2\n)\nSELECT \n    category,\n    sales_year,\n    total_revenue,\n    LAG(total_revenue) OVER (PARTITION BY category ORDER BY sales_year) AS prev_year_revenue,\n    ROUND(\n        ((total_revenue - LAG(total_revenue) OVER (PARTITION BY category ORDER BY sales_year)) \n        / LAG(total_revenue) OVER (PARTITION BY category ORDER BY sales_year)) * 100\n    , 2) AS yoy_growth_pct\nFROM yearly_revenue;"}
{"instruction": "Write a Recursive CTE to traverse an employee hierarchy (adjacency list model) and return the path from the root manager to a specific employee, including the depth level.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Select the top-level manager\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 AS depth, \n        name::TEXT AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join with the previous result\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        eh.depth + 1,\n        eh.path || ' -> ' || e.name\n    FROM employees e\n    JOIN employee_hierarchy eh ON e.manager_id = eh.id\n)\nSELECT * FROM employee_hierarchy;"}
{"instruction": "Calculate the 7-day moving average of sales amount for each day, ordered by date. Assume there is one row per day.", "output": "SELECT \n    sale_date,\n    amount,\n    AVG(amount) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Find the top 3 highest-paid employees within each department using a window function. Handle ties by including all employees with the same salary rank (DENSE_RANK).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT * \nFROM RankedSalaries\nWHERE rank_num <= 3;"}
{"instruction": "Use a LATERAL join to retrieve the 5 most recent orders for every customer found in the 'vip_customers' table.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM vip_customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders o\n    WHERE o.customer_id = c.customer_id\n    ORDER BY o.order_date DESC\n    LIMIT 5\n) o;"}
{"instruction": "Identify 'Gaps' in a sequence of invoice IDs. Return the start and end of any missing range of IDs.", "output": "WITH leads AS (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) AS next_invoice_id\n    FROM invoices\n)\nSELECT \n    invoice_id + 1 AS gap_start,\n    next_invoice_id - 1 AS gap_end\nFROM leads\nWHERE next_invoice_id - invoice_id > 1;"}
{"instruction": "Pivot a sales table (columns: year, month, amount) to display months as columns for a specific year using filtered aggregation.", "output": "SELECT \n    year,\n    SUM(amount) FILTER (WHERE month = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE month = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE month = 3) AS mar_sales,\n    SUM(amount) FILTER (WHERE month = 4) AS apr_sales\n    -- ... continue for other months\nFROM monthly_sales\nWHERE year = 2023\nGROUP BY year;"}
{"instruction": "Database Administration: Identify currently active queries that have been running for longer than 5 minutes.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > interval '5 minutes' \nORDER BY duration DESC;"}
{"instruction": "Database Administration: Find the total disk size of a specific table ('large_table'), including all its associated indexes and toast data.", "output": "SELECT \n    pg_size_pretty(pg_total_relation_size('large_table')) AS total_size,\n    pg_size_pretty(pg_relation_size('large_table')) AS table_size,\n    pg_size_pretty(pg_total_relation_size('large_table') - pg_relation_size('large_table')) AS index_toast_size;"}
{"instruction": "Calculate the 90th percentile of query execution times per user using an ordered-set aggregate function.", "output": "SELECT \n    user_id,\n    PERCENTILE_CONT(0.90) WITHIN GROUP (ORDER BY execution_time_ms) AS p90_latency\nFROM query_logs\nGROUP BY user_id;"}
{"instruction": "Perform an 'Upsert' (Insert or Update): Insert a new user record, but if the email already exists, update the 'last_login' timestamp instead.", "output": "INSERT INTO users (username, email, last_login)\nVALUES ('jdoe', 'john.doe@example.com', NOW())\nON CONFLICT (email) \nDO UPDATE SET \n    last_login = EXCLUDED.last_login,\n    username = EXCLUDED.username;"}
{"instruction": "Write a query to calculate the running total of sales for each customer, ordered by the transaction date.", "output": "SELECT customer_id, transaction_date, amount, SUM(amount) OVER (PARTITION BY customer_id ORDER BY transaction_date) AS running_total FROM sales;"}
{"instruction": "Identify the top 3 highest-paid employees within each department using a window function.", "output": "WITH RankedSalaries AS (\n  SELECT department_id, employee_name, salary,\n         DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n  FROM employees\n)\nSELECT department_id, employee_name, salary\nFROM RankedSalaries\nWHERE rank <= 3;"}
{"instruction": "Create a recursive CTE to traverse an employee hierarchy and find the management level of every employee (where level 1 is the CEO/top manager).", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n  SELECT id, name, manager_id, 1 AS level\n  FROM employees\n  WHERE manager_id IS NULL\n  UNION ALL\n  SELECT e.id, e.name, e.manager_id, eh.level + 1\n  FROM employees e\n  INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.id\n)\nSELECT * FROM EmployeeHierarchy;"}
{"instruction": "Write a PostgreSQL administrative query to find the size of all tables in the database, including indexes, and display them in a human-readable format.", "output": "SELECT relname AS table_name,\n       pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Use a LATERAL join to retrieve the 5 most recent log entries for every user in the 'users' table without aggregating the whole logs table first.", "output": "SELECT u.username, l.log_message, l.created_at\nFROM users u\nCROSS JOIN LATERAL (\n  SELECT log_message, created_at\n  FROM user_logs\n  WHERE user_id = u.id\n  ORDER BY created_at DESC\n  LIMIT 5\n) l;"}
{"instruction": "Calculate the 7-day moving average of daily sign-ups.", "output": "SELECT signup_date, daily_count,\n       AVG(daily_count) OVER (\n         ORDER BY signup_date \n         ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n       ) AS moving_average_7d\nFROM daily_signups;"}
{"instruction": "Find 'gaps' in a sequence of IDs to identify deleted records. Return the start and end of any missing ID ranges.", "output": "SELECT id + 1 AS gap_start, next_id - 1 AS gap_end\nFROM (\n  SELECT id, LEAD(id) OVER (ORDER BY id) AS next_id\n  FROM orders\n) t\nWHERE next_id > id + 1;"}
{"instruction": "Write a query to pivot monthly sales data into columns (Jan, Feb, Mar) for the current year using the FILTER clause.", "output": "SELECT product_id,\n       SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n       SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n       SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY product_id;"}
{"instruction": "Identify currently blocked queries and the Process IDs (PIDs) blocking them in a PostgreSQL database.", "output": "SELECT pid, \n       usename, \n       pg_blocking_pids(pid) AS blocked_by, \n       query AS blocked_query\nFROM pg_stat_activity\nWHERE cardinality(pg_blocking_pids(pid)) > 0;"}
{"instruction": "Find all indexes in the public schema that have never been used (scanned) since the last statistics reset.", "output": "SELECT schemaname, relname AS table_name, indexrelname AS index_name, idx_scan\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0 \n  AND schemaname = 'public'\n  AND indexrelname NOT LIKE '%_pkey';"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to find the top 3 sales representatives by total revenue within each sales region for the current year.", "output": "WITH RegionalSales AS (\n    SELECT \n        r.region_name,\n        s.rep_name,\n        SUM(o.amount) as total_revenue\n    FROM sales_reps s\n    JOIN regions r ON s.region_id = r.id\n    JOIN orders o ON s.id = o.rep_id\n    WHERE o.order_date >= DATE_TRUNC('year', CURRENT_DATE)\n    GROUP BY r.region_name, s.rep_name\n),\nRankedSales AS (\n    SELECT \n        region_name,\n        rep_name,\n        total_revenue,\n        DENSE_RANK() OVER (PARTITION BY region_name ORDER BY total_revenue DESC) as rank\n    FROM RegionalSales\n)\nSELECT * \nFROM RankedSales \nWHERE rank <= 3;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of an organization, displaying the employee name and their full management path (e.g., 'CEO > VP > Manager > Employee') starting from the top-level manager (where manager_id is NULL).", "output": "WITH RECURSIVE OrgHierarchy AS (\n    -- Anchor member: Top level management\n    SELECT \n        id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as path,\n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n    \n    UNION ALL\n    \n    -- Recursive member: Subordinates\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oh.path || ' > ' || e.name,\n        oh.level + 1\n    FROM employees e\n    JOIN OrgHierarchy oh ON e.manager_id = oh.id\n)\nSELECT id, name, level, path \nFROM OrgHierarchy \nORDER BY path;"}
{"instruction": "Write a query to calculate the 7-day moving average of daily sign-ups. Use a window function with a specific frame clause to ensure the average is calculated based on the current row and the 6 preceding rows.", "output": "SELECT \n    signup_date,\n    COUNT(user_id) as daily_signups,\n    AVG(COUNT(user_id)) OVER (\n        ORDER BY signup_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM users\nGROUP BY signup_date\nORDER BY signup_date;"}
{"instruction": "PostgreSQL Administration: Write a query to identify indexes that have not been used (scanned) since the database statistics were last reset, excluding primary keys and internal system schemas.", "output": "SELECT \n    schemaname, \n    relname AS table_name, \n    indexrelname AS index_name, \n    idx_scan AS number_of_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0 \n  AND NOT indisprimary \n  AND schemaname NOT IN ('pg_catalog', 'information_schema')\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Solve the 'Gaps and Islands' problem: Identify consecutive days a user logged in. Group consecutive dates into a single range (Start Date, End Date) for each user.", "output": "WITH DatedLogins AS (\n    SELECT DISTINCT user_id, login_date \n    FROM user_logs\n),\nGroups AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtracting row_number (days) from the date creates a constant date for consecutive sequences\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM DatedLogins\n)\nSELECT \n    user_id,\n    MIN(login_date) as start_date,\n    MAX(login_date) as end_date,\n    COUNT(*) as consecutive_days\nFROM Groups\nGROUP BY user_id, grp\nORDER BY user_id, start_date;"}
{"instruction": "Use a CROSS JOIN LATERAL to find the 3 most recent comments for every blog post without using a window function in the main select list.", "output": "SELECT \n    p.title,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE post_id = p.id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c\nORDER BY p.title, c.created_at DESC;"}
{"instruction": "Perform a Pivot operation using Conditional Aggregation (FILTER clause) to display total sales per month for the current year, with months as columns.", "output": "SELECT \n    product_category,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS \"Jan\",\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS \"Feb\",\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS \"Mar\",\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 4) AS \"Apr\",\n    SUM(amount) AS total_year\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY product_category;"}
{"instruction": "PostgreSQL Administration: Write a query to detect currently blocking queries (queries waiting on locks held by other queries). Display the blocking PID, the blocked PID, and the query texts.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Write a query to find 'Churned' customers: Users who purchased something in the year 2022 but have made zero purchases in 2023. Use set operations (EXCEPT) or EXISTS logic.", "output": "SELECT c.customer_id, c.email\nFROM customers c\nWHERE EXISTS (\n    SELECT 1 FROM orders o \n    WHERE o.customer_id = c.customer_id \n    AND o.order_date BETWEEN '2022-01-01' AND '2022-12-31'\n)\nAND NOT EXISTS (\n    SELECT 1 FROM orders o \n    WHERE o.customer_id = c.customer_id \n    AND o.order_date >= '2023-01-01'\n);"}
{"instruction": "Advanced JSONB Querying: Given a table 'events' with a JSONB column 'payload', calculate the total duration of events where the payload contains a specific tag inside a JSON array (e.g., payload = {'tags': ['error', 'timeout'], 'duration': 500}).", "output": "SELECT \n    SUM((payload->>'duration')::INT) as total_duration\nFROM events\nWHERE payload @> '{\"tags\": [\"timeout\"]}';"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to find the top 3 highest-paid employees in each department. Use DENSE_RANK to handle ties appropriately.", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM RankedSalaries\nWHERE rank <= 3\nORDER BY department_id, rank;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of an organization. Given an 'employees' table with 'id', 'name', and 'manager_id', return the management path (e.g., 'CEO > VP > Manager > Employee') for a specific employee with ID 105.", "output": "WITH RECURSIVE ManagementPath AS (\n    -- Base case: the employee themselves\n    SELECT \n        id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL -- Assuming top level, or start from specific root if needed\n\n    UNION ALL\n\n    -- Recursive step: join employees to their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        mp.path || ' > ' || e.name\n    FROM employees e\n    INNER JOIN ManagementPath mp ON mp.id = e.manager_id\n)\nSELECT path \nFROM ManagementPath \nWHERE id = 105;"}
{"instruction": "Write a PostgreSQL query to calculate the 7-day moving average of daily sales. The result should include the date, daily sales, and the moving average, ordered by date.", "output": "SELECT \n    sales_date,\n    daily_total,\n    AVG(daily_total) OVER (\n        ORDER BY sales_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) :: NUMERIC(10,2) AS moving_avg_7_days\nFROM daily_sales\nORDER BY sales_date;"}
{"instruction": "Identify 'Islands' in a dataset of consecutive login dates. Group consecutive dates into a single range (start_date, end_date) for each user.", "output": "WITH GroupedDates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a grouping identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_length\nFROM GroupedDates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a complex aggregation query to find customers who have purchased Product A but have NEVER purchased Product B.", "output": "SELECT \n    c.customer_id,\n    c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nGROUP BY c.customer_id, c.customer_name\nHAVING \n    COUNT(CASE WHEN p.product_name = 'Product A' THEN 1 END) > 0\n    AND \n    COUNT(CASE WHEN p.product_name = 'Product B' THEN 1 END) = 0;"}
{"instruction": "Using PostgreSQL's FILTER clause, create a pivot-style report that shows total revenue per year (rows) broken down by quarter (columns).", "output": "SELECT \n    EXTRACT(YEAR FROM order_date) AS sales_year,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM order_date) = 1) AS q1_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM order_date) = 2) AS q2_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM order_date) = 3) AS q3_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM order_date) = 4) AS q4_revenue\nFROM sales\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "DBA Task: Write a query to identify unused indexes in a PostgreSQL database to help with storage optimization.", "output": "SELECT \n    schemaname || '.' || relname AS table_name,\n    indexrelname AS index_name,\n    idx_scan AS index_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0 -- Index has never been scanned\nAND indexrelname NOT LIKE '%pkey' -- Exclude primary keys\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "DBA Task: Detect currently running queries that are being blocked by other transactions, showing the blocked PID and the blocking PID.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocked_activity.query AS blocked_query,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Query a JSONB column named 'attributes' to find all products that have a specific tag 'summer' inside a JSON array stored at the key 'tags'.", "output": "SELECT \n    product_id,\n    product_name,\n    attributes\nFROM products\nWHERE attributes -> 'tags' @> '[\"summer\"]';"}
{"instruction": "Calculate the 'Churn Rate' per month. Churn is defined as the number of users who cancelled in the current month divided by the number of active users at the start of the month.", "output": "WITH MonthlyStats AS (\n    SELECT \n        DATE_TRUNC('month', event_date) AS month,\n        COUNT(CASE WHEN event_type = 'cancel' THEN 1 END) as cancelled_users,\n        COUNT(CASE WHEN event_type = 'signup' THEN 1 END) as new_users\n    FROM user_events\n    GROUP BY 1\n),\nActiveUsers AS (\n    SELECT \n        month,\n        cancelled_users,\n        SUM(new_users - cancelled_users) OVER (ORDER BY month ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING) as start_of_month_active\n    FROM MonthlyStats\n)\nSELECT \n    month,\n    cancelled_users,\n    start_of_month_active,\n    ROUND((cancelled_users::NUMERIC / NULLIF(start_of_month_active, 0)) * 100, 2) as churn_rate_percent\nFROM ActiveUsers\nWHERE start_of_month_active > 0\nORDER BY month;"}
{"instruction": "Calculate the top 3 selling products within each category based on total revenue. Use a Common Table Expression (CTE) to aggregate sales first, and then apply the DENSE_RANK window function to determine the ranking.", "output": "WITH ProductRevenue AS (\n    SELECT \n        p.category_id,\n        p.product_name,\n        SUM(o.quantity * o.unit_price) as total_revenue\n    FROM products p\n    JOIN order_details o ON p.product_id = o.product_id\n    GROUP BY p.category_id, p.product_name\n)\nSELECT \n    category_id,\n    product_name,\n    total_revenue\nFROM (\n    SELECT \n        category_id,\n        product_name,\n        total_revenue,\n        DENSE_RANK() OVER (PARTITION BY category_id ORDER BY total_revenue DESC) as rank\n    FROM ProductRevenue\n) ranked_products\nWHERE rank <= 3;"}
{"instruction": "Generate a hierarchical view of employees showing their level in the organization and the path from the top manager (CEO) down to them using a Recursive CTE.", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n    -- Anchor member: Select the top manager (who has no manager)\n    SELECT \n        employee_id, \n        first_name, \n        manager_id, \n        1 as level,\n        CAST(first_name AS TEXT) as path\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join with the previous level\n    SELECT \n        e.employee_id, \n        e.first_name, \n        e.manager_id, \n        eh.level + 1,\n        eh.path || ' -> ' || e.first_name\n    FROM employees e\n    JOIN EmployeeHierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM EmployeeHierarchy ORDER BY path;"}
{"instruction": "Calculate the Month-over-Month (MoM) percentage growth in total sales revenue. Handle potential division by zero errors.", "output": "WITH MonthlySales AS (\n    SELECT \n        DATE_TRUNC('month', order_date) as sales_month,\n        SUM(amount) as revenue\n    FROM sales\n    GROUP BY 1\n)\nSELECT \n    sales_month,\n    revenue,\n    LAG(revenue) OVER (ORDER BY sales_month) as previous_month_revenue,\n    ROUND(\n        (\n            (revenue - LAG(revenue) OVER (ORDER BY sales_month)) \n            / NULLIF(LAG(revenue) OVER (ORDER BY sales_month), 0)\n        ) * 100, 2\n    ) as growth_percentage\nFROM MonthlySales;"}
{"instruction": "Identify user 'sessions' based on activity logs. A new session is defined if there is a gap of more than 30 minutes between consecutive events for a specific user.", "output": "WITH LaggedEvents AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        LAG(event_timestamp) OVER (PARTITION BY user_id ORDER BY event_timestamp) as prev_timestamp\n    FROM user_activity\n),\nSessionFlags AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        CASE \n            WHEN prev_timestamp IS NULL OR event_timestamp > prev_timestamp + INTERVAL '30 minutes' THEN 1 \n            ELSE 0 \n        END as is_new_session\n    FROM LaggedEvents\n),\nSessionIds AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY event_timestamp) as session_id\n    FROM SessionFlags\n)\nSELECT \n    user_id, \n    session_id, \n    MIN(event_timestamp) as session_start, \n    MAX(event_timestamp) as session_end,\n    COUNT(*) as events_in_session\nFROM SessionIds\nGROUP BY user_id, session_id;"}
{"instruction": "PostgreSQL DBA Task: List the top 10 largest tables in the database, including the size of their associated indexes, formatted in a human-readable format.", "output": "SELECT\n    schemaname as schema,\n    relname as table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) as total_size,\n    pg_size_pretty(pg_relation_size(relid)) as data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) as index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform a 'gap analysis' to find missing order IDs in a sequence. Assume order IDs are sequential integers.", "output": "SELECT \n    s.i as missing_id\nFROM generate_series(\n    (SELECT MIN(order_id) FROM orders), \n    (SELECT MAX(order_id) FROM orders)\n) s(i)\nLEFT JOIN orders o ON s.i = o.order_id\nWHERE o.order_id IS NULL;"}
{"instruction": "Calculate the 7-day moving average of daily sign-ups using a window function with a frame clause.", "output": "SELECT \n    signup_date,\n    daily_count,\n    AVG(daily_count) OVER (\n        ORDER BY signup_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM (\n    SELECT \n        DATE(created_at) as signup_date, \n        COUNT(*) as daily_count\n    FROM users\n    GROUP BY DATE(created_at)\n) daily_stats\nORDER BY signup_date;"}
{"instruction": "PostgreSQL Specific: Aggregate key-value pairs from a child table (Entity-Attribute-Value pattern) into a single JSONB column for each product.", "output": "SELECT \n    p.product_id,\n    p.product_name,\n    jsonb_object_agg(a.attribute_name, a.attribute_value) as attributes\nFROM products p\nJOIN product_attributes a ON p.product_id = a.product_id\nGROUP BY p.product_id, p.product_name;"}
{"instruction": "PostgreSQL DBA Task: Identify queries that are currently waiting on locks (blocking other queries).", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Perform an UPSERT (Update or Insert) operation. Insert a new inventory record, but if a conflict occurs on `product_id`, update the quantity by adding the new amount to the existing amount.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_updated)\nVALUES (101, 1, 50, NOW())\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Write a Recursive CTE to generate a hierarchical organization chart showing the employee name, their manager, and their hierarchy level (depth), starting from the CEO (where manager_id is NULL).", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name,\n        manager_id, \n        0 AS hierarchy_level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE with employees to find subordinates\n    SELECT \n        e.employee_id, \n        e.name,\n        e.manager_id, \n        oc.hierarchy_level + 1\n    FROM employees e\n    INNER JOIN OrgChart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM OrgChart ORDER BY hierarchy_level, manager_id;"}
{"instruction": "Calculate the 7-day moving average of daily revenue using a window function with a frame specification.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date\n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_days\nFROM sales_data\nORDER BY sale_date;"}
{"instruction": "Identify the top 3 selling products per category using DENSE_RANK to handle ties, and filter the result to only show the top 3.", "output": "WITH RankedSales AS (\n    SELECT \n        category_name,\n        product_name,\n        total_sales,\n        DENSE_RANK() OVER (\n            PARTITION BY category_name \n            ORDER BY total_sales DESC\n        ) as rank_num\n    FROM product_sales\n)\nSELECT * \nFROM RankedSales \nWHERE rank_num <= 3;"}
{"instruction": "Solve the 'Gaps and Islands' problem to find consecutive days a user logged in. Group consecutive dates into a single range.", "output": "WITH DatedGroups AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a grouping identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as start_date,\n    MAX(login_date) as end_date,\n    COUNT(*) as consecutive_days\nFROM DatedGroups\nGROUP BY user_id, grp\nORDER BY user_id, start_date;"}
{"instruction": "Use a LATERAL JOIN to fetch the 5 most recent comments for every blog post, optimizing for cases where there are many posts but we only need a subset of comments for each.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 5\n) c;"}
{"instruction": "PostgreSQL Administration: Query to identify currently blocking queries and the queries they are blocking (Lock Analysis).", "output": "SELECT\n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query AS blocked_statement,\n    blocking_activity.query AS current_statement_in_blocking_process\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate Month-Over-Month (MoM) revenue growth percentage using LAG().", "output": "SELECT \n    year_month,\n    revenue,\n    LAG(revenue) OVER (ORDER BY year_month) as previous_month_revenue,\n    ROUND(\n        (\n            (revenue - LAG(revenue) OVER (ORDER BY year_month))::numeric / \n            NULLIF(LAG(revenue) OVER (ORDER BY year_month), 0)\n        ) * 100, 2\n    ) as growth_percentage\nFROM monthly_financials;"}
{"instruction": "PostgreSQL Administration: List the top 10 largest tables in the database, including their total size (data + indexes) and pretty-printed format.", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform a Full Outer Join to compare sales data between two years (2022 and 2023) for all categories, handling NULLs where a category didn't exist in one of the years.", "output": "SELECT \n    COALESCE(t22.category, t23.category) AS category,\n    COALESCE(t22.total_sales, 0) AS sales_2022,\n    COALESCE(t23.total_sales, 0) AS sales_2023,\n    (COALESCE(t23.total_sales, 0) - COALESCE(t22.total_sales, 0)) AS diff\nFROM sales_2022 t22\nFULL OUTER JOIN sales_2023 t23 \n    ON t22.category = t23.category;"}
{"instruction": "PostgreSQL JSONB: Query a JSONB column to find users who have a specific attribute nested within a JSON object and filter by a value inside an array.", "output": "SELECT \n    id, \n    profile_data->>'username' as username\nFROM users\nWHERE \n    -- Check if 'settings' object contains 'notifications_enabled': true\n    profile_data @> '{\"settings\": {\"notifications_enabled\": true}}' \n    -- Check if the 'tags' array contains the string 'premium'\n    AND profile_data->'tags' ? 'premium';"}
{"instruction": "Write a query to find the top 3 earners in each department using a window function. If there is a tie, they should share the same rank, and the next rank should not be skipped (use DENSE_RANK).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM RankedSalaries\nWHERE rank <= 3;"}
{"instruction": "Create a recursive CTE to traverse an employee hierarchy and retrieve the management chain for a specific employee (ID 105), listing the employee and all their managers up to the CEO.", "output": "WITH RECURSIVE ManagementChain AS (\n    -- Anchor member: start with the specific employee\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        0 as level\n    FROM employees\n    WHERE employee_id = 105\n\n    UNION ALL\n\n    -- Recursive member: join with manager\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        mc.level + 1\n    FROM employees e\n    INNER JOIN ManagementChain mc ON e.employee_id = mc.manager_id\n)\nSELECT * FROM ManagementChain;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for the current year, ordered by date.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) :: NUMERIC(10,2) AS moving_avg_7_days\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "Write a PostgreSQL administration query to identify currently active queries that have been running for more than 5 minutes, including the user, database, and the query text.", "output": "SELECT \n    pid,\n    usename,\n    datname,\n    state,\n    age(clock_timestamp(), query_start) AS duration,\n    query\nFROM pg_stat_activity\nWHERE \n    state = 'active' \n    AND query_start < clock_timestamp() - INTERVAL '5 minutes'\n    AND pid <> pg_backend_pid();"}
{"instruction": "Identify 'gaps' in a sequence of order IDs. Assume order IDs should be sequential integers and find any missing numbers between the minimum and maximum ID in the table.", "output": "WITH ExpectedIds AS (\n    SELECT generate_series(MIN(order_id), MAX(order_id)) AS order_id\n    FROM orders\n)\nSELECT e.order_id AS missing_id\nFROM ExpectedIds e\nLEFT JOIN orders o ON e.order_id = o.order_id\nWHERE o.order_id IS NULL;"}
{"instruction": "Perform a 'sessionization' analysis. Group user page views into sessions where a new session starts if the user is inactive for more than 30 minutes. Return the user_id, session_id, and count of views per session.", "output": "WITH LaggedEvents AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        LAG(event_timestamp) OVER (PARTITION BY user_id ORDER BY event_timestamp) AS prev_timestamp\n    FROM page_views\n),\nSessionFlags AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        CASE \n            WHEN prev_timestamp IS NULL OR event_timestamp > prev_timestamp + INTERVAL '30 minutes' THEN 1 \n            ELSE 0 \n        END AS is_new_session\n    FROM LaggedEvents\n),\nSessionIds AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY event_timestamp) AS session_id\n    FROM SessionFlags\n)\nSELECT \n    user_id, \n    session_id, \n    COUNT(*) as events_in_session,\n    MIN(event_timestamp) as session_start,\n    MAX(event_timestamp) as session_end\nFROM SessionIds\nGROUP BY user_id, session_id;"}
{"instruction": "Write a query to delete duplicate rows from a table named 'contacts' based on the email address, keeping only the entry with the lowest ID. Use PostgreSQL's specific `ctid` or a CTE approach.", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY id ASC) as row_num\n        FROM contacts\n    ) t\n    WHERE t.row_num > 1\n);"}
{"instruction": "Pivot a sales table to display total revenue per month for the current year as columns (Jan, Feb, Mar, etc.) using PostgreSQL's `FILTER` clause.", "output": "SELECT \n    product_category,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_revenue,\n    -- ... continue for other months ...\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 12) AS dec_revenue\nFROM sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nGROUP BY product_category;"}
{"instruction": "Write a PostgreSQL administration query to list the top 10 largest tables in the current database, showing both the table size and total size (including indexes), formatted in a human-readable way.", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Calculate the Year-Over-Year (YoY) growth percentage for monthly sales. The result should show the current month, current sales, previous year's sales for the same month, and the growth percentage.", "output": "WITH MonthlySales AS (\n    SELECT \n        DATE_TRUNC('month', sale_date) AS sales_month,\n        SUM(amount) AS total_sales\n    FROM sales\n    GROUP BY 1\n)\nSELECT \n    curr.sales_month,\n    curr.total_sales AS current_sales,\n    prev.total_sales AS prev_year_sales,\n    ROUND(((curr.total_sales - prev.total_sales) / prev.total_sales::numeric) * 100, 2) AS yoy_growth_pct\nFROM MonthlySales curr\nLEFT JOIN MonthlySales prev \n    ON curr.sales_month = prev.sales_month + INTERVAL '1 year'\nORDER BY curr.sales_month DESC;"}
{"instruction": "Write a PostgreSQL query using a Recursive CTE to generate an organizational hierarchy chart. The query should traverse the 'employees' table (columns: id, name, manager_id) starting from the top-level manager (where manager_id is NULL) and calculate the depth level for each employee.", "output": "WITH RECURSIVE org_chart AS (\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 as level,\n        CAST(name AS TEXT) as path\n    FROM employees \n    WHERE manager_id IS NULL\n    \n    UNION ALL\n    \n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Create a query that calculates the 7-day moving average of daily sales. Use a Window Function to average the 'amount' from the current row and the 6 preceding rows, ordered by 'sale_date'.", "output": "SELECT \n    sale_date,\n    SUM(amount) as daily_total,\n    AVG(SUM(amount)) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_average_7_days\nFROM sales\nGROUP BY sale_date\nORDER BY sale_date;"}
{"instruction": "Write a PostgreSQL administration query to list the top 10 largest tables in the database, showing their name, total size (including indexes), and size in a human-readable format.", "output": "SELECT\n    schemaname || '.' || relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_total_relation_size(relid) AS size_bytes\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL JOIN to find the top 3 most recent orders for every customer. Assume tables 'customers' and 'orders' (with 'order_date').", "output": "SELECT \n    c.customer_name,\n    recent_orders.order_id,\n    recent_orders.order_date,\n    recent_orders.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders o\n    WHERE o.customer_id = c.id\n    ORDER BY o.order_date DESC\n    LIMIT 3\n) AS recent_orders;"}
{"instruction": "Write a query to identify 'Gaps' in a sequence of IDs. Given a table 'invoices' with a sequential 'id' column, find the start and end of any missing ranges of IDs.", "output": "WITH lag_ids AS (\n    SELECT \n        id,\n        LAG(id) OVER (ORDER BY id) as prev_id\n    FROM invoices\n)\nSELECT \n    prev_id + 1 as gap_start,\n    id - 1 as gap_end\nFROM lag_ids\nWHERE id - prev_id > 1;"}
{"instruction": "Perform a cohort analysis using CTEs. Calculate the retention rate of users who signed up in January 2023, showing how many were still active (logged in) in subsequent months.", "output": "WITH january_cohort AS (\n    SELECT user_id \n    FROM users \n    WHERE DATE_TRUNC('month', signup_date) = '2023-01-01'\n),\nmonthly_activity AS (\n    SELECT \n        DATE_TRUNC('month', login_date) as activity_month,\n        COUNT(DISTINCT l.user_id) as active_users\n    FROM logins l\n    JOIN january_cohort c ON l.user_id = c.user_id\n    WHERE l.login_date >= '2023-01-01'\n    GROUP BY 1\n)\nSELECT \n    activity_month,\n    active_users,\n    ROUND(active_users::numeric / (SELECT COUNT(*) FROM january_cohort) * 100, 2) as retention_rate\nFROM monthly_activity\nORDER BY activity_month;"}
{"instruction": "Write a PostgreSQL query to identify currently active queries that have been running for more than 5 minutes, excluding the current session's query.", "output": "SELECT\n    pid,\n    now() - query_start AS duration,\n    usename,\n    datname,\n    state,\n    query\nFROM pg_stat_activity\nWHERE state = 'active'\n  AND (now() - query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid()\nORDER BY duration DESC;"}
{"instruction": "Construct a Pivot Table query using conditional aggregation (CASE statements) to display total sales per region (rows) broken down by product category (columns: Electronics, Furniture, Clothing).", "output": "SELECT \n    region,\n    SUM(CASE WHEN category = 'Electronics' THEN amount ELSE 0 END) AS sales_electronics,\n    SUM(CASE WHEN category = 'Furniture' THEN amount ELSE 0 END) AS sales_furniture,\n    SUM(CASE WHEN category = 'Clothing' THEN amount ELSE 0 END) AS sales_clothing,\n    SUM(amount) AS total_sales\nFROM sales_data\nGROUP BY region\nORDER BY region;"}
{"instruction": "Use a Window Function to calculate the Year-Over-Year (YoY) growth percentage for total sales by year.", "output": "WITH yearly_sales AS (\n    SELECT \n        EXTRACT(YEAR FROM order_date) as sales_year,\n        SUM(total_amount) as total_revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT \n    sales_year,\n    total_revenue,\n    LAG(total_revenue) OVER (ORDER BY sales_year) as prev_year_revenue,\n    ROUND(\n        (total_revenue - LAG(total_revenue) OVER (ORDER BY sales_year))::numeric / \n        NULLIF(LAG(total_revenue) OVER (ORDER BY sales_year), 0) * 100\n    , 2) as yoy_growth_percent\nFROM yearly_sales;"}
{"instruction": "Write a query using PostgreSQL JSONB operators to find all rows in a 'products' table where the 'attributes' JSONB column contains a key 'color' with the value 'red', and expand the 'tags' JSON array into separate rows.", "output": "SELECT \n    product_id,\n    product_name,\n    tag\nFROM products,\nLATERAL jsonb_array_elements_text(attributes -> 'tags') as tag\nWHERE attributes @> '{\"color\": \"red\"}';"}
{"instruction": "Use a Recursive CTE to generate a hierarchical view of employees and their managers, calculating the depth level of each employee in the organizational chart.", "output": "WITH RECURSIVE employee_hierarchy AS (\n  SELECT employee_id, first_name, manager_id, 1 AS level\n  FROM employees\n  WHERE manager_id IS NULL\n  UNION ALL\n  SELECT e.employee_id, e.first_name, e.manager_id, eh.level + 1\n  FROM employees e\n  INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy ORDER BY level, employee_id;"}
{"instruction": "Calculate a 7-day moving average of daily sales using window functions.", "output": "SELECT sale_date,\n       daily_total,\n       AVG(daily_total) OVER (\n         ORDER BY sale_date\n         ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n       ) AS moving_average_7d\nFROM daily_sales_summary;"}
{"instruction": "Identify 'Islands' in a Gap and Islands problem: Group consecutive login dates for users to determine the start and end date of every login streak.", "output": "WITH grouped_dates AS (\n  SELECT user_id,\n         login_date,\n         login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n  FROM user_logins\n)\nSELECT user_id,\n       MIN(login_date) AS streak_start,\n       MAX(login_date) AS streak_end,\n       COUNT(*) AS streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Perform a Pivot operation using PostgreSQL's FILTER clause to display total revenue per category for the first three months of the year.", "output": "SELECT category,\n       SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM payment_date) = 1) AS jan_revenue,\n       SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM payment_date) = 2) AS feb_revenue,\n       SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM payment_date) = 3) AS mar_revenue\nFROM payments\nGROUP BY category;"}
{"instruction": "Database Administration: List the top 10 largest tables in the database, including the size of their indexes and TOAST data, formatted in a human-readable size.", "output": "SELECT relname AS table_name,\n       pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL join to retrieve the 3 most recent orders for every customer without aggregating the entire orders table first.", "output": "SELECT c.customer_name,\n       o.order_id,\n       o.order_date,\n       o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n  SELECT order_id, order_date, total_amount\n  FROM orders\n  WHERE customer_id = c.id\n  ORDER BY order_date DESC\n  LIMIT 3\n) o;"}
{"instruction": "Calculate the median and 90th percentile of query execution times per user using ordered-set aggregate functions.", "output": "SELECT username,\n       PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY execution_time_ms) AS median_time,\n       PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY execution_time_ms) AS p90_time\nFROM query_logs\nGROUP BY username;"}
{"instruction": "Database Administration: Identify currently active queries that have been running for more than 5 minutes, excluding the current session.", "output": "SELECT pid,\n       usename,\n       state,\n       now() - query_start AS duration,\n       query\nFROM pg_stat_activity\nWHERE state = 'active'\n  AND now() - query_start > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Perform an UPSERT (Insert or Update) operation: Insert a new product inventory record, or add to the existing quantity if the product ID already exists.", "output": "INSERT INTO inventory (product_id, quantity, last_updated)\nVALUES (105, 50, NOW())\nON CONFLICT (product_id) \nDO UPDATE SET \n  quantity = inventory.quantity + EXCLUDED.quantity,\n  last_updated = EXCLUDED.last_updated;"}
{"instruction": "Rank products within their respective categories by revenue, but handle ties by skipping ranks (e.g., 1, 1, 3) and filter to show only the top 3 products per category.", "output": "WITH ranked_products AS (\n  SELECT category_id,\n         product_name,\n         revenue,\n         RANK() OVER (PARTITION BY category_id ORDER BY revenue DESC) as rn\n  FROM product_sales\n)\nSELECT *\nFROM ranked_products\nWHERE rn <= 3;"}
{"instruction": "Write a recursive CTE to generate an organizational hierarchy tree showing the employee name, their manager's name, and their hierarchical level (depth) starting from the CEO (where manager_id is NULL).", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: The CEO\n    SELECT \n        employee_id, \n        name,\n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the level above\n    SELECT \n        e.employee_id, \n        e.name,\n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for the current year, ensuring rows are ordered by date.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "Identify the top 3 highest-paid employees within each department using a window function, handling ties with dense ranking.", "output": "WITH ranked_employees AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM ranked_employees\nWHERE rank <= 3;"}
{"instruction": "Find all dates in the current month where no login events occurred (gap analysis) using a generated series of dates and a Left Join.", "output": "SELECT \n    calendar_date::DATE as missing_date\nFROM \n    GENERATE_SERIES(\n        DATE_TRUNC('month', CURRENT_DATE), \n        (DATE_TRUNC('month', CURRENT_DATE) + INTERVAL '1 month' - INTERVAL '1 day'), \n        INTERVAL '1 day'\n    ) AS calendar_date\nLEFT JOIN user_logins ul ON ul.login_timestamp::DATE = calendar_date\nWHERE ul.login_id IS NULL;"}
{"instruction": "Use a CROSS JOIN LATERAL to retrieve the most recent order for every active customer without using a window function or GROUP BY.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE orders.customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 1\n) o\nWHERE c.status = 'ACTIVE';"}
{"instruction": "Pivot a sales table to display total revenue per product (rows) broken down by quarter (columns: Q1, Q2, Q3, Q4) for the year 2023.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS \"Q1\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS \"Q2\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS \"Q3\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS \"Q4\"\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_name;"}
{"instruction": "DBA Task: List the top 10 largest tables in the PostgreSQL database, showing the size of the table data, the size of indexes, and the total size, formatted in a human-readable format (e.g., MB/GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_relation_size(C.oid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(C.oid) - pg_relation_size(C.oid)) AS index_size,\n    pg_size_pretty(pg_total_relation_size(C.oid)) AS total_size\nFROM pg_class C\nLEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)\nWHERE nspname NOT IN ('pg_catalog', 'information_schema')\nAND C.relkind <> 'i'\nAND nspname !~ '^pg_toast'\nORDER BY pg_total_relation_size(C.oid) DESC\nLIMIT 10;"}
{"instruction": "Calculate the 'Churn Rate' per month. Churn is defined as the number of users who cancelled divided by the number of active users at the start of the month.", "output": "WITH monthly_stats AS (\n    SELECT \n        DATE_TRUNC('month', event_date) as month,\n        COUNT(CASE WHEN event_type = 'cancel' THEN 1 END) as cancellations,\n        COUNT(CASE WHEN event_type = 'active' THEN 1 END) as active_base\n    FROM subscription_events\n    GROUP BY 1\n)\nSELECT \n    month,\n    cancellations,\n    active_base,\n    ROUND((cancellations::NUMERIC / NULLIF(active_base, 0)) * 100, 2) as churn_percentage\nFROM monthly_stats\nORDER BY month;"}
{"instruction": "DBA Task: Identify unused indexes in the database (indexes that have not been scanned) to optimize storage and write performance.", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    indexrelname AS index_name,\n    idx_scan as number_of_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0\nAND indisunique IS FALSE\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Perform a 'Market Basket Analysis' using a self-join to find pairs of products that are most frequently purchased together in the same transaction.", "output": "SELECT \n    p1.product_id AS product_a,\n    p2.product_id AS product_b,\n    COUNT(*) AS frequency\nFROM order_items p1\nJOIN order_items p2 \n    ON p1.transaction_id = p2.transaction_id \n    AND p1.product_id < p2.product_id -- Avoid duplicates (A-B vs B-A) and self-pairs\nGROUP BY p1.product_id, p2.product_id\nORDER BY frequency DESC\nLIMIT 10;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to find the top 3 performing salespeople by revenue within each sales region for the year 2023.", "output": "WITH RegionalSales AS (\n    SELECT \n        s.region_id,\n        s.salesperson_id,\n        sp.name AS salesperson_name,\n        SUM(s.amount) AS total_revenue\n    FROM sales s\n    JOIN salespeople sp ON s.salesperson_id = sp.id\n    WHERE s.sale_date >= '2023-01-01' AND s.sale_date <= '2023-12-31'\n    GROUP BY s.region_id, s.salesperson_id, sp.name\n),\nRankedSales AS (\n    SELECT \n        region_id,\n        salesperson_name,\n        total_revenue,\n        RANK() OVER (PARTITION BY region_id ORDER BY total_revenue DESC) as rank\n    FROM RegionalSales\n)\nSELECT * \nFROM RankedSales\nWHERE rank <= 3;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of an organization, showing the employee ID, name, manager ID, and their depth level in the hierarchy, starting from the CEO (where manager_id is NULL).", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        0 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' > ' || e.name\n    FROM employees e\n    INNER JOIN OrgChart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM OrgChart\nORDER BY path;"}
{"instruction": "Write a PostgreSQL DBA query to identify the top 10 largest tables in the database, displaying their name, total size (including indexes), and size in a human-readable format.", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_total_relation_size(relid) AS total_size_bytes\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Calculate the 7-day moving average of daily sign-ups. The result should include the date, daily count, and the moving average, handling gaps where no sign-ups occurred by treating them as zero.", "output": "WITH DailySignups AS (\n    SELECT \n        DATE(signup_date) as day,\n        COUNT(*) as signup_count\n    FROM users\n    GROUP BY DATE(signup_date)\n),\nDateSeries AS (\n    -- Generate a continuous series of dates to handle gaps\n    SELECT generate_series(\n        MIN(day), \n        MAX(day), \n        '1 day'::interval\n    )::date as day\n    FROM DailySignups\n)\nSELECT \n    ds.day,\n    COALESCE(d.signup_count, 0) as daily_count,\n    AVG(COALESCE(d.signup_count, 0)) OVER (\n        ORDER BY ds.day \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_day\nFROM DateSeries ds\nLEFT JOIN DailySignups d ON ds.day = d.day\nORDER BY ds.day;"}
{"instruction": "Use a LATERAL JOIN to find the 3 most recent orders for every customer who has placed an order in the last month, returning the customer name, order date, and total amount.", "output": "SELECT \n    c.customer_name,\n    recent_orders.order_date,\n    recent_orders.total_amount\nFROM customers c\nJOIN LATERAL (\n    SELECT \n        o.order_date, \n        o.total_amount\n    FROM orders o\n    WHERE o.customer_id = c.id\n    ORDER BY o.order_date DESC\n    LIMIT 3\n) recent_orders ON true\nWHERE c.last_active_date >= NOW() - INTERVAL '1 month';"}
{"instruction": "Write a query to pivot monthly sales data into columns for the year 2023 (Jan through Dec) for each product category using the `FILTER` clause (ANSI SQL compliant conditional aggregation).", "output": "SELECT \n    category_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 4) AS apr_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 5) AS may_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 6) AS jun_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 7) AS jul_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 8) AS aug_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 9) AS sep_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 10) AS oct_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 11) AS nov_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 12) AS dec_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY category_id;"}
{"instruction": "Identify duplicate records in a `user_logs` table based on `user_id` and `log_timestamp`, and write a DELETE statement to remove the duplicates, keeping only the entry with the lowest unique ID (primary key).", "output": "DELETE FROM user_logs\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (\n                PARTITION BY user_id, log_timestamp \n                ORDER BY id ASC\n            ) as rn\n        FROM user_logs\n    ) sub\n    WHERE rn > 1\n);"}
{"instruction": "Write a PostgreSQL administration query to detect currently active queries that have been running for more than 5 minutes, displaying the username, duration, and the query text.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active'\n  AND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Calculate the 'churn' rate per month. Churn is defined as the number of users who cancelled their subscription in a given month divided by the total number of active subscribers at the start of that month.", "output": "WITH MonthlyStats AS (\n    SELECT \n        DATE_TRUNC('month', status_date) AS month_start,\n        COUNT(*) FILTER (WHERE status = 'active') AS active_start,\n        COUNT(*) FILTER (WHERE status = 'cancelled') AS cancelled_count\n    FROM subscription_history\n    GROUP BY DATE_TRUNC('month', status_date)\n)\nSELECT \n    month_start,\n    cancelled_count,\n    active_start,\n    CASE \n        WHEN active_start = 0 THEN 0\n        ELSE ROUND((cancelled_count::NUMERIC / active_start) * 100, 2) \n    END AS churn_rate_percentage\nFROM MonthlyStats\nORDER BY month_start;"}
{"instruction": "Write a query to identify blocking locks in PostgreSQL. The output should show the PID and query of the blocked process, and the PID and query of the blocking process.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocked_activity.query    AS blocked_query,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query   AS blocking_query\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Write a Recursive CTE to generate a hierarchical view of employees and their managers, including the depth level of the hierarchy and the full path of names from the CEO down to the employee.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 AS depth, \n        CAST(name AS TEXT) AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the hierarchy with employees\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        eh.depth + 1,\n        eh.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.id\n)\nSELECT * FROM employee_hierarchy ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product category using Window Functions.", "output": "SELECT \n    sale_date,\n    category,\n    daily_sales,\n    AVG(daily_sales) OVER (\n        PARTITION BY category \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM (\n    SELECT \n        date(created_at) as sale_date, \n        category, \n        SUM(amount) as daily_sales\n    FROM sales\n    GROUP BY 1, 2\n) subquery\nORDER BY category, sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login streaks. Find the start and end dates of consecutive login streaks for every user.", "output": "WITH distinct_logins AS (\n    SELECT DISTINCT user_id, login_date \n    FROM user_logins\n),\ngrouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (DENSE_RANK() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM distinct_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_length\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "DBA Task: List the top 10 largest tables in the PostgreSQL database, displaying their size in a human-readable format, including indexes and toast data.", "output": "SELECT\n    schemaname AS table_schema,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot a sales table to display total revenue per month (January to June) as columns for each product using PostgreSQL's FILTER clause.", "output": "SELECT \n    product_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 4) AS apr_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 5) AS may_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 6) AS jun_revenue\nFROM sales\nWHERE sale_date >= '2023-01-01' AND sale_date <= '2023-06-30'\nGROUP BY product_id;"}
{"instruction": "Find the top 3 highest-paid employees in each department. If there is a tie in salary, include all tied employees (using DENSE_RANK).", "output": "WITH ranked_employees AS (\n    SELECT \n        dept_id,\n        emp_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY dept_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT * \nFROM ranked_employees \nWHERE rank <= 3;"}
{"instruction": "Perform a LATERAL JOIN to retrieve the 3 most recent comments for each user, optimizing for cases where users have millions of comments.", "output": "SELECT \n    u.username,\n    c.comment_text,\n    c.created_at\nFROM users u\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE user_id = u.id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c;"}
{"instruction": "Calculate Month-over-Month (MoM) percentage growth in revenue using the LAG window function.", "output": "WITH monthly_revenue AS (\n    SELECT \n        DATE_TRUNC('month', payment_date) as month,\n        SUM(amount) as total_revenue\n    FROM payments\n    GROUP BY 1\n)\nSELECT \n    month,\n    total_revenue,\n    LAG(total_revenue) OVER (ORDER BY month) as previous_month_revenue,\n    ROUND(\n        ((total_revenue - LAG(total_revenue) OVER (ORDER BY month)) / \n        NULLIF(LAG(total_revenue) OVER (ORDER BY month), 0)) * 100, \n    2) as growth_percentage\nFROM monthly_revenue;"}
{"instruction": "DBA Task: Identify currently active queries that are waiting on locks, including the PID of the blocking process and the query it is running.", "output": "SELECT\n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Use `generate_series` to find missing dates (days with zero orders) within a specific date range for a reporting dashboard.", "output": "SELECT \n    calendar.day::date as missing_date\nFROM generate_series(\n    '2023-01-01'::timestamp, \n    '2023-01-31'::timestamp, \n    '1 day'::interval\n) AS calendar(day)\nLEFT JOIN orders o ON o.order_date = calendar.day::date\nWHERE o.order_id IS NULL\nORDER BY calendar.day;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to find the top 3 highest-earning employees within each department.", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_id,\n        first_name,\n        last_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_id,\n    first_name,\n    last_name,\n    salary\nFROM RankedSalaries\nWHERE rank <= 3\nORDER BY department_id, rank;"}
{"instruction": "Create a Recursive CTE to traverse an organizational hierarchy (adjacency list) and generate a full path string for each employee (e.g., 'CEO->VP->Manager->Employee').", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n    -- Anchor member: select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        first_name, \n        manager_id, \n        CAST(first_name AS TEXT) as path,\n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.employee_id, \n        e.first_name, \n        e.manager_id, \n        eh.path || '->' || e.first_name,\n        eh.level + 1\n    FROM employees e\n    INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM EmployeeHierarchy\nORDER BY path;"}
{"instruction": "Write a PostgreSQL DBA query to identify currently active queries that have been running for more than 5 minutes, excluding the current session.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes' \n  AND pid <> pg_backend_pid()\nORDER BY duration DESC;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue using a Window Function with a frame clause.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_days\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Use a LATERAL JOIN to retrieve the 3 most recent orders for every customer who resides in 'New York'.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nWHERE c.city = 'New York';"}
{"instruction": "Write a query to delete duplicate rows from a table named 'user_logs' based on 'user_id' and 'log_timestamp', keeping only the entry with the lowest unique ID (primary key).", "output": "DELETE FROM user_logs\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (\n                PARTITION BY user_id, log_timestamp \n                ORDER BY id ASC\n            ) as row_num\n        FROM user_logs\n    ) t\n    WHERE t.row_num > 1\n);"}
{"instruction": "Perform a 'Gap Analysis' to find missing sequence numbers in a table of invoice IDs (assuming IDs should be sequential).", "output": "WITH InvoiceLag AS (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) as next_invoice_id\n    FROM invoices\n)\nSELECT \n    invoice_id + 1 as gap_start,\n    next_invoice_id - 1 as gap_end\nFROM InvoiceLag\nWHERE next_invoice_id - invoice_id > 1;"}
{"instruction": "Write a PostgreSQL DBA query to list the top 10 largest tables in the database, displaying their size in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform a cohort analysis pivot: Count the number of active users per month, grouped by their registration year, using conditional aggregation.", "output": "SELECT \n    EXTRACT(YEAR FROM registration_date) AS reg_year,\n    COUNT(CASE WHEN EXTRACT(MONTH FROM last_active_date) = 1 THEN user_id END) AS Jan,\n    COUNT(CASE WHEN EXTRACT(MONTH FROM last_active_date) = 2 THEN user_id END) AS Feb,\n    COUNT(CASE WHEN EXTRACT(MONTH FROM last_active_date) = 3 THEN user_id END) AS Mar,\n    COUNT(CASE WHEN EXTRACT(MONTH FROM last_active_date) = 4 THEN user_id END) AS Apr,\n    COUNT(CASE WHEN EXTRACT(MONTH FROM last_active_date) = 5 THEN user_id END) AS May,\n    COUNT(CASE WHEN EXTRACT(MONTH FROM last_active_date) = 6 THEN user_id END) AS Jun\nFROM users\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Compare this month's revenue to last month's revenue for each product category and calculate the percentage growth.", "output": "WITH MonthlyStats AS (\n    SELECT \n        category_id,\n        DATE_TRUNC('month', sale_date) as sales_month,\n        SUM(amount) as revenue\n    FROM sales\n    GROUP BY 1, 2\n),\nGrowthCalc AS (\n    SELECT \n        category_id,\n        sales_month,\n        revenue,\n        LAG(revenue) OVER (PARTITION BY category_id ORDER BY sales_month) as prev_month_revenue\n    FROM MonthlyStats\n)\nSELECT \n    category_id,\n    sales_month,\n    revenue,\n    prev_month_revenue,\n    ROUND(((revenue - prev_month_revenue) / NULLIF(prev_month_revenue, 0)) * 100, 2) as growth_percentage\nFROM GrowthCalc\nWHERE prev_month_revenue IS NOT NULL;"}
{"instruction": "Calculate the running total of sales for each salesperson, ordered by the sale date, using a Window Function.", "output": "SELECT \n    salesperson_id,\n    sale_date,\n    sale_amount,\n    SUM(sale_amount) OVER (\n        PARTITION BY salesperson_id \n        ORDER BY sale_date\n    ) AS running_total\nFROM sales;"}
{"instruction": "Write a recursive CTE to generate a hierarchical view of employees and their managers, including the depth level of each employee in the hierarchy.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Top-level managers (no manager)\n    SELECT \n        employee_id, \n        first_name, \n        manager_id, \n        0 AS level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the hierarchy found so far\n    SELECT \n        e.employee_id, \n        e.first_name, \n        e.manager_id, \n        eh.level + 1\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy;"}
{"instruction": "Identify the top 3 highest-paid employees within each department using DENSE_RANK to handle ties appropriately.", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (\n            PARTITION BY department_id \n            ORDER BY salary DESC\n        ) AS rank\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM RankedSalaries\nWHERE rank <= 3;"}
{"instruction": "Find all dates in the current month where no orders were placed. Use `generate_series` (PostgreSQL specific) to create the calendar and a LEFT JOIN to find gaps.", "output": "SELECT \n    calendar_date::DATE\nFROM \n    generate_series(\n        DATE_TRUNC('month', CURRENT_DATE), \n        DATE_TRUNC('month', CURRENT_DATE) + INTERVAL '1 month' - INTERVAL '1 day', \n        INTERVAL '1 day'\n    ) AS calendar_date\nLEFT JOIN orders o ON o.order_date = calendar_date::DATE\nWHERE o.order_id IS NULL;"}
{"instruction": "Perform a pivoting operation (Cross-tabulation) to display total sales per product category for the last three months as separate columns (Month 1, Month 2, Month 3).", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE sale_date >= DATE_TRUNC('month', NOW()) - INTERVAL '2 months' AND sale_date < DATE_TRUNC('month', NOW()) - INTERVAL '1 month') AS month_1_sales,\n    SUM(amount) FILTER (WHERE sale_date >= DATE_TRUNC('month', NOW()) - INTERVAL '1 month' AND sale_date < DATE_TRUNC('month', NOW())) AS month_2_sales,\n    SUM(amount) FILTER (WHERE sale_date >= DATE_TRUNC('month', NOW())) AS current_month_sales\nFROM sales\nGROUP BY category_name;"}
{"instruction": "Calculate the Month-over-Month (MoM) percentage growth in revenue using LAG().", "output": "WITH MonthlyRevenue AS (\n    SELECT \n        DATE_TRUNC('month', order_date) AS order_month,\n        SUM(revenue) AS total_revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT \n    order_month,\n    total_revenue,\n    LAG(total_revenue) OVER (ORDER BY order_month) AS prev_month_revenue,\n    ROUND(\n        (total_revenue - LAG(total_revenue) OVER (ORDER BY order_month)) * 100.0 / \n        NULLIF(LAG(total_revenue) OVER (ORDER BY order_month), 0), \n    2) AS growth_percentage\nFROM MonthlyRevenue;"}
{"instruction": "Use a LATERAL JOIN to retrieve the 2 most recent comments for every blog post without using a correlated subquery in the SELECT clause.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_body,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_body, created_at\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 2\n) c;"}
{"instruction": "DBA Task: Identify currently active queries that have been running for more than 5 minutes to diagnose performance bottlenecks.", "output": "SELECT \n    pid,\n    usename,\n    application_name,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes';"}
{"instruction": "Update a JSONB column to add a new key-value pair ('status': 'verified') for users who have logged in within the last 7 days.", "output": "UPDATE users\nSET profile_data = profile_data || '{\"status\": \"verified\"}'::jsonb\nWHERE last_login >= NOW() - INTERVAL '7 days';"}
{"instruction": "DBA Task: Check the total disk size of a specific table, including its associated indexes and toast data.", "output": "SELECT \n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_and_toast_size\nFROM pg_catalog.pg_stat_user_tables\nWHERE relname = 'target_table_name';"}
{"instruction": "Write a Recursive CTE to generate a hierarchical organization chart showing the path from the CEO down to every employee, including the depth level.", "output": "WITH RECURSIVE org_path AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        name::TEXT AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join with subordinates\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        op.level + 1,\n        op.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_path op ON e.manager_id = op.employee_id\n)\nSELECT * FROM org_path ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product category using window functions.", "output": "SELECT \n    sale_date,\n    category,\n    daily_sales,\n    AVG(daily_sales) OVER (\n        PARTITION BY category \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM (\n    SELECT \n        sale_date,\n        category,\n        SUM(amount) as daily_sales\n    FROM sales\n    GROUP BY sale_date, category\n) subquery\nORDER BY category, sale_date;"}
{"instruction": "DBA Task: Identify the top 10 largest tables in a PostgreSQL database, including both table data and index size, formatted in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Solve the 'Gaps and Islands' problem: Identify consecutive days where a user logged in. Output the user_id, start_date, end_date, and the number of consecutive days.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtract row number from date to create a constant value for consecutive sequences\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as start_date,\n    MAX(login_date) as end_date,\n    COUNT(*) as consecutive_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, start_date;"}
{"instruction": "Use a LATERAL JOIN to efficiently retrieve the 3 most recent orders for every customer who has placed an order in the last month, without scanning the entire orders table for every user.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nWHERE c.last_active_date >= NOW() - INTERVAL '1 month';"}
{"instruction": "DBA Task: Find currently active queries that have been running for more than 5 minutes, excluding the current session's query.", "output": "SELECT \n    pid, \n    usename, \n    application_name, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid()\nORDER BY duration DESC;"}
{"instruction": "Perform a cohort analysis using CTEs to calculate the retention rate of users who signed up in January 2023, showing how many were still active in subsequent months.", "output": "WITH jan_cohort AS (\n    SELECT user_id, DATE_TRUNC('month', signup_date) as cohort_month\n    FROM users\n    WHERE signup_date >= '2023-01-01' AND signup_date < '2023-02-01'\n),\nmonthly_activity AS (\n    SELECT \n        jc.user_id,\n        DATE_TRUNC('month', a.activity_date) as activity_month,\n        EXTRACT(MONTH FROM AGE(DATE_TRUNC('month', a.activity_date), jc.cohort_month)) as month_number\n    FROM jan_cohort jc\n    JOIN activity_log a ON jc.user_id = a.user_id\n)\nSELECT \n    month_number,\n    COUNT(DISTINCT user_id) as active_users,\n    ROUND(COUNT(DISTINCT user_id)::numeric / (SELECT COUNT(*) FROM jan_cohort) * 100, 2) as retention_percentage\nFROM monthly_activity\nGROUP BY month_number\nORDER BY month_number;"}
{"instruction": "Compare inventory counts between two warehouses using a FULL OUTER JOIN and COALESCE to handle missing products in either location.", "output": "SELECT \n    COALESCE(w1.product_id, w2.product_id) AS product_id,\n    COALESCE(w1.product_name, w2.product_name) AS product_name,\n    COALESCE(w1.quantity, 0) AS warehouse_a_qty,\n    COALESCE(w2.quantity, 0) AS warehouse_b_qty,\n    (COALESCE(w1.quantity, 0) - COALESCE(w2.quantity, 0)) AS variance\nFROM inventory_warehouse_a w1\nFULL OUTER JOIN inventory_warehouse_b w2 \n    ON w1.product_id = w2.product_id\nWHERE COALESCE(w1.quantity, 0) <> COALESCE(w2.quantity, 0);"}
{"instruction": "Calculate the Year-Over-Year (YoY) growth percentage for monthly revenue using the LAG window function.", "output": "WITH monthly_revenue AS (\n    SELECT \n        DATE_TRUNC('year', order_date) as sales_year,\n        EXTRACT(MONTH FROM order_date) as sales_month,\n        SUM(amount) as revenue\n    FROM orders\n    GROUP BY 1, 2\n)\nSELECT \n    sales_year,\n    sales_month,\n    revenue,\n    LAG(revenue, 12) OVER (ORDER BY sales_year, sales_month) as prev_year_revenue,\n    ROUND(\n        ((revenue - LAG(revenue, 12) OVER (ORDER BY sales_year, sales_month)) / \n        NULLIF(LAG(revenue, 12) OVER (ORDER BY sales_year, sales_month), 0)) * 100, \n    2) as yoy_growth_pct\nFROM monthly_revenue;"}
{"instruction": "DBA Task: Identify unused indexes in a PostgreSQL database to optimize storage and write performance.", "output": "SELECT \n    schemaname || '.' || relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(i.indexrelid)) AS index_size,\n    idx_scan as index_scans\nFROM pg_stat_user_indexes i\nJOIN pg_index using (indexrelid)\nWHERE idx_scan = 0 \n  AND indisunique IS FALSE\nORDER BY pg_relation_size(i.indexrelid) DESC;"}
{"instruction": "Write a query to identify the top 3 highest-paid employees within each department. Handle ties by including all employees with the same salary rank (e.g., if two people are tied for 2nd, both should be listed, and the next person is 3rd).", "output": "WITH RankedSalaries AS (\n    SELECT \n        employee_id,\n        department_id,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank\n    FROM employees\n)\nSELECT \n    employee_id,\n    department_id,\n    salary,\n    salary_rank\nFROM RankedSalaries\nWHERE salary_rank <= 3;"}
{"instruction": "Using a Recursive CTE, generate a hierarchical view of employees showing the path from the CEO (manager_id IS NULL) down to every employee, including their depth in the organization.", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: The CEO / Top level\n    SELECT \n        employee_id, \n        name,\n        manager_id,\n        1 as depth,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the previous level\n    SELECT \n        e.employee_id, \n        e.name,\n        e.manager_id,\n        o.depth + 1,\n        o.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN OrgChart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM OrgChart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for the current year. The result should show the date, daily revenue, and the moving average.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) :: NUMERIC(10,2) AS moving_avg_7_days\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "PostgreSQL Administration: Write a query to identify user-defined indexes that have not been used (scanned) since the database statistics were last reset, excluding primary keys and unique constraints.", "output": "SELECT \n    schemaname, \n    relname AS table_name, \n    indexrelname AS index_name, \n    idx_scan AS index_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0 \n  AND indisunique IS FALSE\n  AND indisprimary IS FALSE\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Find customers who have placed orders in three consecutive months. Assume an 'orders' table exists with 'customer_id' and 'order_date'.", "output": "WITH MonthlyActivity AS (\n    SELECT DISTINCT \n        customer_id,\n        DATE_TRUNC('month', order_date) as order_month\n    FROM orders\n),\nLaggedActivity AS (\n    SELECT \n        customer_id,\n        order_month,\n        LAG(order_month, 1) OVER (PARTITION BY customer_id ORDER BY order_month) as prev_month,\n        LAG(order_month, 2) OVER (PARTITION BY customer_id ORDER BY order_month) as prev_prev_month\n    FROM MonthlyActivity\n)\nSELECT DISTINCT customer_id\nFROM LaggedActivity\nWHERE \n    prev_month = order_month - INTERVAL '1 month'\n    AND prev_prev_month = order_month - INTERVAL '2 months';"}
{"instruction": "Perform a gap analysis to find missing sequence numbers in the 'invoice_id' column of the 'invoices' table. Return the start and end of any gap greater than 1.", "output": "SELECT \n    invoice_id + 1 AS gap_start,\n    next_id - 1 AS gap_end\nFROM (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) AS next_id\n    FROM invoices\n) sub\nWHERE next_id > invoice_id + 1;"}
{"instruction": "Using a LATERAL JOIN, retrieve the top 2 most recent orders for every customer who has spent more than $10,000 in total lifetime value.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nJOIN (\n    SELECT customer_id \n    FROM orders \n    GROUP BY customer_id \n    HAVING SUM(total_amount) > 10000\n) high_spenders ON c.customer_id = high_spenders.customer_id\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders \n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 2\n) o;"}
{"instruction": "PostgreSQL Administration: Identify currently active queries that are being blocked by other transactions, showing the blocked PID, the blocking PID, and the query text for both.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocked_activity.query    AS blocked_query,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query   AS blocking_query\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate Year-Over-Year (YoY) growth percentage for monthly revenue. The output should include the month, current year revenue, previous year revenue, and the growth percentage.", "output": "WITH MonthlyRevenue AS (\n    SELECT \n        DATE_TRUNC('month', payment_date) as month_start,\n        SUM(amount) as revenue\n    FROM payments\n    GROUP BY 1\n)\nSELECT \n    month_start,\n    revenue as current_revenue,\n    LAG(revenue, 12) OVER (ORDER BY month_start) as prev_year_revenue,\n    ROUND(\n        ((revenue - LAG(revenue, 12) OVER (ORDER BY month_start)) \n        / NULLIF(LAG(revenue, 12) OVER (ORDER BY month_start), 0)) * 100\n    , 2) as yoy_growth_pct\nFROM MonthlyRevenue;"}
{"instruction": "Aggregate product attributes stored in a Key-Value table (product_id, attribute_key, attribute_value) into a single JSONB object per product.", "output": "SELECT \n    product_id,\n    jsonb_object_agg(attribute_key, attribute_value) AS attributes_json\nFROM product_attributes\nGROUP BY product_id;"}
{"instruction": "Write a Recursive CTE to generate a hierarchical organization chart showing the path from the top manager down to every employee.", "output": "WITH RECURSIVE org_chart AS (\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as path, \n        1 as level\n    FROM employees \n    WHERE manager_id IS NULL\n    \n    UNION ALL\n    \n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        o.path || ' -> ' || e.name,\n        o.level + 1\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Identify 'Gaps and Islands' in user login data to find streaks of consecutive login days for each user.", "output": "WITH data AS (\n    SELECT DISTINCT \n        user_id, \n        login_date,\n        DENSE_RANK() OVER (PARTITION BY user_id ORDER BY login_date) as rn\n    FROM user_logins\n),\ngroupings AS (\n    SELECT \n        user_id, \n        login_date,\n        login_date - (rn * INTERVAL '1 day') as group_id\n    FROM data\n)\nSELECT \n    user_id, \n    MIN(login_date) as streak_start, \n    MAX(login_date) as streak_end, \n    COUNT(*) as consecutive_days\nFROM groupings\nGROUP BY user_id, group_id\nHAVING COUNT(*) >= 3\nORDER BY user_id, streak_start;"}
{"instruction": "Use a Lateral Join to retrieve the top 3 most recent orders for every customer without using a window function in the select clause.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Calculate the Month-over-Month (MoM) percentage growth in sales using Window Functions.", "output": "SELECT \n    DATE_TRUNC('month', order_date) as sales_month,\n    SUM(amount) as current_sales,\n    LAG(SUM(amount)) OVER (ORDER BY DATE_TRUNC('month', order_date)) as previous_sales,\n    ROUND(\n        (SUM(amount) - LAG(SUM(amount)) OVER (ORDER BY DATE_TRUNC('month', order_date))) / \n        NULLIF(LAG(SUM(amount)) OVER (ORDER BY DATE_TRUNC('month', order_date)), 0) * 100\n    , 2) as growth_percentage\nFROM sales\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "DBA Task: Identify unused indexes in a PostgreSQL database to optimize storage and write performance.", "output": "SELECT \n    schemaname, \n    relname AS table_name, \n    indexrelname AS index_name,\n    idx_scan AS number_of_scans,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0 \nAND indexrelname NOT LIKE '%_pkey' -- Exclude primary keys\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Perform a 'Running Total' calculation that resets every time a specific cumulative threshold (e.g., 1000) is reached.", "output": "/* Note: Standard SQL window functions cannot easily self-reference the running total for conditional resets. This requires a Recursive CTE. */\nWITH RECURSIVE running_sales AS (\n    SELECT \n        id, \n        amount, \n        amount as current_total, \n        1 as batch_id\n    FROM sales \n    WHERE id = 1\n    \n    UNION ALL\n    \n    SELECT \n        s.id, \n        s.amount,\n        CASE \n            WHEN rs.current_total + s.amount > 1000 THEN s.amount\n            ELSE rs.current_total + s.amount \n        END,\n        CASE \n            WHEN rs.current_total + s.amount > 1000 THEN rs.batch_id + 1\n            ELSE rs.batch_id \n        END\n    FROM sales s\n    JOIN running_sales rs ON s.id = rs.id + 1\n)\nSELECT * FROM running_sales;"}
{"instruction": "DBA Task: Find currently blocking queries (locks) in PostgreSQL.", "output": "SELECT\n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS blocking_statement\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Pivot a table dynamically using JSON aggregation to show sales by category as columns for each year.", "output": "SELECT \n    EXTRACT(YEAR FROM order_date) as sales_year,\n    jsonb_object_agg(category, total_sales) as category_sales\nFROM (\n    SELECT \n        order_date, \n        category, \n        SUM(amount) as total_sales\n    FROM sales_data\n    GROUP BY 1, 2\n) sub\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Delete duplicate rows from a table based on specific columns, keeping only the entry with the lowest ID (using CTE and ctid for Postgres).", "output": "WITH duplicates AS (\n    SELECT \n        ctid, \n        ROW_NUMBER() OVER (\n            PARTITION BY email, username \n            ORDER BY id ASC\n        ) as rn\n    FROM users\n)\nDELETE FROM users\nWHERE ctid IN (\n    SELECT ctid \n    FROM duplicates \n    WHERE rn > 1\n);"}
{"instruction": "DBA Task: Analyze table bloat and total size including indexes.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size,\n    n_live_tup AS live_rows,\n    n_dead_tup AS dead_rows,\n    ROUND(n_dead_tup::numeric / (n_live_tup + n_dead_tup + 0.0001) * 100, 2) AS dead_tuple_ratio\nFROM pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to find the top 3 performing sales representatives in each region based on total revenue generated.", "output": "WITH SalesSummary AS (\n    SELECT \n        region_id,\n        sales_rep_id,\n        SUM(order_amount) as total_revenue\n    FROM sales\n    GROUP BY region_id, sales_rep_id\n),\nRankedSales AS (\n    SELECT \n        region_id,\n        sales_rep_id,\n        total_revenue,\n        RANK() OVER (PARTITION BY region_id ORDER BY total_revenue DESC) as rank\n    FROM SalesSummary\n)\nSELECT * \nFROM RankedSales \nWHERE rank <= 3;"}
{"instruction": "Create a recursive CTE to traverse an employee hierarchy and retrieve the management chain (all managers up to the CEO) for a specific employee with ID 42.", "output": "WITH RECURSIVE ManagementChain AS (\n    -- Anchor member: select the specific employee\n    SELECT employee_id, manager_id, full_name, 0 as level\n    FROM employees\n    WHERE employee_id = 42\n    \n    UNION ALL\n    \n    -- Recursive member: join with the manager\n    SELECT e.employee_id, e.manager_id, e.full_name, mc.level + 1\n    FROM employees e\n    INNER JOIN ManagementChain mc ON e.employee_id = mc.manager_id\n)\nSELECT * FROM ManagementChain;"}
{"instruction": "Write a PostgreSQL query to identify 'Islands' of consecutive login dates for a user. The output should show the start date, end date, and count of consecutive days.", "output": "WITH Dates AS (\n    SELECT DISTINCT login_date\n    FROM user_logins\n    WHERE user_id = 101\n),\nGroups AS (\n    SELECT \n        login_date,\n        login_date - (ROW_NUMBER() OVER (ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM Dates\n)\nSELECT \n    MIN(login_date) as start_date,\n    MAX(login_date) as end_date,\n    COUNT(*) as consecutive_days\nFROM Groups\nGROUP BY grp\nORDER BY start_date;"}
{"instruction": "Perform a 'Pivot' operation using conditional aggregation to display total sales per product category (rows) for each quarter (columns) of the current year.", "output": "SELECT \n    category_name,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM order_date) = 1 THEN amount ELSE 0 END) AS Q1_Sales,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM order_date) = 2 THEN amount ELSE 0 END) AS Q2_Sales,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM order_date) = 3 THEN amount ELSE 0 END) AS Q3_Sales,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM order_date) = 4 THEN amount ELSE 0 END) AS Q4_Sales\nFROM sales\nWHERE EXTRACT(YEAR FROM order_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY category_name;"}
{"instruction": "Write a query to calculate the 7-day moving average of daily website visits using a window function with a frame clause.", "output": "SELECT \n    visit_date,\n    daily_visits,\n    AVG(daily_visits) OVER (\n        ORDER BY visit_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) :: NUMERIC(10,2) as moving_avg_7d\nFROM site_traffic\nORDER BY visit_date;"}
{"instruction": "Write a PostgreSQL administration query to list the top 10 largest tables in the database, including their index size, displayed in a human-readable format.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use PostgreSQL JSONB functions to query a table `orders` with a `metadata` JSONB column. Find all orders where the 'customer_type' key inside `metadata` is 'VIP' and the 'tags' array contains 'urgent'.", "output": "SELECT order_id, metadata\nFROM orders\nWHERE metadata ->> 'customer_type' = 'VIP'\nAND metadata -> 'tags' ? 'urgent';"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation. Insert a new inventory record for product_id 500. If the product_id already exists, update the stock count by adding the new quantity.", "output": "INSERT INTO inventory (product_id, stock_count, last_updated)\nVALUES (500, 10, NOW())\nON CONFLICT (product_id) \nDO UPDATE SET \n    stock_count = inventory.stock_count + EXCLUDED.stock_count,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Write a query to find the difference in days between the current order and the previous order for each customer using LAG().", "output": "SELECT \n    customer_id,\n    order_id,\n    order_date,\n    LAG(order_date) OVER (PARTITION BY customer_id ORDER BY order_date) as previous_order_date,\n    order_date - LAG(order_date) OVER (PARTITION BY customer_id ORDER BY order_date) as days_since_last_order\nFROM orders;"}
{"instruction": "Write a DBA query to identify currently active queries that have been running for more than 5 minutes, excluding the current query itself.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start as duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes' \n  AND pid <> pg_backend_pid();"}
{"instruction": "Write a recursive CTE to traverse an employee hierarchy and calculate the depth (level) of each employee in the organization chart, starting from the CEO (manager_id is NULL).", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE with employees to find direct reports\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY level, manager_id;"}
{"instruction": "Find the top 3 highest-paid employees within each department using window functions, handling ties by allowing skipping ranks (using RANK) or not skipping (using DENSE_RANK).", "output": "SELECT \n    department_id,\n    employee_name,\n    salary,\n    ranking\nFROM (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as ranking\n    FROM employees\n) sub\nWHERE ranking <= 3;"}
{"instruction": "Create a query to identify 'Gaps and Islands' in user login data. Specifically, group consecutive login dates together to identify periods of continuous activity.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as start_streak,\n    MAX(login_date) as end_streak,\n    COUNT(*) as streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, start_streak;"}
{"instruction": "Write a PostgreSQL administration query to find the total size (data + indexes) of the 10 largest tables in the current database, formatted in a human-readable size.", "output": "SELECT \n    schemaname AS schema_name,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Pivot a sales table to show total sales per product category for each month (January to March) as columns. Use the PostgreSQL FILTER clause for aggregation.", "output": "SELECT \n    product_category,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) AS q1_total\nFROM sales\nWHERE sale_date BETWEEN '2023-01-01' AND '2023-03-31'\nGROUP BY product_category;"}
{"instruction": "Calculate the 7-day moving average of daily revenue using a window function.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM (\n    SELECT \n        DATE(created_at) as sale_date, \n        SUM(amount) as daily_revenue\n    FROM orders\n    GROUP BY DATE(created_at)\n) daily_data\nORDER BY sale_date;"}
{"instruction": "Identify duplicate records in a 'customer_contacts' table based on email address and delete all but the most recently updated record.", "output": "DELETE FROM customer_contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY updated_at DESC) as rn\n        FROM customer_contacts\n    ) sub\n    WHERE rn > 1\n);"}
{"instruction": "Query a PostgreSQL JSONB column named 'attributes' to find all products where the color is 'red' and calculate the average weight (stored inside the JSON) for those products.", "output": "SELECT \n    category,\n    AVG((attributes->>'weight')::NUMERIC) as avg_weight\nFROM products\nWHERE attributes @> '{\"color\": \"red\"}'\nGROUP BY category;"}
{"instruction": "Write a database administration query to identify currently running queries that have been active for more than 5 minutes, excluding the current session.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) as duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle'\n  AND query_start < clock_timestamp() - INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid()\nORDER BY duration DESC;"}
{"instruction": "Perform a Cohort Analysis to calculate the retention rate. Count how many users signed up in a specific month (Cohort) and how many of them were active in subsequent months.", "output": "WITH cohort_items AS (\n  SELECT\n    date_trunc('month', u.signup_date) AS cohort_month,\n    u.user_id\n  FROM users u\n),\nuser_activities AS (\n  SELECT\n    u.user_id,\n    date_trunc('month', a.activity_date) AS activity_month\n  FROM activity_log a\n  JOIN users u ON a.user_id = u.user_id\n  GROUP BY 1, 2\n)\nSELECT\n  C.cohort_month,\n  A.activity_month,\n  count(DISTINCT A.user_id) AS active_users\nFROM cohort_items C\nLEFT JOIN user_activities A \n  ON C.user_id = A.user_id \n  AND A.activity_month >= C.cohort_month\nGROUP BY 1, 2\nORDER BY 1, 2;"}
{"instruction": "Write a query to find the top 3 highest-grossing products within each product category for the year 2023. Use a Window Function.", "output": "WITH RankedProducts AS (\n    SELECT \n        p.category_id,\n        p.product_name,\n        SUM(s.amount) as total_revenue,\n        DENSE_RANK() OVER (PARTITION BY p.category_id ORDER BY SUM(s.amount) DESC) as rank\n    FROM products p\n    JOIN sales s ON p.product_id = s.product_id\n    WHERE s.sale_date >= '2023-01-01' AND s.sale_date <= '2023-12-31'\n    GROUP BY p.category_id, p.product_name\n)\nSELECT \n    category_id,\n    product_name,\n    total_revenue\nFROM RankedProducts\nWHERE rank <= 3;"}
{"instruction": "Create a Recursive CTE to generate an organizational hierarchy path for all employees, showing the chain of command from the CEO (manager_id IS NULL) down to every employee.", "output": "WITH RECURSIVE OrgPath AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as path,\n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n    \n    UNION ALL\n    \n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        op.path || ' -> ' || e.name,\n        op.level + 1\n    FROM employees e\n    INNER JOIN OrgPath op ON e.manager_id = op.employee_id\n)\nSELECT * FROM OrgPath ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of stock prices for each ticker symbol, ordered by date.", "output": "SELECT \n    ticker_symbol,\n    trade_date,\n    close_price,\n    AVG(close_price) OVER (\n        PARTITION BY ticker_symbol \n        ORDER BY trade_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM stock_prices\nORDER BY ticker_symbol, trade_date;"}
{"instruction": "Write a PostgreSQL administration query to list the size of all tables in the current database schema, including indexes, formatted in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Identify users who placed orders in January 2024 but did not place any orders in February 2024 using a standard SQL approach (avoiding database-specific syntax where possible).", "output": "SELECT DISTINCT u.user_id, u.email\nFROM users u\nJOIN orders o_jan ON u.user_id = o_jan.user_id\nWHERE o_jan.order_date >= '2024-01-01' AND o_jan.order_date < '2024-02-01'\nAND NOT EXISTS (\n    SELECT 1 \n    FROM orders o_feb \n    WHERE o_feb.user_id = u.user_id \n    AND o_feb.order_date >= '2024-02-01' AND o_feb.order_date < '2024-03-01'\n);"}
{"instruction": "Use a PostgreSQL `LATERAL` join to retrieve the 3 most recent comments for every blog post published in the last month.", "output": "SELECT \n    p.post_id,\n    p.title,\n    r.comment_text,\n    r.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments c\n    WHERE c.post_id = p.post_id\n    ORDER BY c.created_at DESC\n    LIMIT 3\n) r\nWHERE p.published_date >= NOW() - INTERVAL '1 month';"}
{"instruction": "Write a query to identify and terminate any PostgreSQL queries that have been running for more than 5 minutes, excluding the current query session.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    query_start,\n    now() - query_start AS duration,\n    query,\n    pg_terminate_backend(pid) as terminated\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > interval '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Pivot a sales table using conditional aggregation to show total sales per product for Q1, Q2, Q3, and Q4 in a single row per product.", "output": "SELECT \n    product_id,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM sale_date) = 1 THEN amount ELSE 0 END) AS Q1_Sales,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM sale_date) = 2 THEN amount ELSE 0 END) AS Q2_Sales,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM sale_date) = 3 THEN amount ELSE 0 END) AS Q3_Sales,\n    SUM(CASE WHEN EXTRACT(QUARTER FROM sale_date) = 4 THEN amount ELSE 0 END) AS Q4_Sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_id;"}
{"instruction": "Write a query to delete duplicate rows from a table named `customer_leads` based on `email`, keeping only the entry with the latest `created_at` timestamp.", "output": "DELETE FROM customer_leads\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY created_at DESC) as rn\n        FROM customer_leads\n    ) t\n    WHERE t.rn > 1\n);"}
{"instruction": "Query a PostgreSQL table with a JSONB column named `attributes` to find all products that are colored 'Red' and have a 'size' attribute explicitly defined.", "output": "SELECT \n    product_id, \n    product_name, \n    attributes\nFROM products\nWHERE attributes ->> 'color' = 'Red'\nAND attributes ? 'size';"}
{"instruction": "Write a recursive Common Table Expression (CTE) query to generate a hierarchical view of employees and their managers, showing the employee's name, their manager's name, and their level in the organizational hierarchy (depth).", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Create a query using Window Functions to calculate the 3-day moving average of sales revenue for each store, ordered by date.", "output": "SELECT \n    store_id,\n    sale_date,\n    revenue,\n    AVG(revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_3_day\nFROM daily_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Solve the 'Gaps and Islands' problem: Identify groups of consecutive days where a user logged in. Return the user_id, the start date of the streak, the end date of the streak, and the number of consecutive days.", "output": "WITH grouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as consecutive_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a PostgreSQL LATERAL JOIN to find the top 3 most recent orders for every customer without using a complex window function in the WHERE clause.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nORDER BY c.customer_id, o.order_date DESC;"}
{"instruction": "Write a query to pivot monthly sales data from rows (columns: year, month, amount) into columns (columns: year, jan_sales, feb_sales, ... dec_sales) using ANSI SQL aggregation.", "output": "SELECT \n    year,\n    SUM(CASE WHEN month = 1 THEN amount ELSE 0 END) AS jan_sales,\n    SUM(CASE WHEN month = 2 THEN amount ELSE 0 END) AS feb_sales,\n    SUM(CASE WHEN month = 3 THEN amount ELSE 0 END) AS mar_sales,\n    SUM(CASE WHEN month = 4 THEN amount ELSE 0 END) AS apr_sales,\n    SUM(CASE WHEN month = 5 THEN amount ELSE 0 END) AS may_sales,\n    SUM(CASE WHEN month = 6 THEN amount ELSE 0 END) AS jun_sales,\n    SUM(CASE WHEN month = 7 THEN amount ELSE 0 END) AS jul_sales,\n    SUM(CASE WHEN month = 8 THEN amount ELSE 0 END) AS aug_sales,\n    SUM(CASE WHEN month = 9 THEN amount ELSE 0 END) AS sep_sales,\n    SUM(CASE WHEN month = 10 THEN amount ELSE 0 END) AS oct_sales,\n    SUM(CASE WHEN month = 11 THEN amount ELSE 0 END) AS nov_sales,\n    SUM(CASE WHEN month = 12 THEN amount ELSE 0 END) AS dec_sales\nFROM sales\nGROUP BY year\nORDER BY year;"}
{"instruction": "Write a query to delete duplicate rows from a table named 'contacts' based on the email address, keeping only the record with the lowest ID.", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY id ASC) as rn\n        FROM contacts\n    ) t\n    WHERE rn > 1\n);"}
{"instruction": "DBA Task: Write a PostgreSQL query to list the top 10 largest tables in the database, including the size of their indexes, displaying the output in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Calculate the Month-over-Month (MoM) percentage growth in revenue using Window Functions.", "output": "WITH monthly_revenue AS (\n    SELECT \n        DATE_TRUNC('month', order_date) AS month,\n        SUM(amount) AS revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT \n    month,\n    revenue,\n    LAG(revenue) OVER (ORDER BY month) AS prev_month_revenue,\n    ROUND(\n        ((revenue - LAG(revenue) OVER (ORDER BY month)) / NULLIF(LAG(revenue) OVER (ORDER BY month), 0)) * 100, \n        2\n    ) AS mom_growth_percentage\nFROM monthly_revenue;"}
{"instruction": "DBA Task: Identify currently active queries in PostgreSQL that have been running for more than 5 minutes, showing the user, the duration, and the query text.", "output": "SELECT \n    pid,\n    usename AS user,\n    state,\n    age(clock_timestamp(), query_start) AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND age(clock_timestamp(), query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "DBA Task: Find unused indexes in the current PostgreSQL database (indexes that have not been scanned), excluding primary keys and unique constraints.", "output": "SELECT \n    schemaname,\n    relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as scan_count\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0\n  AND indisunique IS FALSE\n  AND indisprimary IS FALSE\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Write a Recursive CTE in PostgreSQL to find the management hierarchy for a specific employee (ID 50), returning the path from the top-level manager down to the employee.", "output": "WITH RECURSIVE ManagementChain AS (\n    -- Anchor member: Start with the specific employee\n    SELECT employee_id, manager_id, full_name, 1 as level, CAST(full_name AS TEXT) as path\n    FROM employees\n    WHERE employee_id = 50\n\n    UNION ALL\n\n    -- Recursive member: Join with the manager to move up the hierarchy\n    SELECT e.employee_id, e.manager_id, e.full_name, mc.level + 1, e.full_name || ' -> ' || mc.path\n    FROM employees e\n    INNER JOIN ManagementChain mc ON e.employee_id = mc.manager_id\n)\nSELECT * FROM ManagementChain\nORDER BY level DESC;"}
{"instruction": "Create a query to identify 'Gaps and Islands' in user login data. Find all consecutive ranges of days a user logged in without missing a day.", "output": "WITH DailyLogins AS (\n    SELECT DISTINCT user_id, login_date\n    FROM user_logs\n),\nGroupedLogins AS (\n    SELECT \n        user_id, \n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM DailyLogins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM GroupedLogins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a PostgreSQL administrative query to identify currently locked tables and the queries causing those blocks.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate the 7-day moving average of sales revenue for each store using Window Functions.", "output": "SELECT \n    store_id,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM (\n    SELECT store_id, sale_date, SUM(amount) as daily_revenue\n    FROM sales\n    GROUP BY store_id, sale_date\n) daily_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Use a LATERAL JOIN to retrieve the top 3 most recent comments for every blog post without using a Window Function in the SELECT clause.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_id,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_id, comment_text, created_at\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c;"}
{"instruction": "Write a query to delete duplicate rows from a table named 'audit_logs' based on 'event_id' and 'log_message', keeping only the record with the latest timestamp. Use the PostgreSQL CTID system column for efficiency.", "output": "DELETE FROM audit_logs a\nUSING audit_logs b\nWHERE \n    a.event_id = b.event_id \n    AND a.log_message = b.log_message \n    AND a.created_at < b.created_at\n    -- Identify the specific physical row to delete\n    AND a.ctid < b.ctid;"}
{"instruction": "Perform a Pivot operation using FILTER clauses (PostgreSQL specific) to display total sales for 'Electronics', 'Clothing', and 'Home' categories per month.", "output": "SELECT \n    DATE_TRUNC('month', sale_date) as sales_month,\n    SUM(amount) FILTER (WHERE category = 'Electronics') as electronics_sales,\n    SUM(amount) FILTER (WHERE category = 'Clothing') as clothing_sales,\n    SUM(amount) FILTER (WHERE category = 'Home') as home_sales\nFROM sales\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Identify unused indexes in the current PostgreSQL database to assist with performance tuning and space reclamation.", "output": "SELECT \n    schemaname || '.' || relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as number_of_scans\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0 \nAND NOT indisunique -- Keep unique indexes as they enforce constraints\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Query a JSONB column 'attributes' in a 'products' table to find items where the 'specifications' key contains a 'warranty_years' greater than 2.", "output": "SELECT \n    product_id, \n    name, \n    attributes \nFROM products \nWHERE \n    (attributes -> 'specifications' ->> 'warranty_years')::numeric > 2;"}
{"instruction": "Compare two tables, 'inventory_system_a' and 'inventory_system_b', using a FULL OUTER JOIN to find discrepancies in stock counts (items present in one but not the other, or count mismatches).", "output": "SELECT \n    COALESCE(a.sku, b.sku) as sku,\n    a.quantity as qty_system_a,\n    b.quantity as qty_system_b,\n    CASE \n        WHEN a.sku IS NULL THEN 'Missing in A'\n        WHEN b.sku IS NULL THEN 'Missing in B'\n        WHEN a.quantity <> b.quantity THEN 'Count Mismatch'\n        ELSE 'Match'\n    END as status\nFROM inventory_system_a a\nFULL OUTER JOIN inventory_system_b b ON a.sku = b.sku\nWHERE a.quantity IS DISTINCT FROM b.quantity;"}
{"instruction": "Write a Recursive CTE to traverse an employee hierarchy and generate a full reporting path (breadcrumbs) from the CEO down to every employee, including their depth level in the organization.", "output": "WITH RECURSIVE employee_path AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        manager_id, \n        full_name, \n        CAST(full_name AS TEXT) as path,\n        1 as level\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join subordinates to their managers\n    SELECT \n        e.employee_id, \n        e.manager_id, \n        e.full_name, \n        ep.path || ' > ' || e.full_name,\n        ep.level + 1\n    FROM employees e\n    INNER JOIN employee_path ep ON e.manager_id = ep.employee_id\n)\nSELECT * FROM employee_path ORDER BY path;"}
{"instruction": "Identify 'islands' of consecutive login activity. Write a query that finds the start date, end date, and length of every streak of consecutive daily logins for each user.", "output": "WITH dated_logins AS (\n    SELECT DISTINCT user_id, login_date \n    FROM user_logins\n),\ngrouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a grouping identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM dated_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a Window Function to calculate the 7-day moving average of sales revenue, ordered by date.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Write a PostgreSQL administrative query to identify the top 10 largest tables in the database, showing their size in a human-readable format (including indexes).", "output": "SELECT \n    schemaname as schema, \n    relname as table_name, \n    pg_size_pretty(pg_total_relation_size(relid)) as total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform a 'Pivot' operation using conditional aggregation to display total sales for specific product categories ('Electronics', 'Furniture', 'Clothing') as separate columns for each region.", "output": "SELECT \n    region,\n    SUM(CASE WHEN category = 'Electronics' THEN amount ELSE 0 END) as electronics_sales,\n    SUM(CASE WHEN category = 'Furniture' THEN amount ELSE 0 END) as furniture_sales,\n    SUM(CASE WHEN category = 'Clothing' THEN amount ELSE 0 END) as clothing_sales\nFROM sales_transactions\nGROUP BY region;"}
{"instruction": "Write a query using a LATERAL join to retrieve the top 3 most recent comments for every blog post published in 2023, avoiding a full scan of the comments table.", "output": "SELECT \n    p.post_id, \n    p.title, \n    c.comment_text, \n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at \n    FROM comments \n    WHERE post_id = p.post_id \n    ORDER BY created_at DESC \n    LIMIT 3\n) c\nWHERE p.published_date >= '2023-01-01' AND p.published_date < '2024-01-01';"}
{"instruction": "Calculate the retention rate: Find the percentage of users who signed up in January 2023 and made a purchase within 30 days of their signup.", "output": "WITH january_signups AS (\n    SELECT user_id, signup_date \n    FROM users \n    WHERE signup_date BETWEEN '2023-01-01' AND '2023-01-31'\n)\nSELECT \n    COUNT(DISTINCT CASE \n        WHEN p.purchase_date BETWEEN js.signup_date AND js.signup_date + INTERVAL '30 days' \n        THEN js.user_id \n    END)::FLOAT / COUNT(DISTINCT js.user_id) * 100 as retention_rate_percent\nFROM january_signups js\nLEFT JOIN purchases p ON js.user_id = p.user_id;"}
{"instruction": "Write a PostgreSQL query to detect blocking locks: Identify queries that are currently waiting for a lock and the specific query that is blocking them.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Use `DENSE_RANK()` to find the second highest salary per department. If a department has less than 2 employees, exclude it.", "output": "WITH ranked_salaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rnk\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM ranked_salaries\nWHERE rnk = 2;"}
{"instruction": "Write a query to extract data from a JSONB column. Given a table `events` with a column `payload` (JSONB), count the occurrences of each unique 'event_type' where the 'status' key inside the JSON is 'failed'.", "output": "SELECT \n    payload ->> 'event_type' as event_type,\n    COUNT(*)\nFROM events\nWHERE payload ->> 'status' = 'failed'\nGROUP BY payload ->> 'event_type'\nORDER BY COUNT(*) DESC;"}
{"instruction": "Write a recursive Common Table Expression (CTE) query to generate a hierarchical view of employees. Given an 'employees' table with 'id', 'name', and 'manager_id', return the path of names from the top-level manager (CEO) down to each employee, separated by '->'.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Select top-level managers (those with no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        name::TEXT AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE with employees\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        eh.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.id\n)\nSELECT id, name, path FROM employee_hierarchy ORDER BY path;"}
{"instruction": "Calculate the 'Gaps and Islands' problem to find consecutive login streaks for users. Given a 'user_logins' table with 'user_id' and 'login_date', return the start date, end date, and length of each consecutive streak of daily logins per user.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Using PostgreSQL specific syntax, identify queries that are currently waiting for locks held by other transactions. Return the blocked PID, the blocking PID, and the query text for both.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.query AS blocked_query,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate the 7-day moving average of sales and the percentage growth compared to the previous day for each date. Use the 'daily_sales' table with columns 'sale_date' and 'total_amount'.", "output": "SELECT \n    sale_date,\n    total_amount,\n    -- 7-day moving average (current row + 6 previous)\n    AVG(total_amount) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7d,\n    -- Percentage growth calculation\n    CASE \n        WHEN LAG(total_amount) OVER (ORDER BY sale_date) = 0 THEN NULL\n        ELSE (total_amount - LAG(total_amount) OVER (ORDER BY sale_date)) \n             / NULLIF(LAG(total_amount) OVER (ORDER BY sale_date), 0) * 100 \n    END AS daily_growth_pct\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Use a LATERAL join to efficiently retrieve the top 3 most recent orders for every customer. Assume tables 'customers' (id, name) and 'orders' (id, customer_id, order_date, total).", "output": "SELECT \n    c.name AS customer_name,\n    o.order_date,\n    o.total\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_date, total\n    FROM orders\n    WHERE customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nORDER BY c.name, o.order_date DESC;"}
{"instruction": "Perform a cohort analysis to calculate Month-1 retention. Identify the number of users who signed up in a specific month (cohort) and the percentage of them who were active in the following month.", "output": "WITH user_cohorts AS (\n    SELECT \n        user_id, \n        DATE_TRUNC('month', signup_date) AS cohort_month\n    FROM users\n),\nactivity_log AS (\n    SELECT DISTINCT \n        user_id, \n        DATE_TRUNC('month', activity_date) AS activity_month\n    FROM user_activity\n)\nSELECT \n    uc.cohort_month,\n    COUNT(DISTINCT uc.user_id) AS total_users,\n    COUNT(DISTINCT al.user_id) AS retained_users,\n    ROUND((COUNT(DISTINCT al.user_id)::NUMERIC / COUNT(DISTINCT uc.user_id)) * 100, 2) AS retention_rate_pct\nFROM user_cohorts uc\nLEFT JOIN activity_log al \n    ON uc.user_id = al.user_id \n    AND al.activity_month = uc.cohort_month + INTERVAL '1 month'\nGROUP BY uc.cohort_month\nORDER BY uc.cohort_month;"}
{"instruction": "Pivot a table dynamically using the FILTER clause (PostgreSQL) to show total sales for specific categories ('Electronics', 'Clothing', 'Home') per region in a single row.", "output": "SELECT \n    region,\n    SUM(amount) FILTER (WHERE category = 'Electronics') AS sales_electronics,\n    SUM(amount) FILTER (WHERE category = 'Clothing') AS sales_clothing,\n    SUM(amount) FILTER (WHERE category = 'Home') AS sales_home,\n    SUM(amount) AS total_sales\nFROM sales\nGROUP BY region\nORDER BY total_sales DESC;"}
{"instruction": "Database Administration: List the top 10 largest tables in the current database, showing both the table size (data only) and the total relation size (including indexes and toast data), formatted in human-readable units.", "output": "SELECT\n    schemaname AS schema,\n    relname AS table_name,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Handle complex JSONB data: Given a 'products' table with a JSONB column 'attributes', find products where the 'attributes' contain a key 'color' set to 'red' AND a 'dimensions' object where 'width' is greater than 10.", "output": "SELECT \n    product_id, \n    name, \n    attributes\nFROM products\nWHERE \n    attributes @> '{\"color\": \"red\"}' \n    AND (attributes -> 'dimensions' ->> 'width')::NUMERIC > 10;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation. Insert a new record into the 'inventory' table (product_id, warehouse_id, quantity). If the combination of product_id and warehouse_id already exists, update the quantity by adding the new amount to the existing amount.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity)\nVALUES (101, 5, 50)\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    updated_at = NOW();"}
{"instruction": "Write a Recursive CTE to retrieve an organizational hierarchy starting from a specific manager (ID 101), calculating the depth of each employee in the reporting chain.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    SELECT employee_id, manager_id, full_name, 1 AS depth\n    FROM employees\n    WHERE manager_id = 101\n    UNION ALL\n    SELECT e.employee_id, e.manager_id, e.full_name, eh.depth + 1\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy ORDER BY depth, employee_id;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for each store using window functions.", "output": "SELECT \n    store_id,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login data to find consecutive login streaks (dates where a user logged in every single day).", "output": "WITH dates_with_groups AS (\n    SELECT \n        user_id,\n        login_date,\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM dates_with_groups\nGROUP BY user_id, grp\nHAVING COUNT(*) >= 2\nORDER BY user_id, streak_start;"}
{"instruction": "Use a LATERAL JOIN to fetch the top 3 most recent orders for every customer efficiently.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Write a PostgreSQL administration query to list the top 10 largest tables in the database, including index size, formatted in a human-readable size.", "output": "SELECT \n    schemaname,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Aggregate order items into a JSONB array of objects for each order to simplify application-side parsing.", "output": "SELECT \n    o.order_id,\n    o.order_date,\n    jsonb_agg(\n        jsonb_build_object(\n            'product_id', i.product_id,\n            'product_name', p.name,\n            'quantity', i.quantity,\n            'price', i.unit_price\n        )\n    ) AS order_items\nFROM orders o\nJOIN order_items i ON o.order_id = i.order_id\nJOIN products p ON i.product_id = p.product_id\nGROUP BY o.order_id, o.order_date;"}
{"instruction": "Calculate the 90th percentile of query execution times per hour from a logging table.", "output": "SELECT \n    DATE_TRUNC('hour', log_timestamp) AS hour_bucket,\n    PERCENTILE_CONT(0.90) WITHIN GROUP (ORDER BY execution_time_ms) AS p90_latency\nFROM query_logs\nGROUP BY 1\nORDER BY 1 DESC;"}
{"instruction": "Perform an 'Upsert' operation: Insert a new inventory record, or update the quantity if the product already exists in the warehouse.", "output": "INSERT INTO warehouse_inventory (warehouse_id, product_id, quantity, last_updated)\nVALUES (5, 1024, 50, NOW())\nON CONFLICT (warehouse_id, product_id) \nDO UPDATE SET \n    quantity = warehouse_inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Identify blocking queries in PostgreSQL (queries waiting for locks held by other transactions).", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate Month-over-Month (MoM) revenue growth percentage using a self-join approach via CTEs.", "output": "WITH monthly_revenue AS (\n    SELECT \n        DATE_TRUNC('month', payment_date) AS payment_month,\n        SUM(amount) AS total_revenue\n    FROM payments\n    GROUP BY 1\n)\nSELECT \n    curr.payment_month,\n    curr.total_revenue AS current_revenue,\n    prev.total_revenue AS previous_revenue,\n    ROUND(((curr.total_revenue - prev.total_revenue) / NULLIF(prev.total_revenue, 0)) * 100, 2) AS growth_percentage\nFROM monthly_revenue curr\nLEFT JOIN monthly_revenue prev \n    ON curr.payment_month = prev.payment_month + INTERVAL '1 month'\nORDER BY curr.payment_month;"}
{"instruction": "Write a query using a Recursive CTE to generate a hierarchical path string (e.g., 'Electronics > Computers > Laptops') for a category tree structure stored in an adjacency list model (id, name, parent_id).", "output": "WITH RECURSIVE category_tree AS (\n    SELECT \n        id, \n        name, \n        parent_id, \n        CAST(name AS TEXT) as path\n    FROM categories\n    WHERE parent_id IS NULL\n    \n    UNION ALL\n    \n    SELECT \n        c.id, \n        c.name, \n        c.parent_id, \n        ct.path || ' > ' || c.name\n    FROM categories c\n    INNER JOIN category_tree ct ON c.parent_id = ct.id\n)\nSELECT id, name, path \nFROM category_tree \nORDER BY path;"}
{"instruction": "Create a query to identify 'Gaps and Islands' in user login data. Find all periods of consecutive daily logins for each user, returning the start date, end date, and the length of the streak.", "output": "WITH grouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n    GROUP BY user_id, login_date\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a PostgreSQL administration query to identify unused indexes (indexes that have not been scanned) to help optimize storage, excluding primary keys.", "output": "SELECT \n    schemaname, \n    relname AS table_name, \n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as scan_count\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0 \nAND indexrelname NOT LIKE '%_pkey'\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Calculate the 7-day moving average of daily revenue for the current year using Window Functions.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) :: NUMERIC(10,2) as moving_avg_7_days\nFROM (\n    SELECT \n        DATE(created_at) as sale_date, \n        SUM(amount) as daily_revenue\n    FROM sales\n    WHERE created_at >= DATE_TRUNC('year', CURRENT_DATE)\n    GROUP BY 1\n) daily_sales\nORDER BY sale_date;"}
{"instruction": "Use a LATERAL JOIN to find the top 3 most recent orders for every customer who has placed an order in the last 30 days.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nJOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o ON true\nWHERE EXISTS (\n    SELECT 1 FROM orders recent \n    WHERE recent.customer_id = c.customer_id \n    AND recent.order_date > CURRENT_DATE - INTERVAL '30 days'\n);"}
{"instruction": "Pivot sales data using ANSI SQL (conditional aggregation) to show total sales per product (rows) broken down by Quarter (columns) for the year 2023.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS Q1_Sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS Q2_Sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS Q3_Sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS Q4_Sales,\n    SUM(amount) AS Total_2023_Sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_name\nORDER BY Total_2023_Sales DESC;"}
{"instruction": "Write a query to find the 'Churn Rate' of employees. Calculate the number of employees who left each month and the percentage relative to the total employees at the start of that month.", "output": "WITH monthly_activity AS (\n    SELECT \n        DATE_TRUNC('month', termination_date) as mth,\n        COUNT(*) as churned_count\n    FROM employees\n    WHERE termination_date IS NOT NULL\n    GROUP BY 1\n),\ntotal_staff_history AS (\n    SELECT \n        DATE_TRUNC('month', d)::date as mth,\n        (SELECT COUNT(*) FROM employees e WHERE e.hire_date < d AND (e.termination_date IS NULL OR e.termination_date >= d)) as active_staff\n    FROM generate_series('2023-01-01'::date, '2023-12-01'::date, '1 month') d\n)\nSELECT \n    t.mth,\n    t.active_staff,\n    COALESCE(m.churned_count, 0) as churned,\n    ROUND((COALESCE(m.churned_count, 0)::numeric / NULLIF(t.active_staff, 0)) * 100, 2) as churn_rate_pct\nFROM total_staff_history t\nLEFT JOIN monthly_activity m ON t.mth = m.mth\nORDER BY t.mth;"}
{"instruction": "Identify blocking transactions in PostgreSQL. Write a query to list pids that are waiting for locks and the pids that are blocking them.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Perform a complex cohort analysis. For users who signed up in January, calculate their retention rate (percentage of users who logged in) for each subsequent month up to June.", "output": "WITH jan_cohort AS (\n    SELECT user_id \n    FROM users \n    WHERE DATE_TRUNC('month', signup_date) = '2023-01-01'\n),\ncohort_size AS (\n    SELECT COUNT(*) as total_users FROM jan_cohort\n),\nmonthly_activity AS (\n    SELECT \n        EXTRACT(MONTH FROM login_date) as month_num,\n        COUNT(DISTINCT l.user_id) as active_users\n    FROM logins l\n    JOIN jan_cohort c ON l.user_id = c.user_id\n    WHERE login_date BETWEEN '2023-01-01' AND '2023-06-30'\n    GROUP BY 1\n)\nSELECT \n    TO_CHAR(TO_DATE(m.month_num::text, 'MM'), 'Month') as month_name,\n    m.active_users,\n    ROUND((m.active_users::numeric / cs.total_users) * 100, 2) as retention_rate\nFROM monthly_activity m\nCROSS JOIN cohort_size cs\nORDER BY m.month_num;"}
{"instruction": "Clean and aggregate email data. Extract the domain from email addresses, count users per domain, and filter for domains with more than 50 users, ignoring case.", "output": "SELECT \n    LOWER(SUBSTRING(email FROM POSITION('@' IN email) + 1)) AS domain_name,\n    COUNT(*) as user_count\nFROM users\nWHERE email LIKE '%@%'\nGROUP BY 1\nHAVING COUNT(*) > 50\nORDER BY user_count DESC;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and window functions to find the top 3 sales representatives by total revenue within each sales region for the current year.", "output": "WITH RegionSales AS (\n    SELECT \n        region_id,\n        rep_id,\n        SUM(amount) as total_revenue\n    FROM sales\n    WHERE date_part('year', sale_date) = date_part('year', CURRENT_DATE)\n    GROUP BY region_id, rep_id\n),\nRankedSales AS (\n    SELECT \n        region_id,\n        rep_id,\n        total_revenue,\n        DENSE_RANK() OVER (PARTITION BY region_id ORDER BY total_revenue DESC) as rank\n    FROM RegionSales\n)\nSELECT * \nFROM RankedSales \nWHERE rank <= 3;"}
{"instruction": "Create a recursive CTE to traverse an employee hierarchy (adjacency list model) and retrieve the full reporting path from a specific employee (ID 105) up to the CEO.", "output": "WITH RECURSIVE ManagementChain AS (\n    -- Anchor member: start with the specific employee\n    SELECT \n        employee_id, \n        manager_id, \n        full_name, \n        0 as level\n    FROM employees \n    WHERE employee_id = 105\n\n    UNION ALL\n\n    -- Recursive member: join with the manager\n    SELECT \n        e.employee_id, \n        e.manager_id, \n        e.full_name, \n        mc.level + 1\n    FROM employees e\n    INNER JOIN ManagementChain mc ON e.employee_id = mc.manager_id\n)\nSELECT * FROM ManagementChain;"}
{"instruction": "Write a query to calculate the 7-day moving average of stock closing prices for each ticker symbol, ordered by date.", "output": "SELECT \n    ticker_symbol,\n    trade_date,\n    close_price,\n    AVG(close_price) OVER (\n        PARTITION BY ticker_symbol \n        ORDER BY trade_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_day\nFROM stock_prices\nORDER BY ticker_symbol, trade_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login data. Find the start date, end date, and length of consecutive daily login streaks for every user.", "output": "WITH GroupedLogins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a grouping identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM GroupedLogins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a PostgreSQL administration query to identify currently running queries that are waiting on locks held by other transactions (blocking queries).", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocked_activity.query    AS blocked_query,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query   AS blocking_query\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Use a CROSS JOIN LATERAL to find the 3 most recent comments for each blog post without using a window function in the main select list.", "output": "SELECT \n    p.post_title,\n    c.comment_body,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_body, created_at\n    FROM comments\n    WHERE post_id = p.id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c;"}
{"instruction": "Pivot monthly sales data from rows to columns (Cross-tabulation) using the FILTER clause (PostgreSQL/Modern ANSI) to show total sales for Q1 (Jan, Feb, Mar) per product.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_total\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_name;"}
{"instruction": "Write a PostgreSQL administration query to list the top 10 largest tables in the database, including the size of their associated indexes, formatted in a human-readable format.", "output": "SELECT\n    schemaname AS table_schema,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Find customers who have purchased 'Product A' but have never purchased 'Product B' using set operations or EXISTS logic.", "output": "SELECT DISTINCT c.customer_id, c.email\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nWHERE p.product_name = 'Product A'\nAND NOT EXISTS (\n    SELECT 1\n    FROM orders o2\n    JOIN order_items oi2 ON o2.order_id = oi2.order_id\n    JOIN products p2 ON oi2.product_id = p2.product_id\n    WHERE o2.customer_id = c.customer_id\n    AND p2.product_name = 'Product B'\n);"}
{"instruction": "Working with JSONB in PostgreSQL: Given a table 'events' with a JSONB column 'payload', calculate the frequency of every key present in the top-level of the JSON objects across all rows.", "output": "SELECT \n    key AS json_key,\n    COUNT(*) AS frequency\nFROM events,\nLATERAL jsonb_each(payload) \nGROUP BY key\nORDER BY frequency DESC;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to identify the top 3 products by total revenue within each product category. If there is a tie in revenue, they should share the same rank, and the next rank should be skipped (use RANK).", "output": "WITH ProductRevenue AS (\n    SELECT \n        p.category_id,\n        p.product_name,\n        SUM(o.quantity * o.unit_price) as total_revenue\n    FROM products p\n    JOIN order_details o ON p.product_id = o.product_id\n    GROUP BY p.category_id, p.product_name\n)\nSELECT \n    category_id,\n    product_name,\n    total_revenue,\n    rank_in_category\nFROM (\n    SELECT \n        category_id,\n        product_name,\n        total_revenue,\n        RANK() OVER (PARTITION BY category_id ORDER BY total_revenue DESC) as rank_in_category\n    FROM ProductRevenue\n) ranked\nWHERE rank_in_category <= 3;"}
{"instruction": "Create a Recursive CTE to generate the full hierarchical path (e.g., 'CEO > VP > Manager') for every employee in the 'employees' table, which contains 'id', 'name', and 'manager_id'.", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n    -- Anchor member: Select top-level managers (those with no manager)\n    SELECT \n        id, \n        name,\n        manager_id,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.id, \n        e.name,\n        e.manager_id,\n        eh.path || ' > ' || e.name\n    FROM employees e\n    JOIN EmployeeHierarchy eh ON e.manager_id = eh.id\n)\nSELECT * FROM EmployeeHierarchy ORDER BY path;"}
{"instruction": "Write a PostgreSQL query to calculate the 7-day moving average of daily sales. The result should include the date, daily total, and the moving average, ordered by date.", "output": "SELECT \n    sale_date,\n    SUM(amount) as daily_total,\n    AVG(SUM(amount)) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_average_7_days\nFROM sales\nGROUP BY sale_date\nORDER BY sale_date;"}
{"instruction": "Construct a query to find customers who have purchased 'Product A' but have NEVER purchased 'Product B'. Use set operations (EXCEPT or NOT EXISTS) for efficiency.", "output": "SELECT customer_id \nFROM orders o\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nWHERE p.product_name = 'Product A'\n\nEXCEPT\n\nSELECT customer_id \nFROM orders o\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nWHERE p.product_name = 'Product B';"}
{"instruction": "Write a Database Administration query for PostgreSQL to identify unused indexes. The query should list the index name, table name, and index size for indexes that have not been scanned, excluding primary keys and internal schemas.", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as scan_count\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0\n  AND indexrelname NOT LIKE '%pkey%'\n  AND NOT indisunique\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Solve the 'Gaps and Islands' problem: Identify groups of consecutive days where a user logged in. Return the user_id, the start date of the streak, the end date of the streak, and the length of the streak.", "output": "WITH GroupedDates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM GroupedDates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a query utilizing PostgreSQL's CROSS JOIN LATERAL to fetch the 3 most recent comments for every blog post, assuming a 'posts' table and a 'comments' table.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_id,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c;"}
{"instruction": "Pivot a sales table using PostgreSQL's FILTER clause to display total sales per Region (rows) for Q1, Q2, Q3, and Q4 (columns).", "output": "SELECT \n    region,\n    SUM(amount) FILTER (WHERE quarter = 1) AS \"Q1_Sales\",\n    SUM(amount) FILTER (WHERE quarter = 2) AS \"Q2_Sales\",\n    SUM(amount) FILTER (WHERE quarter = 3) AS \"Q3_Sales\",\n    SUM(amount) FILTER (WHERE quarter = 4) AS \"Q4_Sales\"\nFROM sales_data\nGROUP BY region\nORDER BY region;"}
{"instruction": "Write a PostgreSQL DBA query to detect currently blocking queries. The output should show the blocked PID, the blocking PID, the duration of the wait, and the actual query text causing the block.", "output": "SELECT\n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process,\n    now() - blocked_activity.query_start AS duration_waiting\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Query a PostgreSQL table with a JSONB column named 'attributes'. Find all rows where the JSON object contains a key 'tags' which is an array containing the string 'urgent'.", "output": "SELECT \n    id, \n    attributes \nFROM tasks \nWHERE attributes @> '{\"tags\": [\"urgent\"]}';"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to find the top 3 best-selling products by revenue within each product category.", "output": "WITH ProductRevenue AS (\n    SELECT \n        c.category_name,\n        p.product_name,\n        SUM(o.quantity * o.unit_price) as total_revenue,\n        RANK() OVER (PARTITION BY c.category_name ORDER BY SUM(o.quantity * o.unit_price) DESC) as revenue_rank\n    FROM products p\n    JOIN categories c ON p.category_id = c.category_id\n    JOIN order_details o ON p.product_id = o.product_id\n    GROUP BY c.category_name, p.product_name\n)\nSELECT \n    category_name,\n    product_name,\n    total_revenue\nFROM ProductRevenue\nWHERE revenue_rank <= 3;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of an organization, showing the full path from the CEO down to every employee (e.g., 'CEO -> VP -> Manager -> Employee').", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        name::TEXT as path,\n        1 as level\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.path || ' -> ' || e.name,\n        oc.level + 1\n    FROM employees e\n    JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Write a PostgreSQL administration query to list all tables in the current database along with their total size on disk (including indexes), ordered by size descending.", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue using a Window Function.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7d\nFROM daily_sales_summary\nORDER BY sale_date;"}
{"instruction": "Identify 'churned' customers: Find customers who placed an order in 2022 but have not placed any orders in 2023, using the EXCEPT set operator.", "output": "SELECT customer_id \nFROM orders \nWHERE order_date >= '2022-01-01' AND order_date <= '2022-12-31'\n\nEXCEPT\n\nSELECT customer_id \nFROM orders \nWHERE order_date >= '2023-01-01' AND order_date <= '2023-12-31';"}
{"instruction": "Write a query to perform a 'Gap Analysis' on invoice numbers to find missing invoice IDs in a sequential list.", "output": "WITH LeadInvoices AS (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) as next_invoice_id\n    FROM invoices\n)\nSELECT \n    invoice_id + 1 as gap_start,\n    next_invoice_id - 1 as gap_end\nFROM LeadInvoices\nWHERE next_invoice_id - invoice_id > 1;"}
{"instruction": "Use the PostgreSQL specific `LATERAL` join to retrieve the most recent 3 comments for every blog post without using a window function in the main select list.", "output": "SELECT \n    p.post_title,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE post_id = p.id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c;"}
{"instruction": "Write a DBA query to identify currently active queries that have been running for more than 5 minutes.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    query_start, \n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state != 'idle' \n  AND (now() - query_start) > interval '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Pivot a sales table to display total revenue per product for January, February, and March as separate columns using the FILTER clause.", "output": "SELECT \n    product_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_revenue,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_revenue\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_id;"}
{"instruction": "Calculate the Month-over-Month (MoM) revenue growth percentage using CTEs and LAG().", "output": "WITH MonthlySales AS (\n    SELECT \n        DATE_TRUNC('month', order_date) as sales_month,\n        SUM(amount) as revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT \n    sales_month,\n    revenue,\n    LAG(revenue) OVER (ORDER BY sales_month) as prev_month_revenue,\n    ROUND(\n        ((revenue - LAG(revenue) OVER (ORDER BY sales_month)) / \n        NULLIF(LAG(revenue) OVER (ORDER BY sales_month), 0)) * 100\n    , 2) as growth_percentage\nFROM MonthlySales;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to find the top 3 salespeople by revenue within each region. The output should include the region, salesperson name, revenue, and their rank within that region.", "output": "WITH RegionalSales AS (\n    SELECT \n        region,\n        salesperson_name,\n        SUM(revenue) as total_revenue,\n        RANK() OVER (PARTITION BY region ORDER BY SUM(revenue) DESC) as rank_in_region\n    FROM sales_data\n    GROUP BY region, salesperson_name\n)\nSELECT \n    region,\n    salesperson_name,\n    total_revenue,\n    rank_in_region\nFROM RegionalSales\nWHERE rank_in_region <= 3;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of an organization. Given a table 'employees' with 'id', 'name', and 'manager_id', return a list showing the employee name and their hierarchical path (e.g., 'CEO > VP > Manager > Employee').", "output": "WITH RECURSIVE OrgHierarchy AS (\n    -- Anchor member: Top level managers (no manager_id)\n    SELECT \n        id, \n        name, \n        manager_id, \n        name::TEXT as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oh.path || ' > ' || e.name\n    FROM employees e\n    INNER JOIN OrgHierarchy oh ON e.manager_id = oh.id\n)\nSELECT id, name, path FROM OrgHierarchy ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product using Window Functions. The result should show the date, product_id, daily sales, and the moving average.", "output": "SELECT \n    sales_date,\n    product_id,\n    daily_sales_amount,\n    AVG(daily_sales_amount) OVER (\n        PARTITION BY product_id \n        ORDER BY sales_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM daily_product_sales\nORDER BY product_id, sales_date;"}
{"instruction": "Write a PostgreSQL administration query to identify unused indexes. The query should return the schema, table name, index name, and the size of the index, filtered for indexes that have not been scanned.", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0\n  AND indexrelname NOT LIKE '%pkey%'\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Solve the 'Gaps and Islands' problem to find consecutive login streaks for users. Return the user_id, start_date, end_date, and the length of the streak in days.", "output": "WITH GroupedLogins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM GroupedLogins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Perform a complex join to find customers who have purchased 'Product A' but have NEVER purchased 'Product B'. Use conditional aggregation or EXISTS clauses.", "output": "SELECT c.customer_id, c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nGROUP BY c.customer_id, c.customer_name\nHAVING \n    COUNT(CASE WHEN p.product_name = 'Product A' THEN 1 END) > 0\n    AND \n    COUNT(CASE WHEN p.product_name = 'Product B' THEN 1 END) = 0;"}
{"instruction": "Use a LATERAL JOIN to retrieve the 3 most recent comments for every blog post without using a window function in the main select list (PostgreSQL specific).", "output": "SELECT \n    p.post_id,\n    p.title,\n    r.comment_text,\n    r.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments c\n    WHERE c.post_id = p.post_id\n    ORDER BY c.created_at DESC\n    LIMIT 3\n) r;"}
{"instruction": "Write a PostgreSQL query to identify currently active queries that are being blocked by locks held by other transactions.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Pivot monthly sales data from rows to columns using the ANSI SQL FILTER clause. The source table has columns 'year', 'month', and 'amount'. The output should have one row per year with columns for Q1, Q2, Q3, and Q4 totals.", "output": "SELECT \n    year,\n    SUM(amount) FILTER (WHERE month IN ('Jan', 'Feb', 'Mar')) AS Q1_Total,\n    SUM(amount) FILTER (WHERE month IN ('Apr', 'May', 'Jun')) AS Q2_Total,\n    SUM(amount) FILTER (WHERE month IN ('Jul', 'Aug', 'Sep')) AS Q3_Total,\n    SUM(amount) FILTER (WHERE month IN ('Oct', 'Nov', 'Dec')) AS Q4_Total\nFROM monthly_sales\nGROUP BY year\nORDER BY year;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation in PostgreSQL. Insert a new user record, but if the email already exists, update the last_login timestamp instead.", "output": "INSERT INTO users (username, email, last_login)\nVALUES ('jdoe', 'john.doe@example.com', NOW())\nON CONFLICT (email) \nDO UPDATE SET \n    last_login = EXCLUDED.last_login,\n    username = EXCLUDED.username;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to find the top 3 highest-paid employees within each department. The result should include the department name, employee name, salary, and their rank within the department.", "output": "WITH RankedSalaries AS (\n    SELECT \n        d.department_name,\n        e.employee_name,\n        e.salary,\n        DENSE_RANK() OVER (PARTITION BY e.department_id ORDER BY e.salary DESC) as salary_rank\n    FROM employees e\n    JOIN departments d ON e.department_id = d.id\n)\nSELECT \n    department_name,\n    employee_name,\n    salary,\n    salary_rank\nFROM RankedSalaries\nWHERE salary_rank <= 3\nORDER BY department_name, salary_rank;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical organizational chart. Given an 'employees' table with 'id', 'name', and 'manager_id', return the hierarchy path (e.g., 'CEO > VP > Manager') and the depth level for every employee.", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: Select top-level managers (those with no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        name::TEXT as hierarchy_path, \n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oc.hierarchy_path || ' > ' || e.name,\n        oc.level + 1\n    FROM employees e\n    INNER JOIN OrgChart oc ON e.manager_id = oc.id\n)\nSELECT * FROM OrgChart\nORDER BY hierarchy_path;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue using a Window Function. The output should contain the date, daily revenue, and the moving average formatted to 2 decimal places.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    ROUND(\n        AVG(daily_revenue) OVER (\n            ORDER BY sale_date \n            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n        ), 2\n    ) AS moving_avg_7_days\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Solve the 'Gap and Islands' problem to identify consecutive login streaks for users. Given a 'user_logins' table with 'user_id' and 'login_date', return the user_id, start_date, end_date, and length of the streak.", "output": "WITH GroupedDates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM GroupedDates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a PostgreSQL DBA query to identify the top 10 largest tables in the database, including their total size (data + indexes) in a human-readable format.", "output": "SELECT\n    schemaname as schema,\n    relname as table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) as total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a CROSS JOIN LATERAL to fetch the 3 most recent orders for every customer efficiently. This assumes tables 'customers' and 'orders'.", "output": "SELECT \n    c.customer_name,\n    recent_orders.order_id,\n    recent_orders.order_date,\n    recent_orders.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT \n        o.order_id, \n        o.order_date, \n        o.total_amount\n    FROM orders o\n    WHERE o.customer_id = c.id\n    ORDER BY o.order_date DESC\n    LIMIT 3\n) AS recent_orders;"}
{"instruction": "Perform a Pivot (Crosstab) operation using the FILTER clause (ANSI SQL compliant) to display total sales per product for the first quarter (Jan, Feb, Mar) as separate columns.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nWHERE sale_date >= '2023-01-01' AND sale_date <= '2023-03-31'\nGROUP BY product_name;"}
{"instruction": "Write a query to identify customers who have purchased 'Product A' but have NEVER purchased 'Product B'. Use the EXCEPT operator or NOT EXISTS clause.", "output": "SELECT DISTINCT customer_id \nFROM orders \nWHERE product_id = 'Product A'\nEXCEPT\nSELECT DISTINCT customer_id \nFROM orders \nWHERE product_id = 'Product B';"}
{"instruction": "PostgreSQL DBA Task: Find and list currently active queries that have been running for more than 5 minutes, including the user, IP address, and the query text.", "output": "SELECT \n    pid,\n    usename AS username,\n    client_addr AS ip_address,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Work with JSONB data in PostgreSQL. Given a table 'books' with a JSONB column 'info' containing keys for 'tags' (array) and 'author', find all books tagged as 'Science Fiction' and expand the author object to return the author's last name.", "output": "SELECT \n    id,\n    title,\n    info -> 'author' ->> 'last_name' AS author_last_name\nFROM books\nWHERE info @> '{\"tags\": [\"Science Fiction\"]}';"}
{"instruction": "Write a Recursive CTE to retrieve the full organizational hierarchy path for every employee, assuming a table 'employees' with columns 'id', 'name', and 'manager_id'.", "output": "WITH RECURSIVE org_chart AS (\n    SELECT id, name, manager_id, name::TEXT as path\n    FROM employees\n    WHERE manager_id IS NULL\n    UNION ALL\n    SELECT e.id, e.name, e.manager_id, o.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.id\n)\nSELECT * FROM org_chart;"}
{"instruction": "Calculate the 'Gaps and Islands' to find consecutive login streaks for users. Given a 'user_logins' table with 'user_id' and 'login_date', return the start date, end date, and length of every streak of 3 or more consecutive days.", "output": "WITH dates AS (\n    SELECT DISTINCT user_id, login_date\n    FROM user_logins\n),\ngroups AS (\n    SELECT user_id, login_date,\n           login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM dates\n)\nSELECT user_id, MIN(login_date) as streak_start, MAX(login_date) as streak_end, COUNT(*) as days\nFROM groups\nGROUP BY user_id, grp\nHAVING COUNT(*) >= 3\nORDER BY user_id, streak_start;"}
{"instruction": "Write a query to calculate the 7-day moving average of sales amount for each day, ordered by date.", "output": "SELECT sale_date,\n       SUM(amount) as daily_total,\n       AVG(SUM(amount)) OVER (\n           ORDER BY sale_date\n           ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n       ) as moving_avg_7_days\nFROM sales\nGROUP BY sale_date\nORDER BY sale_date;"}
{"instruction": "Database Administration: Identify currently active queries that are being blocked by other transactions, showing both the blocked and blocking PIDs and queries.", "output": "SELECT blocked_activity.pid AS blocked_pid,\n       blocked_activity.query AS blocked_query,\n       blocking_activity.pid AS blocking_pid,\n       blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_stat_activity AS blocked_activity\nJOIN pg_catalog.pg_stat_activity AS blocking_activity\n    ON blocking_activity.pid = ANY(pg_blocking_pids(blocked_activity.pid))\nWHERE blocked_activity.pid <> pg_backend_pid();"}
{"instruction": "Use a LATERAL JOIN to find the top 3 most recent orders for every customer without using a subquery in the SELECT list.", "output": "SELECT c.customer_name, o.order_date, o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Write a query to compare the total sales of each product category in the current month versus the previous month using window functions.", "output": "WITH monthly_sales AS (\n    SELECT category_id,\n           DATE_TRUNC('month', sale_date) as sale_month,\n           SUM(amount) as total_sales\n    FROM sales\n    GROUP BY 1, 2\n)\nSELECT category_id, sale_month, total_sales,\n       LAG(total_sales) OVER (PARTITION BY category_id ORDER BY sale_month) as prev_month_sales,\n       total_sales - LAG(total_sales) OVER (PARTITION BY category_id ORDER BY sale_month) as difference\nFROM monthly_sales;"}
{"instruction": "Database Administration: List the top 10 largest tables in the database, including their total size on disk (data + indexes), formatted in a human-readable size.", "output": "SELECT schemaname, relname,\n       pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform an 'Upsert' (Insert or Update): Insert a new user record, but if the email already exists, update the 'last_login' timestamp instead.", "output": "INSERT INTO users (email, username, last_login)\nVALUES ('test@example.com', 'testuser', NOW())\nON CONFLICT (email)\nDO UPDATE SET last_login = EXCLUDED.last_login;"}
{"instruction": "Query a JSONB column 'attributes' in a 'products' table to find all products where the attribute 'color' is 'red' and 'size' is 'L'.", "output": "SELECT product_name, attributes\nFROM products\nWHERE attributes @> '{\"color\": \"red\", \"size\": \"L\"}';"}
{"instruction": "Calculate the 95th percentile of response times per API endpoint from a logs table.", "output": "SELECT endpoint,\n       PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY response_time_ms) as p95_latency\nFROM api_logs\nGROUP BY endpoint;"}
{"instruction": "Write a query using a Recursive CTE to generate a hierarchical view of employees. Given an 'employees' table with 'id', 'name', and 'manager_id', return the employee's name, their manager's name, and their hierarchy level (depth), starting from the CEO (where manager_id is NULL).", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: select the top-level manager (CEO)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 AS hierarchy_level,\n        CAST(name AS TEXT) as path\n    FROM employees \n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        eh.hierarchy_level + 1,\n        eh.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.id\n)\nSELECT \n    id, \n    name, \n    hierarchy_level, \n    path \nFROM employee_hierarchy \nORDER BY path;"}
{"instruction": "Calculate the 3-day moving average of sales for each product using Window Functions. The table 'daily_sales' contains 'product_id', 'sale_date', and 'amount'.", "output": "SELECT \n    product_id,\n    sale_date,\n    amount,\n    AVG(amount) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n    ) AS moving_average_3_days\nFROM daily_sales\nORDER BY product_id, sale_date;"}
{"instruction": "Identify 'islands' of consecutive integers in a table 'sequences' with a column 'seq_id'. The goal is to group consecutive numbers into ranges (start and end).", "output": "WITH grouped_sequences AS (\n    SELECT \n        seq_id,\n        seq_id - ROW_NUMBER() OVER (ORDER BY seq_id) AS group_id\n    FROM sequences\n)\nSELECT \n    MIN(seq_id) AS range_start,\n    MAX(seq_id) AS range_end\nFROM grouped_sequences\nGROUP BY group_id\nORDER BY range_start;"}
{"instruction": "Perform a Pivot (Cross-tabulation) to display total sales per category for the first quarter (Jan, Feb, Mar). Use PostgreSQL's FILTER clause for conditional aggregation.", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nJOIN categories ON sales.category_id = categories.id\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY category_name;"}
{"instruction": "DBA Task: List the top 10 largest tables in the current database, including schemas, and display their size in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    n.nspname AS schema_name,\n    c.relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(c.oid)) AS total_size\nFROM pg_class c\nLEFT JOIN pg_namespace n ON n.oid = c.relnamespace\nWHERE c.relkind = 'r' -- 'r' means ordinary table\nAND n.nspname NOT IN ('pg_catalog', 'information_schema')\nORDER BY pg_total_relation_size(c.oid) DESC\nLIMIT 10;"}
{"instruction": "Find the top 3 highest-paid employees in each department using DENSE_RANK to handle salary ties appropriately.", "output": "WITH ranked_salaries AS (\n    SELECT \n        department_id,\n        name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT * \nFROM ranked_salaries\nWHERE rank <= 3;"}
{"instruction": "Use a LATERAL JOIN to find the most recent order for each customer without using a correlated subquery in the SELECT list. Assume tables 'customers' and 'orders'.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    recent_order.order_date,\n    recent_order.total_amount\nFROM customers c\nLEFT JOIN LATERAL (\n    SELECT order_date, total_amount\n    FROM orders o\n    WHERE o.customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 1\n) AS recent_order ON true;"}
{"instruction": "PostgreSQL Specific: Query a table 'products' with a JSONB column named 'attributes'. Find all products where the JSON attribute 'color' is 'red' and return the product name and the 'weight' attribute.", "output": "SELECT \n    product_name,\n    attributes ->> 'weight' AS weight\nFROM products\nWHERE attributes @> '{\"color\": \"red\"}'; \n-- Alternatively: WHERE attributes ->> 'color' = 'red'"}
{"instruction": "DBA Task: Identify currently active queries that have been running for longer than 5 minutes, excluding the current session.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > interval '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Calculate Customer Churn: Identify customers who placed an order in the previous month but have NOT placed an order in the current month using Set Operations (EXCEPT).", "output": "SELECT customer_id \nFROM orders \nWHERE order_date >= DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month')\n  AND order_date < DATE_TRUNC('month', CURRENT_DATE)\n\nEXCEPT\n\nSELECT customer_id \nFROM orders \nWHERE order_date >= DATE_TRUNC('month', CURRENT_DATE);"}
{"instruction": "Write a query using a recursive CTE to generate an organizational chart. The output should list every employee, their manager, and their hierarchical depth (level) starting from the CEO (who has a NULL manager_id).", "output": "WITH RECURSIVE org_hierarchy AS (\n    -- Anchor member: Select top-level managers (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees to their managers\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oh.level + 1,\n        oh.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_hierarchy oh ON e.manager_id = oh.employee_id\n)\nSELECT * FROM org_hierarchy ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily revenue for each store. The result should include the date, store ID, daily revenue, and the moving average, ordered by store and date.", "output": "SELECT \n    store_id,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Identify 'gaps' in data. Given a table of user logins, find all dates in the current month where a specific user (user_id = 101) did NOT log in. Use `generate_series` to create the calendar spine.", "output": "SELECT \n    calendar_date::DATE\nFROM \n    generate_series(\n        DATE_TRUNC('month', CURRENT_DATE), \n        DATE_TRUNC('month', CURRENT_DATE) + INTERVAL '1 month' - INTERVAL '1 day', \n        INTERVAL '1 day'\n    ) AS calendar_date\nLEFT JOIN user_logins ul \n    ON ul.login_date = calendar_date::DATE \n    AND ul.user_id = 101\nWHERE ul.login_date IS NULL;"}
{"instruction": "Perform a 'sessionization' analysis on web clickstream data. Group events into sessions where a new session starts if more than 30 minutes have passed since the user's previous event.", "output": "WITH lag_calculations AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        LAG(event_timestamp) OVER (PARTITION BY user_id ORDER BY event_timestamp) AS prev_timestamp\n    FROM clicks\n),\nsession_flags AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        CASE \n            WHEN prev_timestamp IS NULL \n                 OR event_timestamp > prev_timestamp + INTERVAL '30 minutes' THEN 1 \n            ELSE 0 \n        END AS is_new_session\n    FROM lag_calculations\n)\nSELECT \n    user_id,\n    event_timestamp,\n    SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY event_timestamp) AS session_id\nFROM session_flags;"}
{"instruction": "Create a pivot table (cross-tab) report showing total sales amount per category (rows) for each quarter of the current year (columns) using filtered aggregation.", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS q2_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS q3_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS q4_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY category_name;"}
{"instruction": "Database Administration: Write a query to identify currently blocked queries in PostgreSQL. The output should show the blocked PID, the blocking PID, the duration of the wait, and the query text for both transactions.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query AS blocked_statement,\n    blocking_activity.query AS current_statement_in_blocking_process,\n    now() - blocked_activity.query_start AS blocking_duration\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity \n    ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity \n    ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Use a `LATERAL` join to efficiently retrieve the top 3 most recent comments for every blog post without using a correlated subquery in the SELECT clause.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_id,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_id, comment_text, created_at\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c;"}
{"instruction": "Clean up duplicate data: Delete rows from the `contacts` table that have duplicate email addresses, keeping only the row with the most recent `updated_at` timestamp.", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (\n                PARTITION BY email \n                ORDER BY updated_at DESC\n            ) as rn\n        FROM contacts\n    ) t\n    WHERE t.rn > 1\n);"}
{"instruction": "Query a JSONB column to find products where the `attributes` JSON object contains a key 'colors' that includes 'red' in its array of values.", "output": "SELECT \n    product_id, \n    product_name, \n    attributes\nFROM products\nWHERE attributes @> '{\"colors\": [\"red\"]}';"}
{"instruction": "Database Administration: List the top 10 largest tables in the current database, including the size of their indexes and toast data, formatted in a human-readable size (e.g., MB, GB).", "output": "SELECT\n    schemaname || '.' || relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Write a query using a Recursive CTE to generate a hierarchical view of employees and their managers. The output should include the employee's ID, name, and a 'path' string showing the hierarchy chain (e.g., 'CEO > VP > Manager > Employee') for a table named 'employees' with columns 'id', 'name', and 'manager_id'.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Anchor member: Select top-level managers (those with no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join employees with their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        eh.path || ' > ' || e.name\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.id\n)\nSELECT * FROM employee_hierarchy ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for the current year. Use a window function to look back 6 days plus the current day.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "Identify the top 3 customers by total spending in each specific region. Use DENSE_RANK to handle ties appropriately.", "output": "WITH CustomerSpending AS (\n    SELECT \n        c.customer_name,\n        c.region,\n        SUM(o.total_amount) as total_spent\n    FROM customers c\n    JOIN orders o ON c.customer_id = o.customer_id\n    GROUP BY c.customer_name, c.region\n),\nRankedCustomers AS (\n    SELECT \n        customer_name,\n        region,\n        total_spent,\n        DENSE_RANK() OVER (PARTITION BY region ORDER BY total_spent DESC) as rank\n    FROM CustomerSpending\n)\nSELECT * \nFROM RankedCustomers \nWHERE rank <= 3;"}
{"instruction": "Perform a gap analysis to find products that have current stock inventory but have not been ordered in the last 6 months. Use a LEFT JOIN and filter for NULLs on the right side.", "output": "SELECT \n    p.product_id,\n    p.product_name,\n    i.stock_quantity\nFROM products p\nJOIN inventory i ON p.product_id = i.product_id\nLEFT JOIN order_items oi \n    JOIN orders o ON oi.order_id = o.order_id AND o.order_date >= CURRENT_DATE - INTERVAL '6 months'\n    ON p.product_id = oi.product_id\nWHERE \n    i.stock_quantity > 0 \n    AND oi.product_id IS NULL;"}
{"instruction": "Pivot monthly sales data from rows to columns (Cross-Tabulation) for the year 2023, showing product names as rows and months (Jan-Mar) as columns.", "output": "SELECT \n    product_name,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 1 THEN amount ELSE 0 END) AS Jan_Sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 2 THEN amount ELSE 0 END) AS Feb_Sales,\n    SUM(CASE WHEN EXTRACT(MONTH FROM sale_date) = 3 THEN amount ELSE 0 END) AS Mar_Sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_name;"}
{"instruction": "PostgreSQL Administration: Write a query to identify unused indexes in the database (indexes that have not been scanned) to help reclaim storage space.", "output": "SELECT \n    schemaname, \n    relname AS table_name, \n    indexrelname AS index_name, \n    idx_scan AS number_of_scans, \n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Calculate the Month-over-Month (MoM) percentage growth rate of active users using CTEs and the LAG window function.", "output": "WITH MonthlyUsers AS (\n    SELECT \n        DATE_TRUNC('month', activity_date) AS activity_month,\n        COUNT(DISTINCT user_id) AS active_users\n    FROM user_logs\n    GROUP BY 1\n),\nGrowthCalc AS (\n    SELECT \n        activity_month,\n        active_users,\n        LAG(active_users) OVER (ORDER BY activity_month) AS prev_month_users\n    FROM MonthlyUsers\n)\nSELECT \n    activity_month,\n    active_users,\n    ROUND(((active_users - prev_month_users)::numeric / prev_month_users) * 100, 2) AS mom_growth_percentage\nFROM GrowthCalc;"}
{"instruction": "Find students who have taken *every* required core course. This is an example of Relational Division.", "output": "SELECT s.student_id, s.student_name\nFROM students s\nJOIN transcript t ON s.student_id = t.student_id\nJOIN courses c ON t.course_id = c.course_id\nWHERE c.is_core = TRUE\nGROUP BY s.student_id, s.student_name\nHAVING COUNT(DISTINCT c.course_id) = (SELECT COUNT(*) FROM courses WHERE is_core = TRUE);"}
{"instruction": "PostgreSQL Administration: Write a query to detect currently blocked queries and the queries holding the locks blocking them.", "output": "SELECT\n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query    AS blocked_statement,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Update a table using data from another table based on a complex join condition (Update with Join). Specifically, update the 'tier' column in the 'customers' table based on their total spending calculated from the 'orders' table.", "output": "UPDATE customers\nSET tier = CASE \n    WHEN sub.total_spent > 10000 THEN 'Gold'\n    WHEN sub.total_spent > 5000 THEN 'Silver'\n    ELSE 'Bronze'\nEND\nFROM (\n    SELECT customer_id, SUM(total_amount) as total_spent\n    FROM orders\n    GROUP BY customer_id\n) AS sub\nWHERE customers.customer_id = sub.customer_id;"}
{"instruction": "Write a Recursive CTE to generate a hierarchical view of employees, starting from a specific manager (id = 1), showing the employee name, their manager's name, and their depth level in the organization.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select the manager\n    SELECT \n        e.id,\n        e.name,\n        e.manager_id,\n        CAST(NULL AS VARCHAR) as manager_name,\n        1 as level\n    FROM employees e\n    WHERE e.id = 1\n\n    UNION ALL\n\n    -- Recursive member: join subordinates to the hierarchy\n    SELECT \n        e.id,\n        e.name,\n        e.manager_id,\n        o.name as manager_name,\n        o.level + 1\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.id\n)\nSELECT * FROM org_chart ORDER BY level, manager_id;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for each store using Window Functions.", "output": "SELECT \n    store_id,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) :: NUMERIC(10,2) as moving_avg_7_days\nFROM daily_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Identify 'Islands' of consecutive login days for users. Group consecutive dates into a single range (start_date, end_date) for each user.", "output": "WITH numbered_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtract row_number (in days) from the date to create a constant value for consecutive sequences\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as range_start,\n    MAX(login_date) as range_end,\n    COUNT(*) as consecutive_days\nFROM numbered_dates\nGROUP BY user_id, grp\nORDER BY user_id, range_start;"}
{"instruction": "PostgreSQL DBA Query: List the top 10 largest tables in the database, displaying their size (data only) and total size (including indexes/toast), formatted nicely.", "output": "SELECT\n    schemaname as schema,\n    relname as table_name,\n    pg_size_pretty(pg_relation_size(relid)) as data_size,\n    pg_size_pretty(pg_total_relation_size(relid)) as total_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Find the top 3 selling products per category using DENSE_RANK to handle ties correctly.", "output": "WITH ranked_products AS (\n    SELECT \n        c.category_name,\n        p.product_name,\n        SUM(oi.quantity) as total_sold,\n        DENSE_RANK() OVER (\n            PARTITION BY c.category_name \n            ORDER BY SUM(oi.quantity) DESC\n        ) as rank_in_category\n    FROM products p\n    JOIN categories c ON p.category_id = c.id\n    JOIN order_items oi ON p.id = oi.product_id\n    GROUP BY c.category_name, p.product_name\n)\nSELECT * \nFROM ranked_products \nWHERE rank_in_category <= 3;"}
{"instruction": "PostgreSQL DBA Query: Identify currently active queries that have been running for more than 5 minutes, excluding the current query.", "output": "SELECT \n    pid,\n    usename,\n    application_name,\n    state,\n    now() - query_start as duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Perform a 'Pivot' operation (Cross-tab) using standard SQL aggregation to show total sales per month (columns) for each year (rows).", "output": "SELECT \n    EXTRACT(YEAR FROM order_date) as sales_year,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 1 THEN amount ELSE 0 END) as jan,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 2 THEN amount ELSE 0 END) as feb,\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 3 THEN amount ELSE 0 END) as mar,\n    -- ... continue for other months ...\n    SUM(CASE WHEN EXTRACT(MONTH FROM order_date) = 12 THEN amount ELSE 0 END) as dec,\n    SUM(amount) as total_year\nFROM orders\nGROUP BY EXTRACT(YEAR FROM order_date)\nORDER BY sales_year;"}
{"instruction": "Use a LATERAL JOIN to find the single most recent order for every customer without using a window function (often more efficient for retrieving top-N per group on large datasets).", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nLEFT JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 1\n) o ON true;"}
{"instruction": "PostgreSQL Specific: Query a JSONB column 'attributes' to find the average rating of products where the color attribute is 'Red'.", "output": "SELECT \n    AVG((attributes->>'rating')::NUMERIC) as avg_rating\nFROM products\nWHERE attributes @> '{\"color\": \"Red\"}';"}
{"instruction": "Upsert Operation: Insert a new inventory record, or update the quantity and last_updated timestamp if the product_id and warehouse_id combination already exists.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_updated)\nVALUES (101, 5, 50, NOW())\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Calculate the running total of sales for each salesperson within their respective regions, ordered by sale date, using Window Functions.", "output": "SELECT region, salesperson_id, sale_date, amount, SUM(amount) OVER (PARTITION BY region, salesperson_id ORDER BY sale_date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total FROM sales;"}
{"instruction": "Use a Recursive CTE to traverse an employee hierarchy (adjacency list) and retrieve all subordinates beneath a specific manager (Manager ID 101).", "output": "WITH RECURSIVE subordinates AS (\n  SELECT employee_id, manager_id, full_name, 1 as level\n  FROM employees\n  WHERE manager_id = 101\n  UNION ALL\n  SELECT e.employee_id, e.manager_id, e.full_name, s.level + 1\n  FROM employees e\n  INNER JOIN subordinates s ON e.manager_id = s.employee_id\n)\nSELECT * FROM subordinates;"}
{"instruction": "Identify gaps in a sequence of check numbers (integers) to find missing checks using the LEAD() window function.", "output": "WITH ordered_checks AS (\n  SELECT check_number, LEAD(check_number) OVER (ORDER BY check_number) AS next_check_number\n  FROM checks\n)\nSELECT check_number + 1 AS gap_start, next_check_number - 1 AS gap_end\nFROM ordered_checks\nWHERE next_check_number - check_number > 1;"}
{"instruction": "Perform a conditional aggregation (Pivot) to display total revenue per product category as columns for the years 2021, 2022, and 2023.", "output": "SELECT category,\n  SUM(CASE WHEN EXTRACT(YEAR FROM order_date) = 2021 THEN revenue ELSE 0 END) AS rev_2021,\n  SUM(CASE WHEN EXTRACT(YEAR FROM order_date) = 2022 THEN revenue ELSE 0 END) AS rev_2022,\n  SUM(CASE WHEN EXTRACT(YEAR FROM order_date) = 2023 THEN revenue ELSE 0 END) AS rev_2023\nFROM orders\nGROUP BY category;"}
{"instruction": "Retrieve the top 3 most recent orders for every customer using a LATERAL JOIN for efficient row-per-group limit processing.", "output": "SELECT c.customer_name, o.order_id, o.order_date, o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n  SELECT order_id, order_date, total_amount\n  FROM orders\n  WHERE customer_id = c.id\n  ORDER BY order_date DESC\n  LIMIT 3\n) o;"}
{"instruction": "Calculate the 7-day moving average of daily web traffic using a frame specification in a Window Function.", "output": "SELECT visit_date, daily_visits,\n  AVG(daily_visits) OVER (\n    ORDER BY visit_date\n    ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n  ) AS moving_avg_7d\nFROM web_traffic;"}
{"instruction": "(PostgreSQL) Query a JSONB column 'attributes' to find all products that have the key 'color' set to 'red' and a 'weight' greater than 10.", "output": "SELECT product_id, product_name, attributes\nFROM products\nWHERE attributes @> '{\"color\": \"red\"}'\nAND (attributes->>'weight')::int > 10;"}
{"instruction": "(PostgreSQL Admin) List the 10 largest tables in the database schema, displaying their size in a human-readable format.", "output": "SELECT relname AS table_name,\n  pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "(PostgreSQL Admin) Identify currently running queries that have been active for more than 5 minutes to detect potential performance bottlenecks.", "output": "SELECT pid, usename, state, now() - query_start AS duration, query\nFROM pg_stat_activity\nWHERE state = 'active'\nAND now() - query_start > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Perform a Cohort Analysis to count the percentage of users retained in the months following their first signup.", "output": "WITH first_activity AS (\n  SELECT user_id, DATE_TRUNC('month', MIN(activity_date)) AS cohort_month\n  FROM user_logs\n  GROUP BY user_id\n),\nretention AS (\n  SELECT fa.cohort_month,\n    DATE_PART('month', AGE(DATE_TRUNC('month', ul.activity_date), fa.cohort_month)) AS month_number,\n    COUNT(DISTINCT ul.user_id) AS active_users\n  FROM user_logs ul\n  JOIN first_activity fa ON ul.user_id = fa.user_id\n  GROUP BY 1, 2\n)\nSELECT cohort_month, month_number, active_users\nFROM retention\nORDER BY cohort_month, month_number;"}
{"instruction": "Write a recursive Common Table Expression (CTE) to traverse an employee hierarchy. Given an 'employees' table with 'id', 'name', and 'manager_id', return the hierarchy chain (path of names separated by '->') and the depth level for a specific employee ID (e.g., 105).", "output": "WITH RECURSIVE employee_path AS (\n    -- Anchor member: Start with the specific employee\n    SELECT \n        id, \n        name, \n        manager_id, \n        name::TEXT as path, \n        1 as level\n    FROM employees\n    WHERE id = 105\n\n    UNION ALL\n\n    -- Recursive member: Join with the manager\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        e.name || ' -> ' || ep.path,\n        ep.level + 1\n    FROM employees e\n    INNER JOIN employee_path ep ON e.id = ep.manager_id\n)\nSELECT * FROM employee_path;"}
{"instruction": "Calculate the 7-day moving average of sales amount and the running total of sales for each region, ordered by date. Use Window Functions.", "output": "SELECT \n    region,\n    sale_date,\n    amount,\n    AVG(amount) OVER (\n        PARTITION BY region \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days,\n    SUM(amount) OVER (\n        PARTITION BY region \n        ORDER BY sale_date\n    ) AS running_total\nFROM sales_data\nORDER BY region, sale_date;"}
{"instruction": "Perform a 'Gaps and Islands' analysis to find consecutive login streaks for users. Return the user_id, start_date, end_date, and duration of the streak.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a grouping identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a LATERAL JOIN to retrieve the top 3 most recent orders for every customer, without using a subquery in the SELECT clause or a window function filter in a second step.", "output": "SELECT \n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders o\n    WHERE o.customer_id = c.id\n    ORDER BY o.order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Pivot a table of monthly sales data using PostgreSQL's conditional aggregation (FILTER clause) to show total sales for specific categories ('Electronics', 'Clothing', 'Home') as columns for each month.", "output": "SELECT \n    DATE_TRUNC('month', sale_date) AS sales_month,\n    SUM(amount) FILTER (WHERE category = 'Electronics') AS electronics_sales,\n    SUM(amount) FILTER (WHERE category = 'Clothing') AS clothing_sales,\n    SUM(amount) FILTER (WHERE category = 'Home') AS home_sales,\n    SUM(amount) AS total_monthly_sales\nFROM sales\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "DBA Task: Identify unused indexes in a PostgreSQL database to help with storage optimization. Return the index name, table name, and size, filtering for indexes that have never been scanned.", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as index_scans\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\nAND indexrelname NOT LIKE '%_pkey'\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "DBA Task: Detect currently blocking queries. The output should show the blocked PID, the blocking PID, and the actual query text for both.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.query    AS blocked_statement,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.query   AS current_statement_in_blocking_process\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate the median and the 90th percentile of response times for API logs per endpoint using the PERCENTILE_CONT inverse distribution function.", "output": "SELECT \n    endpoint_url,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY response_time_ms) AS median_response,\n    PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY response_time_ms) AS p90_response\nFROM api_logs\nGROUP BY endpoint_url;"}
{"instruction": "Delete duplicate records from a table named 'contacts' based on the email address, keeping only the record with the highest ID. Use a CTE with a Window Function.", "output": "WITH duplicates_to_delete AS (\n    SELECT \n        id,\n        ROW_NUMBER() OVER (\n            PARTITION BY email \n            ORDER BY id DESC\n        ) as row_num\n    FROM contacts\n)\nDELETE FROM contacts\nWHERE id IN (\n    SELECT id \n    FROM duplicates_to_delete \n    WHERE row_num > 1\n);"}
{"instruction": "Perform a Full Outer Join between two tables, 'budget' (planned) and 'actuals' (spent), coalescing the keys (Year/Month) to ensure no data is lost for periods that exist in one table but not the other.", "output": "SELECT \n    COALESCE(b.year, a.year) as year,\n    COALESCE(b.month, a.month) as month,\n    COALESCE(b.planned_amount, 0) as planned,\n    COALESCE(a.spent_amount, 0) as spent,\n    (COALESCE(a.spent_amount, 0) - COALESCE(b.planned_amount, 0)) as variance\nFROM budget b\nFULL OUTER JOIN actuals a \n    ON b.year = a.year AND b.month = a.month\nORDER BY year, month;"}
{"instruction": "Write a recursive CTE to generate a hierarchical view of employees from an 'employees' table (id, name, manager_id), showing the hierarchy path (e.g., 'CEO > VP > Manager') and the depth level for a specific employee ID.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select the specific employee or root\n    SELECT \n        id, \n        name, \n        manager_id, \n        name::TEXT as path, \n        1 as level\n    FROM employees \n    WHERE manager_id IS NULL -- Or a specific starting ID\n\n    UNION ALL\n\n    -- Recursive member: join to the CTE\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        o.path || ' > ' || e.name,\n        o.level + 1\n    FROM employees e\n    INNER JOIN org_chart o ON e.manager_id = o.id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product, assuming there are missing dates in the source table (requires generating a complete date series first).", "output": "WITH date_series AS (\n    SELECT generate_series(MIN(sale_date), MAX(sale_date), '1 day'::interval)::date AS day\n    FROM sales\n),\nproduct_list AS (\n    SELECT DISTINCT product_id FROM sales\n),\ndense_sales AS (\n    SELECT \n        d.day,\n        p.product_id,\n        COALESCE(s.amount, 0) as daily_amount\n    FROM date_series d\n    CROSS JOIN product_list p\n    LEFT JOIN sales s ON s.sale_date = d.day AND s.product_id = p.product_id\n)\nSELECT \n    day,\n    product_id,\n    daily_amount,\n    AVG(daily_amount) OVER (\n        PARTITION BY product_id \n        ORDER BY day \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7d\nFROM dense_sales\nORDER BY product_id, day;"}
{"instruction": "Find the top 3 highest-paid employees in each department using window functions, handling ties by skipping ranks (e.g., 1, 1, 3).", "output": "WITH ranked_employees AS (\n    SELECT \n        department_id,\n        name,\n        salary,\n        RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT * \nFROM ranked_employees \nWHERE rank_num <= 3;"}
{"instruction": "Pivot a 'payments' table (user_id, payment_date, amount) to show total spend per user for the first quarter (Jan, Feb, Mar) as separate columns using ANSI SQL FILTER clause.", "output": "SELECT \n    user_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM payment_date) = 1) AS jan_spend,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM payment_date) = 2) AS feb_spend,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM payment_date) = 3) AS mar_spend,\n    SUM(amount) AS q1_total\nFROM payments\nWHERE payment_date >= '2023-01-01' AND payment_date < '2023-04-01'\nGROUP BY user_id\nORDER BY q1_total DESC;"}
{"instruction": "Identify 'Islands' of consecutive login days for users. Given a table of user_logins (user_id, login_date), group consecutive dates into a single period with a start and end date.", "output": "WITH grouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtract row number from date; consecutive dates will result in the same constant value\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "PostgreSQL Administration: List the top 10 largest tables in the current database, showing schema name, table name, and pretty-printed total size (including indexes).", "output": "SELECT\n    n.nspname AS schema_name,\n    c.relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(c.oid)) AS total_size\nFROM pg_class c\nLEFT JOIN pg_namespace n ON n.oid = c.relnamespace\nWHERE c.relkind = 'r' -- only ordinary tables\n  AND n.nspname NOT IN ('pg_catalog', 'information_schema')\nORDER BY pg_total_relation_size(c.oid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL JOIN to find the 2 most recent comments for every blog post without using a window function in the select clause.", "output": "SELECT \n    p.title,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments\n    WHERE post_id = p.id\n    ORDER BY created_at DESC\n    LIMIT 2\n) c;"}
{"instruction": "PostgreSQL JSONB: Given a table 'events' with a JSONB column 'payload' containing keys {'browser': '...', 'os': '...', 'load_time': 120}, calculate the average load time per browser.", "output": "SELECT \n    payload ->> 'browser' as browser_name,\n    AVG((payload ->> 'load_time')::numeric) as avg_load_time\nFROM events\nGROUP BY payload ->> 'browser'\nORDER BY avg_load_time DESC;"}
{"instruction": "PostgreSQL Administration: Identify currently running queries that have been active for more than 5 minutes, excluding the current query.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start as duration, \n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > interval '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Perform a 'Gap Analysis' to find missing order IDs. Assuming order_ids should be sequential integers, find the start and end of any gaps in the sequence.", "output": "WITH lag_orders AS (\n    SELECT \n        order_id,\n        LAG(order_id) OVER (ORDER BY order_id) as prev_order_id\n    FROM orders\n)\nSELECT \n    prev_order_id + 1 as gap_start,\n    order_id - 1 as gap_end\nFROM lag_orders\nWHERE order_id - prev_order_id > 1;"}
{"instruction": "Write a query using a recursive CTE to generate an organizational hierarchy chart. The output should show the employee's name, their manager's name, and their level (depth) in the organization, starting from the CEO (where manager_id is NULL).", "output": "WITH RECURSIVE org_hierarchy AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        employee_id,\n        name,\n        manager_id,\n        1 AS level,\n        CAST(name AS TEXT) AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE with employees to find direct reports\n    SELECT \n        e.employee_id,\n        e.name,\n        e.manager_id,\n        oh.level + 1,\n        oh.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_hierarchy oh ON e.manager_id = oh.employee_id\n)\nSELECT \n    name,\n    level,\n    path\nFROM org_hierarchy\nORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily sales for each product, ordered by date. Use window functions to include the current row and the 6 preceding rows in the calculation.", "output": "SELECT \n    product_id,\n    sale_date,\n    daily_sales_amount,\n    AVG(daily_sales_amount) OVER (\n        PARTITION BY product_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM product_sales\nORDER BY product_id, sale_date;"}
{"instruction": "Identify the top 3 highest-paid employees in each department using the DENSE_RANK() function to handle ties appropriately.", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary,\n    rank\nFROM RankedSalaries\nWHERE rank <= 3;"}
{"instruction": "PostgreSQL Administration: Write a query to find the size of a specific table (e.g., 'orders') including its indexes and toast data, and format the output in a human-readable format (e.g., MB, GB).", "output": "SELECT \n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_toast_size\nFROM pg_catalog.pg_statio_user_tables \nWHERE relname = 'orders';"}
{"instruction": "Perform a 'Gap Filling' analysis. Given a table of sales, generate a report showing every day in January 2023, filling in dates with 0 sales if no record exists for that day. Use `generate_series`.", "output": "SELECT \n    calendar.day::date AS report_date,\n    COALESCE(SUM(s.amount), 0) AS total_sales\nFROM \n    generate_series(\n        '2023-01-01'::timestamp, \n        '2023-01-31'::timestamp, \n        '1 day'::interval\n    ) AS calendar(day)\nLEFT JOIN sales s ON s.sale_date = calendar.day::date\nGROUP BY calendar.day\nORDER BY calendar.day;"}
{"instruction": "Write a query to calculate Year-Over-Year (YoY) growth percentage for total revenue by year. Use the LAG() window function.", "output": "WITH YearlyRevenue AS (\n    SELECT \n        EXTRACT(YEAR FROM order_date) AS year,\n        SUM(amount) AS total_revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT \n    year,\n    total_revenue,\n    LAG(total_revenue) OVER (ORDER BY year) AS prev_year_revenue,\n    ROUND(\n        ((total_revenue - LAG(total_revenue) OVER (ORDER BY year)) / \n        LAG(total_revenue) OVER (ORDER BY year)) * 100, 2\n    ) AS yoy_growth_percentage\nFROM YearlyRevenue;"}
{"instruction": "PostgreSQL Administration: Identify unused indexes in the database. Find indexes that have not been used (scanned) since the statistics were last reset, excluding primary keys and unique constraints.", "output": "SELECT \n    schemaname,\n    relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan AS index_scans\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0 \n  AND indisunique IS FALSE\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Group user web events into 'sessions'. A new session starts if a user is inactive for more than 30 minutes. Use LAG to detect time gaps and a running SUM to assign session IDs.", "output": "WITH TimeGaps AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        CASE \n            WHEN event_timestamp - LAG(event_timestamp) OVER (PARTITION BY user_id ORDER BY event_timestamp) > INTERVAL '30 minutes' \n            THEN 1 \n            ELSE 0 \n        END AS is_new_session\n    FROM web_events\n),\nSessionized AS (\n    SELECT \n        user_id,\n        event_timestamp,\n        SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY event_timestamp) AS session_id\n    FROM TimeGaps\n)\nSELECT \n    user_id,\n    session_id,\n    MIN(event_timestamp) AS session_start,\n    MAX(event_timestamp) AS session_end,\n    COUNT(*) AS events_in_session\nFROM Sessionized\nGROUP BY user_id, session_id;"}
{"instruction": "Pivot a dataset using the PostgreSQL `FILTER` clause. Transform a table of (Department, Gender, Count) into a single row per department with columns for Male_Count, Female_Count, and Other_Count.", "output": "SELECT \n    department_name,\n    COUNT(*) FILTER (WHERE gender = 'Male') AS male_count,\n    COUNT(*) FILTER (WHERE gender = 'Female') AS female_count,\n    COUNT(*) FILTER (WHERE gender NOT IN ('Male', 'Female')) AS other_count\nFROM employees\nGROUP BY department_name;"}
{"instruction": "PostgreSQL Administration: Detect blocking queries. Write a query to find processes that are waiting for locks and the specific query that is blocking them.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocked_activity.query AS blocked_query,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Write a query using a Window Function to find the top 3 highest-paid employees in each department. If there is a tie in salary, they should share the same rank, and the next rank should be skipped (e.g., 1, 1, 3).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank\n    FROM employees\n)\nSELECT * \nFROM RankedSalaries\nWHERE salary_rank <= 3;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of an organization chart. The table 'employees' has 'id', 'name', and 'manager_id'. The output should show the employee name and their level in the hierarchy (1 being the CEO/top manager).", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: select the top manager (who has no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oc.level + 1\n    FROM employees e\n    INNER JOIN OrgChart oc ON e.manager_id = oc.id\n)\nSELECT * FROM OrgChart\nORDER BY level, name;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue using Window Functions. The table 'daily_sales' contains 'sale_date' and 'revenue'.", "output": "SELECT \n    sale_date,\n    revenue,\n    AVG(revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7d\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Write a PostgreSQL DBA query to list all tables in the current database along with their total size (including indexes) in a human-readable format, ordered by size descending.", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Solve the 'Gaps and Islands' problem: Identify consecutive days where a user logged in. Group these consecutive days into a single 'streak' record with a start date, end date, and streak length.", "output": "WITH GroupedDates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Subtract row number from date to create a constant value for consecutive groups\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_length\nFROM GroupedDates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a LATERAL JOIN to find the 3 most recent orders for every customer. This approach is often more efficient than a window function when finding 'Top N per group' on large datasets with indexes.", "output": "SELECT \n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, amount\n    FROM orders\n    WHERE customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Create a pivot table using PostgreSQL's FILTER clause to show total sales for each product category for the months of January, February, and March.", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nGROUP BY category_name;"}
{"instruction": "Write a query to identify customers who purchased product A but have NEVER purchased product B. Use NOT EXISTS for the exclusion logic.", "output": "SELECT DISTINCT c.customer_id, c.email\nFROM customers c\nJOIN orders o1 ON c.customer_id = o1.customer_id\nWHERE o1.product_id = 'Product_A'\nAND NOT EXISTS (\n    SELECT 1 \n    FROM orders o2 \n    WHERE o2.customer_id = c.customer_id \n    AND o2.product_id = 'Product_B'\n);"}
{"instruction": "PostgreSQL DBA Task: Identify currently active queries that have been running for more than 5 minutes, excluding the current query itself.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Delete duplicate rows from a table named 'contacts' based on the 'email' column, keeping only the entry with the lowest 'id'. Use a CTE with ROW_NUMBER.", "output": "WITH Duplicates AS (\n    SELECT \n        id,\n        ROW_NUMBER() OVER (PARTITION BY email ORDER BY id ASC) as rn\n    FROM contacts\n)\nDELETE FROM contacts\nWHERE id IN (\n    SELECT id \n    FROM Duplicates \n    WHERE rn > 1\n);"}
{"instruction": "Write a Recursive Common Table Expression (CTE) to retrieve an entire organizational hierarchy starting from a top-level manager (id = 1). The output should show the employee ID, name, manager ID, and their depth level in the hierarchy.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select the top-level manager\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS depth_level\n    FROM employees\n    WHERE manager_id IS NULL OR employee_id = 1\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers in the CTE\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.depth_level + 1\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart\nORDER BY depth_level, manager_id;"}
{"instruction": "Using window functions, identify the top 3 highest-paid employees within each specific department. Handle ties by including all employees with the same salary (using DENSE_RANK).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (\n            PARTITION BY department_id \n            ORDER BY salary DESC\n        ) as salary_rank\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary,\n    salary_rank\nFROM RankedSalaries\nWHERE salary_rank <= 3;"}
{"instruction": "Calculate a 7-day moving average of daily sales revenue for the current year. The result should include the date, daily revenue, and the moving average.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date\n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_day\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "Write a query to find customers who have purchased products from the 'Electronics' category but have NEVER purchased products from the 'Books' category. Use aggregation and the FILTER clause (or CASE statement).", "output": "SELECT \n    c.customer_id,\n    c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nGROUP BY c.customer_id, c.customer_name\nHAVING \n    COUNT(*) FILTER (WHERE p.category = 'Electronics') > 0\n    AND \n    COUNT(*) FILTER (WHERE p.category = 'Books') = 0;"}
{"instruction": "DBA Task: Write a PostgreSQL query to list the top 10 largest tables in the current database schema, displaying their size in a human-readable format (e.g., MB, GB), including indexes and toast data.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Solve the 'Gaps and Islands' problem: Given a table of user login dates, identify streaks of consecutive days a user logged in. Return the user_id, start_date, end_date, and length of the streak.", "output": "WITH GroupedDates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - CAST(ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) AS INTEGER) AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_length\nFROM GroupedDates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a LATERAL JOIN to retrieve the 3 most recent comments for every blog post published in 2023. This avoids calculating a rank for the entire comments table.", "output": "SELECT \n    p.post_id,\n    p.title,\n    recent_comments.comment_text,\n    recent_comments.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT \n        c.comment_text, \n        c.created_at\n    FROM comments c\n    WHERE c.post_id = p.post_id\n    ORDER BY c.created_at DESC\n    LIMIT 3\n) AS recent_comments\nWHERE p.published_date >= '2023-01-01' AND p.published_date <= '2023-12-31';"}
{"instruction": "DBA Task: Identify currently blocking queries in PostgreSQL. The output should show the PID of the blocked query, the PID of the blocking query, and the actual query text of the blocker.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Perform a 'Pivot' operation to display total sales per region (rows) for each quarter (columns) of the current year. Assume columns: region, sale_date, amount.", "output": "SELECT \n    region,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS \"Q1\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS \"Q2\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS \"Q3\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS \"Q4\"\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY region\nORDER BY region;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation. Insert a new user record, but if the email already exists in the database, update their 'last_login' timestamp instead.", "output": "INSERT INTO users (username, email, last_login)\nVALUES ('jdoe', 'john.doe@example.com', NOW())\nON CONFLICT (email) \nDO UPDATE SET \n    last_login = EXCLUDED.last_login,\n    username = EXCLUDED.username;"}
{"instruction": "Write a recursive CTE to generate a hierarchical view of an organization. Given an 'employees' table with 'id', 'name', and 'manager_id', return the management chain for a specific employee (ID 105) starting from the CEO down to that employee.", "output": "WITH RECURSIVE management_chain AS (\n    -- Anchor member: Start with the specific employee\n    SELECT id, name, manager_id, 1 AS level\n    FROM employees\n    WHERE id = 105\n\n    UNION ALL\n\n    -- Recursive member: Join with the manager\n    SELECT e.id, e.name, e.manager_id, mc.level + 1\n    FROM employees e\n    INNER JOIN management_chain mc ON e.id = mc.manager_id\n)\nSELECT * FROM management_chain;"}
{"instruction": "Calculate the 7-day moving average of daily sales and the percentage growth compared to the previous day using window functions.", "output": "SELECT \n    sale_date,\n    daily_total,\n    AVG(daily_total) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days,\n    (daily_total - LAG(daily_total) OVER (ORDER BY sale_date)) / \n    NULLIF(LAG(daily_total) OVER (ORDER BY sale_date), 0) * 100 AS growth_percent\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login data. Find the start date, end date, and length of every consecutive daily login streak for each user.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "PostgreSQL Admin: Write a query to list the top 10 largest tables in the database, including the size of their associated indexes, displaying the size in a human-readable format.", "output": "SELECT\n    schemaname AS schema,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL JOIN to find the top 3 most recent orders for every customer who has signed up in the last year. This avoids a complex window function subquery for filtering.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nWHERE c.signup_date >= NOW() - INTERVAL '1 year';"}
{"instruction": "Perform a pivot operation (cross-tabulation) to display total sales per product category (rows) for each quarter (columns) of the current year using PostgreSQL's FILTER clause.", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS q2_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS q3_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS q4_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY category_name;"}
{"instruction": "PostgreSQL Admin: Identify currently active queries that have been running for more than 5 minutes, excluding the query checking for them.", "output": "SELECT \n    pid,\n    usename,\n    state,\n    age(clock_timestamp(), query_start) AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND age(clock_timestamp(), query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Calculate the median salary for each department. Since there is no standard aggregate MEDIAN function, use the PERCENTILE_CONT inverse distribution function.", "output": "SELECT \n    department_id,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY salary) AS median_salary\nFROM employees\nGROUP BY department_id;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) in PostgreSQL. Insert a new inventory record for a product, but if the product_id already exists, add the new quantity to the existing quantity.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_updated)\nVALUES (101, 5, 50, NOW())\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Work with JSONB data: Select all rows where the 'attributes' JSONB column contains a key 'tags' which holds an array containing the value 'urgent', and expand that JSON array into rows.", "output": "SELECT \n    id, \n    attributes->>'title' as title,\n    jsonb_array_elements_text(attributes->'tags') as tag\nFROM tickets\nWHERE attributes @> '{\"tags\": [\"urgent\"]}';"}
{"instruction": "Write a recursive Common Table Expression (CTE) to retrieve the full organizational hierarchy for a specific manager (ID 101), showing the depth level of each subordinate.", "output": "WITH RECURSIVE employee_hierarchy AS (\n    -- Base Case: The Manager\n    SELECT \n        employee_id, \n        manager_id, \n        full_name, \n        job_title, \n        0 AS hierarchy_level\n    FROM employees\n    WHERE employee_id = 101\n\n    UNION ALL\n\n    -- Recursive Step: Subordinates\n    SELECT \n        e.employee_id, \n        e.manager_id, \n        e.full_name, \n        e.job_title, \n        eh.hierarchy_level + 1\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy\nORDER BY hierarchy_level, full_name;"}
{"instruction": "Calculate the 3-day moving average of sales revenue for each store, ordered by date, using window functions.", "output": "SELECT \n    store_id,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_3_days\nFROM store_sales\nORDER BY store_id, sale_date;"}
{"instruction": "Identify 'Churned' users: Users who placed an order in the previous month but have not placed any orders in the current month. Use a set operation or complex join.", "output": "SELECT user_id \nFROM orders\nWHERE order_date >= DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month')\n  AND order_date < DATE_TRUNC('month', CURRENT_DATE)\n\nEXCEPT\n\nSELECT user_id \nFROM orders\nWHERE order_date >= DATE_TRUNC('month', CURRENT_DATE);"}
{"instruction": "PostgreSQL DBA Task: Identify unused indexes in the database to optimize storage and write performance. Return the index name and the size of the index.", "output": "SELECT \n    schemaname || '.' || relname AS table_name,\n    indexrelname AS index_name,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan as number_of_scans\nFROM pg_stat_user_indexes\nJOIN pg_index USING (indexrelid)\nWHERE idx_scan = 0 \n  AND indisunique IS FALSE\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Solve the 'Gaps and Islands' problem: Identify consecutive ranges of dates where a user logged in daily.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number (in days) from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Pivot a sales table to display total sales per product (rows) for each quarter (columns) using the FILTER clause (ANSI SQL standard for pivoting).", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS \"Q1_Sales\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS \"Q2_Sales\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS \"Q3_Sales\",\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS \"Q4_Sales\"\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_name;"}
{"instruction": "PostgreSQL DBA Task: Find currently active queries that are being blocked by locks, including the PID of the blocking query.", "output": "SELECT \n    blocked_locks.pid AS blocked_pid,\n    blocked_activity.usename AS blocked_user,\n    blocking_locks.pid AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocked_activity.query AS blocked_query,\n    blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Remove duplicate rows from a table named 'contacts' based on email, keeping only the entry with the most recent 'created_at' timestamp.", "output": "DELETE FROM contacts\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY created_at DESC) as rn\n        FROM contacts\n    ) t\n    WHERE rn > 1\n);"}
{"instruction": "Analyze Year-Over-Year (YoY) growth: Calculate the total revenue for the current year and the percentage change compared to the previous year.", "output": "WITH yearly_revenue AS (\n    SELECT \n        EXTRACT(YEAR FROM order_date) AS report_year,\n        SUM(total_amount) AS annual_revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT \n    report_year,\n    annual_revenue,\n    LAG(annual_revenue) OVER (ORDER BY report_year) AS prev_year_revenue,\n    ROUND(\n        ((annual_revenue - LAG(annual_revenue) OVER (ORDER BY report_year)) / \n        NULLIF(LAG(annual_revenue) OVER (ORDER BY report_year), 0)) * 100, \n    2) AS yoy_growth_percentage\nFROM yearly_revenue;"}
{"instruction": "Use a LATERAL JOIN to unpack a JSONB array column (e.g., 'tags') in PostgreSQL and count the occurrence of each tag across all posts.", "output": "SELECT \n    tag_element #>> '{}' AS tag_name,\n    COUNT(*) AS tag_count\nFROM posts,\nLATERAL jsonb_array_elements(posts.tags) AS tag_element\nGROUP BY tag_name\nORDER BY tag_count DESC;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and window functions to find the top 3 highest-paid employees within each department. Handle ties using DENSE_RANK.", "output": "WITH RankedSalaries AS (\n    SELECT \n        employee_id,\n        first_name,\n        last_name,\n        department_id,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank\n    FROM employees\n)\nSELECT \n    employee_id,\n    first_name,\n    last_name,\n    department_id,\n    salary\nFROM RankedSalaries\nWHERE salary_rank <= 3;"}
{"instruction": "Create a recursive CTE to generate a hierarchical view of categories (breadcrumbs) from an adjacency list table 'categories' having columns 'id', 'name', and 'parent_id'.", "output": "WITH RECURSIVE CategoryPath (id, name, path) AS (\n    SELECT \n        id, \n        name, \n        CAST(name AS TEXT) as path\n    FROM categories\n    WHERE parent_id IS NULL\n    UNION ALL\n    SELECT \n        c.id, \n        c.name, \n        cp.path || ' > ' || c.name\n    FROM categories c\n    INNER JOIN CategoryPath cp ON c.parent_id = cp.id\n)\nSELECT id, name, path FROM CategoryPath ORDER BY path;"}
{"instruction": "Write a PostgreSQL administration query to identify currently active queries that have been running for more than 5 minutes.", "output": "SELECT\n    pid,\n    usename,\n    application_name,\n    client_addr,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE \n    state = 'active' \n    AND (now() - query_start) > interval '5 minutes';"}
{"instruction": "Calculate the Month-over-Month (MoM) percentage growth in sales revenue for the current year using the LAG() window function.", "output": "WITH MonthlySales AS (\n    SELECT \n        DATE_TRUNC('month', sale_date) as sale_month,\n        SUM(amount) as total_revenue\n    FROM sales\n    WHERE EXTRACT(YEAR FROM sale_date) = 2023\n    GROUP BY 1\n)\nSELECT \n    sale_month,\n    total_revenue,\n    LAG(total_revenue) OVER (ORDER BY sale_month) as prev_month_revenue,\n    ROUND(\n        ((total_revenue - LAG(total_revenue) OVER (ORDER BY sale_month)) / \n        LAG(total_revenue) OVER (ORDER BY sale_month)) * 100, 2\n    ) as mom_growth_percentage\nFROM MonthlySales;"}
{"instruction": "Use a LATERAL join to retrieve the 3 most recent orders for every customer who has placed an order in the last 30 days.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nJOIN orders active_orders ON c.customer_id = active_orders.customer_id \n    AND active_orders.order_date >= CURRENT_DATE - INTERVAL '30 days'\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders sub_o\n    WHERE sub_o.customer_id = c.customer_id\n    ORDER BY sub_o.order_date DESC\n    LIMIT 3\n) o\nGROUP BY c.customer_id, c.customer_name, o.order_id, o.order_date, o.total_amount;"}
{"instruction": "Perform a 'Gaps and Islands' analysis to identify consecutive days a user logged in. Return the start date, end date, and count of consecutive days for each streak.", "output": "WITH GroupedLogins AS (\n    SELECT \n        user_id,\n        login_date,\n        login_date - CAST(ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) AS INTEGER) AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS consecutive_days\nFROM GroupedLogins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Write a PostgreSQL query to find the total size (data + indexes) of a specific table in a human-readable format.", "output": "SELECT \n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nWHERE relname = 'target_table_name';"}
{"instruction": "Pivot sales data using the FILTER clause (ANSI SQL compliant) to show total sales per product for Q1, Q2, Q3, and Q4 in a single row per product.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS q2_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS q3_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS q4_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_name;"}
{"instruction": "Identify unused indexes in a PostgreSQL database to optimize storage and write performance.", "output": "SELECT\n    schemaname,\n    relname AS table_name,\n    indexrelname AS index_name,\n    idx_scan,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\nAND indexrelname NOT LIKE '%pkey%'\nORDER BY pg_relation_size(indexrelid) DESC;"}
{"instruction": "Calculate a 7-day moving average of daily sign-ups using a window function with a frame clause.", "output": "SELECT \n    signup_date,\n    daily_signups,\n    AVG(daily_signups) OVER (\n        ORDER BY signup_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_stats\nORDER BY signup_date;"}
{"instruction": "Write a recursive Common Table Expression (CTE) to generate a hierarchical view of an organization. The output should include the employee's ID, name, manager's name, and their depth level in the hierarchy, starting with the CEO (who has no manager).", "output": "WITH RECURSIVE org_hierarchy AS (\n    -- Anchor member: Select the top-level management (CEO)\n    SELECT \n        e.employee_id, \n        e.name,\n        e.manager_id,\n        NULL::VARCHAR AS manager_name,\n        1 AS hierarchy_level\n    FROM employees e\n    WHERE e.manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE with employees to find direct reports\n    SELECT \n        e.employee_id, \n        e.name,\n        e.manager_id,\n        oh.name AS manager_name,\n        oh.hierarchy_level + 1\n    FROM employees e\n    INNER JOIN org_hierarchy oh ON e.manager_id = oh.employee_id\n)\nSELECT * FROM org_hierarchy ORDER BY hierarchy_level, manager_id;"}
{"instruction": "Create a query to calculate the 7-day rolling average of daily sales for each product category, ensuring rows are ordered by date.", "output": "SELECT \n    category_id,\n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        PARTITION BY category_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS rolling_7_day_avg\nFROM daily_sales_summary\nORDER BY category_id, sale_date;"}
{"instruction": "Identify the top 3 highest-paid employees per department. Handle ties by including all employees with the same salary if they qualify for the top 3 spots (Dense Rank).", "output": "WITH ranked_employees AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT * \nFROM ranked_employees \nWHERE rank_num <= 3;"}
{"instruction": "DBA Task: Write a PostgreSQL query to identify queries that have been running for more than 5 minutes, including the user, the database name, and the full query text.", "output": "SELECT \n    pid,\n    usename AS username,\n    datname AS database_name,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Perform a 'Gaps and Islands' analysis to find consecutive login streaks for users. Group consecutive days of activity into a single range (start_date, end_date).", "output": "WITH distinct_logins AS (\n    -- Ensure one record per day per user\n    SELECT DISTINCT user_id, login_date \n    FROM user_logins\n),\ngrouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a grouping identifier by subtracting row_number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM distinct_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Use a Lateral Join to efficiently retrieve the single most recent order for every customer, along with the customer's details. This acts as a 'for-each' loop optimized for PostgreSQL.", "output": "SELECT \n    c.customer_id,\n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nLEFT JOIN LATERAL (\n    SELECT *\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 1\n) o ON true;"}
{"instruction": "Pivot a table of monthly sales data to display months as columns (Jan, Feb, Mar) for the current year using PostgreSQL's `FILTER` clause for conditional aggregation.", "output": "SELECT \n    product_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_id;"}
{"instruction": "DBA Task: List the top 10 largest tables in the database, displaying their size in a human-readable format (e.g., MB, GB), covering both relation data and index size.", "output": "SELECT \n    schemaname,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform a 'Month-over-Month' growth analysis. Calculate the percentage difference in revenue between the current month and the previous month for each product.", "output": "WITH monthly_sales AS (\n    SELECT \n        product_id,\n        DATE_TRUNC('month', sale_date) as sales_month,\n        SUM(revenue) as total_revenue\n    FROM sales\n    GROUP BY 1, 2\n),\nlagged_sales AS (\n    SELECT \n        product_id,\n        sales_month,\n        total_revenue,\n        LAG(total_revenue) OVER (PARTITION BY product_id ORDER BY sales_month) as prev_month_revenue\n    FROM monthly_sales\n)\nSELECT \n    product_id,\n    sales_month,\n    total_revenue,\n    prev_month_revenue,\n    ROUND(((total_revenue - prev_month_revenue) / prev_month_revenue) * 100, 2) as growth_percentage\nFROM lagged_sales\nWHERE prev_month_revenue IS NOT NULL;"}
{"instruction": "Write an UPSERT (Insert or Update) statement. Insert a new inventory record for a product, but if the product_id already exists, update the quantity by adding the new amount to the existing stock.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_updated)\nVALUES (101, 1, 50, NOW())\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Create a query using a Recursive CTE to generate an organizational hierarchy chart. The query should display the employee's name, their manager's name, and their hierarchical level (depth) within the organization, starting from the top-level CEO (where manager_id is NULL).", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: select the top-level manager(s)\n    SELECT \n        employee_id,\n        full_name,\n        manager_id,\n        1 AS hierarchy_level,\n        CAST(full_name AS TEXT) AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.employee_id,\n        e.full_name,\n        e.manager_id,\n        oc.hierarchy_level + 1,\n        oc.path || ' -> ' || e.full_name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart\nORDER BY path;"}
{"instruction": "Write a query to calculate the 7-day moving average of daily revenue for the current year. Use a window function with a frame clause to ensure the average includes the current row and the 6 preceding days.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date\n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM (\n    SELECT \n        DATE(created_at) as sale_date, \n        SUM(amount) as daily_revenue\n    FROM sales\n    WHERE EXTRACT(YEAR FROM created_at) = EXTRACT(YEAR FROM CURRENT_DATE)\n    GROUP BY DATE(created_at)\n) daily_sales\nORDER BY sale_date;"}
{"instruction": "Identify 'Islands and Gaps' in a sequence of IDs. Write a query to find missing ID numbers in the 'invoices' table. The output should show the start and end of any gap in the sequence.", "output": "WITH checked_sequences AS (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) AS next_invoice_id\n    FROM invoices\n)\nSELECT \n    invoice_id + 1 AS gap_start,\n    next_invoice_id - 1 AS gap_end\nFROM checked_sequences\nWHERE next_invoice_id - invoice_id > 1;"}
{"instruction": "Use a `LATERAL` join to retrieve the top 3 most recent orders for every customer who has placed at least one order. The result should include the customer's name, order ID, and order date.", "output": "SELECT \n    c.customer_name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT \n        order_id, \n        order_date, \n        total_amount\n    FROM orders\n    WHERE user_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o;"}
{"instruction": "Perform a Pivot operation using conditional aggregation (PostgreSQL `FILTER` clause) to display total sales per region for each quarter of the year 2023. The rows should be regions, and columns should be Q1, Q2, Q3, Q4.", "output": "SELECT \n    region,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS q2_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS q3_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS q4_sales\nFROM sales_data\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY region\nORDER BY region;"}
{"instruction": "Write a query to find duplicate email addresses in the 'users' table, but keep the row with the lowest ID. The output should generate the `DELETE` statement required to remove the duplicates using a CTE.", "output": "WITH duplicates AS (\n    SELECT \n        id,\n        ROW_NUMBER() OVER (\n            PARTITION BY email \n            ORDER BY id ASC\n        ) AS row_num\n    FROM users\n)\nDELETE FROM users\nWHERE id IN (\n    SELECT id \n    FROM duplicates \n    WHERE row_num > 1\n);"}
{"instruction": "Database Administration: Write a PostgreSQL query to list the top 10 largest tables in the current database schema, displaying the table name and its size in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Database Administration: Identify currently active queries that are blocking other transactions. The output should show the blocked PID, the blocking PID, and the query being executed by the blocking process.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query   AS blocking_query\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Write a query using `jsonb_array_elements` (PostgreSQL) to flatten a JSONB column containing a list of tags. Count the occurrences of each tag across all records and order by popularity.", "output": "SELECT \n    tag,\n    COUNT(*) as frequency\nFROM books,\n     jsonb_array_elements_text(metadata -> 'tags') AS tag\nGROUP BY tag\nORDER BY frequency DESC;"}
{"instruction": "Calculate the retention rate of users. Specifically, find the percentage of users who signed up in January 2023 and logged in again during February 2023.", "output": "WITH jan_cohort AS (\n    SELECT user_id \n    FROM users \n    WHERE date_trunc('month', signup_date) = '2023-01-01'\n),\nretained_users AS (\n    SELECT DISTINCT l.user_id\n    FROM logins l\n    JOIN jan_cohort c ON l.user_id = c.user_id\n    WHERE date_trunc('month', l.login_date) = '2023-02-01'\n)\nSELECT \n    (SELECT COUNT(*) FROM jan_cohort) AS total_cohort,\n    (SELECT COUNT(*) FROM retained_users) AS retained_count,\n    ROUND(\n        (SELECT COUNT(*)::NUMERIC FROM retained_users) / \n        (SELECT COUNT(*)::NUMERIC FROM jan_cohort) * 100, 2\n    ) AS retention_rate_percent;"}
{"instruction": "Write a query to identify the top 3 highest-paid employees in each department. If there are ties in salary, they should share the same rank, and the next rank should be skipped (use RANK).", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id, \n        employee_name, \n        salary,\n        RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank\n    FROM employees\n)\nSELECT * \nFROM RankedSalaries \nWHERE salary_rank <= 3;"}
{"instruction": "Create a Recursive CTE to generate a hierarchical view of an organization chart, showing the employee ID, name, and their level in the hierarchy (starting at level 1 for employees with no manager).", "output": "WITH RECURSIVE OrgChart AS (\n    -- Anchor member: Top-level managers\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS hierarchy_level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Subordinates\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.hierarchy_level + 1\n    FROM employees e\n    INNER JOIN OrgChart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM OrgChart ORDER BY hierarchy_level, manager_id;"}
{"instruction": "Calculate the 7-day moving average of sales for each day, assuming the table 'daily_sales' has columns 'sale_date' and 'amount'. The window should include the current row and the 6 preceding rows.", "output": "SELECT \n    sale_date, \n    amount,\n    AVG(amount) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales;"}
{"instruction": "Perform a pivot operation to display total sales per year for 'Electronics' and 'Furniture' categories as separate columns using the PostgreSQL FILTER clause.", "output": "SELECT \n    EXTRACT(YEAR FROM order_date) AS sales_year,\n    SUM(amount) FILTER (WHERE category = 'Electronics') AS total_electronics,\n    SUM(amount) FILTER (WHERE category = 'Furniture') AS total_furniture\nFROM orders\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Write a query to solve the 'Gaps and Islands' problem. Identify consecutive days where a specific user logged in. Output the start date, end date, and duration of each login streak.", "output": "WITH GroupedDates AS (\n    SELECT \n        login_date,\n        -- Subtract the row number (in days) from the date to create a constant value for consecutive groups\n        login_date - (ROW_NUMBER() OVER (ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM user_logins\n    WHERE user_id = 101\n)\nSELECT \n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as streak_days\nFROM GroupedDates\nGROUP BY grp\nORDER BY streak_start;"}
{"instruction": "Perform an 'Upsert' operation: Insert a new inventory record for product_id 500 with a quantity of 10. If the product_id already exists, update the existing record by adding 10 to the current quantity.", "output": "INSERT INTO inventory (product_id, quantity, last_updated)\nVALUES (500, 10, NOW())\nON CONFLICT (product_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Use a LATERAL JOIN to retrieve the most recent 3 comments for every blog post written by a specific author.", "output": "SELECT \n    p.post_id, \n    p.title, \n    recent_comments.comment_body, \n    recent_comments.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_body, created_at\n    FROM comments c\n    WHERE c.post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 3\n) AS recent_comments\nWHERE p.author_id = 1;"}
{"instruction": "DBA Task: Write a query to find the total size (data + indexes) of all tables in the 'public' schema, ordered by size descending.", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_total_relation_size(relid) AS raw_size\nFROM pg_catalog.pg_statio_user_tables\nWHERE schemaname = 'public'\nORDER BY raw_size DESC;"}
{"instruction": "DBA Task: Identify currently active queries that have been running for longer than 5 minutes.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    now() - query_start AS duration, \n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Write a query to find customers who have purchased product A but have NEVER purchased product B.", "output": "SELECT c.customer_id, c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nGROUP BY c.customer_id, c.customer_name\nHAVING \n    COUNT(CASE WHEN oi.product_name = 'Product A' THEN 1 END) > 0\n    AND \n    COUNT(CASE WHEN oi.product_name = 'Product B' THEN 1 END) = 0;"}
{"instruction": "Create a query using a Recursive CTE to generate a hierarchical view of employees and their managers, including a calculated 'level' column indicating their depth in the organization.", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n    -- Anchor member: Select top-level managers (those with no manager)\n    SELECT \n        employee_id, \n        first_name, \n        last_name, \n        manager_id, \n        1 AS hierarchy_level,\n        CAST(first_name || ' ' || last_name AS TEXT) AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE with employees to find subordinates\n    SELECT \n        e.employee_id, \n        e.first_name, \n        e.last_name, \n        e.manager_id, \n        eh.hierarchy_level + 1,\n        eh.path || ' -> ' || e.first_name || ' ' || e.last_name\n    FROM employees e\n    INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM EmployeeHierarchy\nORDER BY path;"}
{"instruction": "Write a query to find the top 3 highest-paid employees within each department using window functions.", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        first_name,\n        last_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank\n    FROM employees\n)\nSELECT \n    department_id,\n    first_name,\n    last_name,\n    salary\nFROM RankedSalaries\nWHERE rank <= 3\nORDER BY department_id, salary DESC;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue using a window function.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7_days\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login data to find consecutive days a user logged in.", "output": "WITH DatedLogins AS (\n    -- Remove duplicate logins per day\n    SELECT DISTINCT user_id, login_date \n    FROM user_logins\n),\nGroupedLogins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM DatedLogins\n)\nSELECT \n    user_id,\n    MIN(login_date) as streak_start,\n    MAX(login_date) as streak_end,\n    COUNT(*) as consecutive_days\nFROM GroupedLogins\nGROUP BY user_id, grp\nHAVING COUNT(*) >= 2\nORDER BY user_id, streak_start;"}
{"instruction": "PostgreSQL Administration: List the top 10 largest tables in the database, including their index size, formatted in a human-readable size.", "output": "SELECT\n    schemaname AS table_schema,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use a LATERAL JOIN to efficiently retrieve the 3 most recent comments for every blog post published in 2023.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_id,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT \n        comment_id, \n        comment_text, \n        created_at\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c\nWHERE p.published_date >= '2023-01-01' AND p.published_date <= '2023-12-31';"}
{"instruction": "Pivot a sales table to display total revenue per month (columns) for each product category (rows) using PostgreSQL FILTER clause.", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 4) AS apr_sales\n    -- Continue for remaining months...\nFROM sales s\nJOIN categories c ON s.category_id = c.category_id\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY category_name\nORDER BY category_name;"}
{"instruction": "PostgreSQL Administration: Identify currently active queries that have been running for more than 5 minutes to detect potential performance bottlenecks.", "output": "SELECT \n    pid,\n    usename,\n    application_name,\n    client_addr,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Compare the Month-over-Month (MoM) revenue growth percentage for the current year.", "output": "WITH MonthlySales AS (\n    SELECT \n        DATE_TRUNC('month', sale_date) AS sale_month,\n        SUM(amount) AS revenue\n    FROM sales\n    WHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\n    GROUP BY 1\n),\nSalesWithLag AS (\n    SELECT \n        sale_month,\n        revenue,\n        LAG(revenue) OVER (ORDER BY sale_month) AS previous_month_revenue\n    FROM MonthlySales\n)\nSELECT \n    sale_month,\n    revenue,\n    previous_month_revenue,\n    ROUND(((revenue - previous_month_revenue) / previous_month_revenue) * 100, 2) AS mom_growth_percentage\nFROM SalesWithLag;"}
{"instruction": "Perform a Full Outer Join to compare inventory levels between two warehouses, listing items present in either or both, handling NULLs with COALESCE.", "output": "SELECT \n    COALESCE(w1.product_id, w2.product_id) AS product_id,\n    p.product_name,\n    COALESCE(w1.quantity, 0) AS warehouse_a_qty,\n    COALESCE(w2.quantity, 0) AS warehouse_b_qty,\n    COALESCE(w1.quantity, 0) - COALESCE(w2.quantity, 0) AS difference\nFROM warehouse_a_inventory w1\nFULL OUTER JOIN warehouse_b_inventory w2 \n    ON w1.product_id = w2.product_id\nJOIN products p \n    ON p.product_id = COALESCE(w1.product_id, w2.product_id)\nORDER BY product_id;"}
{"instruction": "Write a Recursive CTE to generate an organizational chart hierarchy showing the employee name, their manager's name, and their hierarchical level (depth) within the company, starting from the CEO (manager_id is NULL).", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Select the top-level employee (CEO)\n    SELECT \n        employee_id, \n        name, \n        manager_id, \n        1 AS level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the CTE with employees to find subordinates\n    SELECT \n        e.employee_id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.employee_id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Calculate the 7-day moving average of daily revenue for the current year using a Window Function, ensuring that gaps in dates are handled (assuming the dates exist in the source table).", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in user login activity. Find the start date, end date, and total duration of consecutive days a user logged in without missing a day.", "output": "WITH distinct_logins AS (\n    SELECT DISTINCT user_id, login_date \n    FROM user_logins\n),\ngrouped_logins AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM distinct_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS consecutive_days\nFROM grouped_logins\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "Perform a Cohort Analysis to calculate the retention rate. For each month in 2023, calculate how many unique customers made their first purchase (cohort size) and what percentage of them made another purchase in the subsequent month.", "output": "WITH first_purchases AS (\n    SELECT \n        customer_id, \n        DATE_TRUNC('month', MIN(order_date)) AS cohort_month\n    FROM orders\n    GROUP BY customer_id\n),\nsubsequent_activity AS (\n    SELECT \n        fp.customer_id,\n        fp.cohort_month,\n        CASE \n            WHEN o.order_date >= fp.cohort_month + INTERVAL '1 month' \n             AND o.order_date < fp.cohort_month + INTERVAL '2 months' THEN 1 \n            ELSE 0 \n        END AS retained_next_month\n    FROM first_purchases fp\n    LEFT JOIN orders o ON fp.customer_id = o.customer_id\n)\nSELECT \n    cohort_month,\n    COUNT(DISTINCT customer_id) AS cohort_size,\n    COUNT(DISTINCT CASE WHEN retained_next_month = 1 THEN customer_id END) AS retained_users,\n    ROUND(COUNT(DISTINCT CASE WHEN retained_next_month = 1 THEN customer_id END)::numeric / COUNT(DISTINCT customer_id) * 100, 2) AS retention_rate_pct\nFROM subsequent_activity\nWHERE cohort_month BETWEEN '2023-01-01' AND '2023-12-31'\nGROUP BY cohort_month\nORDER BY cohort_month;"}
{"instruction": "Find the top 3 highest-paid employees in each department using `DENSE_RANK`, but only include departments that have at least 5 employees.", "output": "WITH dept_counts AS (\n    SELECT department_id \n    FROM employees \n    GROUP BY department_id \n    HAVING COUNT(*) >= 5\n),\nranked_employees AS (\n    SELECT \n        e.name,\n        e.salary,\n        e.department_id,\n        DENSE_RANK() OVER (PARTITION BY e.department_id ORDER BY e.salary DESC) as rank_pos\n    FROM employees e\n    JOIN dept_counts dc ON e.department_id = dc.department_id\n)\nSELECT * \nFROM ranked_employees \nWHERE rank_pos <= 3;"}
{"instruction": "Use a `LATERAL` join to retrieve the 3 most recent comments for every blog post published in the last 30 days. This is often more efficient than a correlated subquery or window function for top-N-per-group.", "output": "SELECT \n    p.post_id,\n    p.title,\n    c.comment_id,\n    c.comment_text,\n    c.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_id, comment_text, created_at\n    FROM comments\n    WHERE post_id = p.post_id\n    ORDER BY created_at DESC\n    LIMIT 3\n) c\nWHERE p.published_date >= CURRENT_DATE - INTERVAL '30 days';"}
{"instruction": "Pivot a table of monthly sales data (columns: `year`, `month`, `amount`) so that each month becomes a column (Jan, Feb, Mar, ...) for each year using the PostgreSQL `FILTER` clause.", "output": "SELECT \n    year,\n    SUM(amount) FILTER (WHERE month = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE month = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE month = 3) AS mar_sales,\n    SUM(amount) FILTER (WHERE month = 4) AS apr_sales,\n    SUM(amount) FILTER (WHERE month = 5) AS may_sales,\n    SUM(amount) FILTER (WHERE month = 6) AS jun_sales,\n    SUM(amount) FILTER (WHERE month = 7) AS jul_sales,\n    SUM(amount) FILTER (WHERE month = 8) AS aug_sales,\n    SUM(amount) FILTER (WHERE month = 9) AS sep_sales,\n    SUM(amount) FILTER (WHERE month = 10) AS oct_sales,\n    SUM(amount) FILTER (WHERE month = 11) AS nov_sales,\n    SUM(amount) FILTER (WHERE month = 12) AS dec_sales\nFROM monthly_sales\nGROUP BY year\nORDER BY year;"}
{"instruction": "DBA Task: Identify the top 10 largest tables in a PostgreSQL database, including their index size, and display the result in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS table_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "DBA Task: List currently active queries that have been running for more than 5 minutes, excluding the current query itself, to identify potential performance bottlenecks.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    age(clock_timestamp(), query_start) as duration,\n    query \nFROM pg_stat_activity \nWHERE state = 'active' \n  AND age(clock_timestamp(), query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid()\nORDER BY duration DESC;"}
{"instruction": "Perform an 'Upsert' (Insert or Update) operation. Insert a new inventory record for a product, but if the product_id already exists, update the quantity by adding the new amount to the existing stock.", "output": "INSERT INTO inventory (product_id, warehouse_id, quantity, last_updated)\nVALUES (101, 1, 50, CURRENT_TIMESTAMP)\nON CONFLICT (product_id, warehouse_id) \nDO UPDATE SET \n    quantity = inventory.quantity + EXCLUDED.quantity,\n    last_updated = EXCLUDED.last_updated;"}
{"instruction": "Write a recursive CTE (Common Table Expression) to traverse an employee hierarchy table (columns: id, name, manager_id). The goal is to generate the full reporting path (names separated by ' -> ') for a specific employee with ID 42, starting from the top-level manager down to the employee.", "output": "WITH RECURSIVE HierarchyPath AS (\n    -- Anchor member: select the top-level manager (roots)\n    SELECT id, name, manager_id, CAST(name AS TEXT) AS path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join with the previous level\n    SELECT e.id, e.name, e.manager_id, hp.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN HierarchyPath hp ON e.manager_id = hp.id\n)\nSELECT path \nFROM HierarchyPath \nWHERE id = 42;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue for each store, along with a running total of revenue for the current year. Use Window Functions.", "output": "SELECT \n    store_id,\n    sale_date,\n    revenue,\n    AVG(revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7d,\n    SUM(revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date\n    ) AS ytd_running_total\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY store_id, sale_date;"}
{"instruction": "Identify the top 3 highest-paid employees in each department. If there is a tie in salary, the ranking should not skip numbers (use DENSE_RANK).", "output": "WITH RankedSalaries AS (\n    SELECT \n        employee_name, \n        department_id, \n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT * \nFROM RankedSalaries \nWHERE rank_num <= 3;"}
{"instruction": "PostgreSQL DBA Task: Write a query to list the top 10 largest tables in the database, displaying the table name and its total size (including indexes) in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform a 'Gap Analysis' on a table of invoice IDs. Assuming invoice IDs should be sequential, write a query to find the start and end numbers of any missing ranges in the sequence.", "output": "SELECT \n    id + 1 AS gap_start, \n    next_id - 1 AS gap_end\nFROM (\n    SELECT \n        id, \n        LEAD(id) OVER (ORDER BY id) AS next_id\n    FROM invoices\n) sub\nWHERE id + 1 < next_id;"}
{"instruction": "Use a LATERAL JOIN to retrieve the single most recent order for every customer efficiently. This avoids a correlated subquery in the SELECT clause.", "output": "SELECT \n    c.customer_name, \n    c.email, \n    o.order_date, \n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 1\n) o;"}
{"instruction": "Pivot a table containing monthly sales data (columns: year, month, amount) into a cross-tab format where each month is a separate column for the year 2023.", "output": "SELECT \n    year,\n    SUM(CASE WHEN month = 'Jan' THEN amount ELSE 0 END) AS Jan,\n    SUM(CASE WHEN month = 'Feb' THEN amount ELSE 0 END) AS Feb,\n    SUM(CASE WHEN month = 'Mar' THEN amount ELSE 0 END) AS Mar,\n    SUM(CASE WHEN month = 'Apr' THEN amount ELSE 0 END) AS Apr,\n    -- ... continue for remaining months ...\n    SUM(CASE WHEN month = 'Dec' THEN amount ELSE 0 END) AS Dec\nFROM sales_data\nWHERE year = 2023\nGROUP BY year;"}
{"instruction": "PostgreSQL DBA Task: Identify currently active queries that have been running for more than 5 minutes, excluding idle connections, to troubleshoot performance issues.", "output": "SELECT \n    pid, \n    usename, \n    now() - query_start AS duration, \n    query, \n    state\nFROM pg_stat_activity\nWHERE state != 'idle' \n  AND now() - query_start > interval '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Calculate 'Session Churn': Identify users who logged in, but then did not log in again within the subsequent 30 days. Use LAG/LEAD window functions.", "output": "WITH LoginGaps AS (\n    SELECT \n        user_id, \n        login_date,\n        LEAD(login_date) OVER (PARTITION BY user_id ORDER BY login_date) as next_login\n    FROM user_logins\n)\nSELECT DISTINCT user_id\nFROM LoginGaps\nWHERE (next_login - login_date) > 30 \n   OR next_login IS NULL;"}
{"instruction": "Parse a JSONB column named 'attributes' in a product table. Extract all products where the JSON contains a key 'color' set to 'red' and aggregate the total stock.", "output": "SELECT \n    SUM((attributes ->> 'stock_quantity')::INT) as total_red_stock\nFROM products\nWHERE attributes @> '{\"color\": \"red\"}';"}
{"instruction": "Write a recursive CTE to generate a hierarchical view of employees. The output should show the employee's name, their manager's name, and their 'level' in the hierarchy (1 for top-level managers). Assume an 'employees' table with 'id', 'name', and 'manager_id'.", "output": "WITH RECURSIVE org_chart AS (\n    -- Anchor member: Top-level managers (no manager)\n    SELECT \n        id, \n        name, \n        manager_id, \n        1 as level,\n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Employees reporting to the previous level\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        oc.level + 1,\n        oc.path || ' -> ' || e.name\n    FROM employees e\n    INNER JOIN org_chart oc ON e.manager_id = oc.id\n)\nSELECT * FROM org_chart ORDER BY path;"}
{"instruction": "Create a query using window functions to calculate the daily revenue, the cumulative running total revenue for the current month, and the 3-day moving average of revenue for a 'sales' table.", "output": "SELECT \n    sale_date,\n    SUM(amount) as daily_revenue,\n    SUM(SUM(amount)) OVER (\n        PARTITION BY DATE_TRUNC('month', sale_date) \n        ORDER BY sale_date\n    ) as running_total_month,\n    AVG(SUM(amount)) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n    ) as moving_avg_3_day\nFROM sales\nGROUP BY sale_date\nORDER BY sale_date;"}
{"instruction": "Identify 'islands' of consecutive login days for users. Write a query that groups consecutive dates together and returns the user_id, start_date, end_date, and count of consecutive days from a 'user_logins' table.", "output": "WITH dated_logins AS (\n    SELECT DISTINCT user_id, login_date \n    FROM user_logins\n),\ngroups AS (\n    SELECT \n        user_id, \n        login_date,\n        -- Create a grouping identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM dated_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) as island_start,\n    MAX(login_date) as island_end,\n    COUNT(*) as consecutive_days\nFROM groups\nGROUP BY user_id, grp\nORDER BY user_id, island_start;"}
{"instruction": "Write a PostgreSQL administration query to find the top 5 largest tables in the database, displaying their size in a human-readable format (e.g., MB, GB), including indexes and toast data.", "output": "SELECT\n    schemaname || '.' || relname AS table_full_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size\nFROM pg_catalog.pg_stat_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 5;"}
{"instruction": "Use a LATERAL join to retrieve the top 3 highest-rated reviews for every product in the 'products' table without using a window function in the SELECT list.", "output": "SELECT \n    p.product_name,\n    r.rating,\n    r.comment\nFROM products p,\nLATERAL (\n    SELECT rating, comment\n    FROM reviews\n    WHERE product_id = p.id\n    ORDER BY rating DESC, created_at DESC\n    LIMIT 3\n) r\nORDER BY p.product_name, r.rating DESC;"}
{"instruction": "Perform a 'pivot' operation using conditional aggregation (FILTER clause) to show total sales for each product category (rows) across four quarters (columns).", "output": "SELECT \n    category_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS q2_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS q3_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS q4_sales\nFROM sales s\nJOIN products p ON s.product_id = p.id\nJOIN categories c ON p.category_id = c.id\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY category_name;"}
{"instruction": "Write a query to handle JSONB data in PostgreSQL. Select rows where the 'attributes' JSONB column contains a key 'color' with value 'red', and expand the 'tags' JSON array inside that column into separate rows.", "output": "SELECT \n    id, \n    attributes ->> 'name' as item_name,\n    tag_element\nFROM inventory,\nLATERAL jsonb_array_elements_text(attributes -> 'tags') as tag_element\nWHERE attributes @> '{\"color\": \"red\"}';"}
{"instruction": "DBA Task: Identify queries that are currently blocked by locks held by other transactions. Return the PID and query of both the blocking and the blocked activity.", "output": "SELECT \n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocked_activity.query    AS blocked_query,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query   AS blocking_query\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Perform a UPSERT (INSERT ON CONFLICT) operation. Insert a new record into 'daily_stats'. If a record with the same 'stat_date' and 'category_id' exists, increment the existing 'view_count' by the new value.", "output": "INSERT INTO daily_stats (stat_date, category_id, view_count)\nVALUES ('2023-10-27', 5, 100)\nON CONFLICT (stat_date, category_id) \nDO UPDATE SET \n    view_count = daily_stats.view_count + EXCLUDED.view_count,\n    last_updated = NOW();"}
{"instruction": "Write a query using a Full Outer Join to compare sales between two years (2022 and 2023) for all products, handling cases where a product sold in one year but not the other using COALESCE.", "output": "WITH sales_2022 AS (\n    SELECT product_id, SUM(amount) as total FROM sales WHERE EXTRACT(year FROM sale_date) = 2022 GROUP BY product_id\n),\nsales_2023 AS (\n    SELECT product_id, SUM(amount) as total FROM sales WHERE EXTRACT(year FROM sale_date) = 2023 GROUP BY product_id\n)\nSELECT \n    COALESCE(s22.product_id, s23.product_id) as product_id,\n    COALESCE(s22.total, 0) as sales_2022,\n    COALESCE(s23.total, 0) as sales_2023,\n    (COALESCE(s23.total, 0) - COALESCE(s22.total, 0)) as diff\nFROM sales_2022 s22\nFULL OUTER JOIN sales_2023 s23 ON s22.product_id = s23.product_id;"}
{"instruction": "Write a query using a Recursive CTE to generate a hierarchical view of an organization. Given an 'employees' table with 'id', 'name', and 'manager_id', find the management path (names separated by '->') and the hierarchy depth level for a specific employee with ID 105.", "output": "WITH RECURSIVE management_chain AS (\n    -- Anchor member: Start with the specific employee\n    SELECT id, name, manager_id, 1 AS depth, name::TEXT AS path\n    FROM employees\n    WHERE id = 105\n\n    UNION ALL\n\n    -- Recursive member: Join with the manager to move up the chain\n    SELECT e.id, e.name, e.manager_id, mc.depth + 1, e.name || ' -> ' || mc.path\n    FROM employees e\n    INNER JOIN management_chain mc ON e.id = mc.manager_id\n)\nSELECT path, depth \nFROM management_chain \nORDER BY depth DESC \nLIMIT 1;"}
{"instruction": "Calculate the 7-day moving average of daily sales and the running total of sales for the current year, partitioned by store location. The table 'daily_sales' contains 'store_id', 'sale_date', and 'revenue'.", "output": "SELECT \n    store_id,\n    sale_date,\n    revenue,\n    AVG(revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7_days,\n    SUM(revenue) OVER (\n        PARTITION BY store_id \n        ORDER BY sale_date\n    ) AS running_total_ytd\nFROM daily_sales\nWHERE sale_date >= DATE_TRUNC('year', CURRENT_DATE)\nORDER BY store_id, sale_date;"}
{"instruction": "Identify 'Gaps and Islands' in a sequence of login dates. Given a 'user_logins' table with 'user_id' and 'login_date', find the start and end dates of consecutive login streaks for every user.", "output": "WITH grouped_dates AS (\n    SELECT \n        user_id,\n        login_date,\n        -- Create a group identifier by subtracting the row number from the date\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') AS grp\n    FROM user_logins\n)\nSELECT \n    user_id,\n    MIN(login_date) AS streak_start,\n    MAX(login_date) AS streak_end,\n    COUNT(*) AS streak_length\nFROM grouped_dates\nGROUP BY user_id, grp\nORDER BY user_id, streak_start;"}
{"instruction": "PostgreSQL Administration: Write a query to list the top 10 largest tables in the current database, showing the table name, schema, and the total size (including indexes) formatted in a human-readable format.", "output": "SELECT\n    schemaname AS table_schema,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size,\n    pg_size_pretty(pg_relation_size(relid)) AS data_size,\n    pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS index_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Perform a 'Pivot' operation using ANSI SQL FILTER clauses to transform monthly sales rows into columns. The source table 'sales' has 'product_id', 'sale_date', and 'amount'. The output should show total sales for Q1 (Jan, Feb, Mar) per product.", "output": "SELECT \n    product_id,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 1) AS jan_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 2) AS feb_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(MONTH FROM sale_date) = 3) AS mar_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS total_q1\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY product_id\nORDER BY total_q1 DESC;"}
{"instruction": "Use a LATERAL JOIN (PostgreSQL) to find the top 3 most recent orders for every customer who lives in 'New York'. The tables are 'customers' and 'orders'.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.order_date,\n    o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.customer_id\n    ORDER BY order_date DESC\n    LIMIT 3\n) o\nWHERE c.city = 'New York';"}
{"instruction": "Find the top 3 products in each category based on revenue using the DENSE_RANK window function. If there is a tie in revenue, they should share the rank, but the next rank should be consecutive.", "output": "WITH ranked_products AS (\n    SELECT \n        category_id,\n        product_id,\n        SUM(price * quantity) as total_revenue,\n        DENSE_RANK() OVER (\n            PARTITION BY category_id \n            ORDER BY SUM(price * quantity) DESC\n        ) as rank\n    FROM order_details\n    JOIN products ON order_details.product_id = products.product_id\n    GROUP BY category_id, product_id\n)\nSELECT * \nFROM ranked_products\nWHERE rank <= 3;"}
{"instruction": "PostgreSQL Administration: Identify currently active queries that have been running for more than 5 minutes, excluding the current query itself.", "output": "SELECT \n    pid,\n    usename AS username,\n    datname AS database_name,\n    client_addr,\n    application_name,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > INTERVAL '5 minutes'\n  AND pid <> pg_backend_pid();"}
{"instruction": "Write a query to calculate Customer Churn. Identify customers who placed an order in the previous month but have NOT placed an order in the current month.", "output": "WITH last_month_active AS (\n    SELECT DISTINCT customer_id \n    FROM orders \n    WHERE order_date >= DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month')\n      AND order_date < DATE_TRUNC('month', CURRENT_DATE)\n),\ncurrent_month_active AS (\n    SELECT DISTINCT customer_id \n    FROM orders \n    WHERE order_date >= DATE_TRUNC('month', CURRENT_DATE)\n)\nSELECT lm.customer_id\nFROM last_month_active lm\nLEFT JOIN current_month_active cm ON lm.customer_id = cm.customer_id\nWHERE cm.customer_id IS NULL;"}
{"instruction": "Work with JSONB data in PostgreSQL. Given a table 'events' with a JSONB column 'payload', calculate the average processing time grouped by event type. The JSON structure is {'type': 'click', 'meta': {'processing_time_ms': 120}}.", "output": "SELECT \n    payload ->> 'type' AS event_type,\n    AVG((payload -> 'meta' ->> 'processing_time_ms')::NUMERIC) AS avg_processing_time\nFROM events\nGROUP BY payload ->> 'type'\nHAVING COUNT(*) > 10\nORDER BY avg_processing_time DESC;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to find the top 3 highest-paid employees within each department. The output should include the department name, employee name, salary, and their rank within the department.", "output": "WITH RankedSalaries AS (\n    SELECT \n        d.department_name,\n        e.employee_name,\n        e.salary,\n        DENSE_RANK() OVER (PARTITION BY e.department_id ORDER BY e.salary DESC) as salary_rank\n    FROM employees e\n    JOIN departments d ON e.department_id = d.department_id\n)\nSELECT \n    department_name,\n    employee_name,\n    salary,\n    salary_rank\nFROM RankedSalaries\nWHERE salary_rank <= 3\nORDER BY department_name, salary_rank;"}
{"instruction": "Create a recursive CTE to generate a hierarchical view of an organization from an 'employees' table (containing 'id', 'name', and 'manager_id'). The result should show the employee's name and their 'path' from the CEO (where manager_id is NULL) down to them.", "output": "WITH RECURSIVE OrgHierarchy AS (\n    -- Anchor member: Select the top-level manager (CEO)\n    SELECT \n        id,\n        name,\n        manager_id,\n        CAST(name AS TEXT) as path,\n        1 as level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: Join the hierarchy with employees reporting to the previous level\n    SELECT \n        e.id,\n        e.name,\n        e.manager_id,\n        h.path || ' -> ' || e.name,\n        h.level + 1\n    FROM employees e\n    JOIN OrgHierarchy h ON e.manager_id = h.id\n)\nSELECT * FROM OrgHierarchy\nORDER BY path;"}
{"instruction": "Write a PostgreSQL query to identify customers who have purchased 'Product A' but have never purchased 'Product B'. Use conditional aggregation in the HAVING clause rather than subqueries or set operations.", "output": "SELECT \n    c.customer_id,\n    c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nGROUP BY c.customer_id, c.customer_name\nHAVING \n    COUNT(CASE WHEN p.product_name = 'Product A' THEN 1 END) > 0\n    AND \n    COUNT(CASE WHEN p.product_name = 'Product B' THEN 1 END) = 0;"}
{"instruction": "Calculate the 7-day moving average of daily sales revenue. The result should include the date, daily revenue, and the moving average formatted to 2 decimal places.", "output": "SELECT \n    sale_date,\n    daily_revenue,\n    ROUND(\n        AVG(daily_revenue) OVER (\n            ORDER BY sale_date \n            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n        ), 2\n    ) as moving_average_7d\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Write a database administration query to find the total size on disk (including indexes and toast data) of a specific table named 'large_event_logs' and display it in a human-readable format (e.g., MB, GB).", "output": "SELECT \n    pg_size_pretty(pg_total_relation_size('large_event_logs')) as total_table_size,\n    pg_size_pretty(pg_relation_size('large_event_logs')) as table_data_size,\n    pg_size_pretty(pg_indexes_size('large_event_logs')) as index_size;"}
{"instruction": "Use a LATERAL JOIN to retrieve the 3 most recent comments for every blog post published in 2023. This is more efficient than a correlated subquery for fetching 'top N per group'.", "output": "SELECT \n    p.post_id,\n    p.title,\n    recent_comments.comment_text,\n    recent_comments.created_at\nFROM posts p\nCROSS JOIN LATERAL (\n    SELECT comment_text, created_at\n    FROM comments c\n    WHERE c.post_id = p.post_id\n    ORDER BY c.created_at DESC\n    LIMIT 3\n) AS recent_comments\nWHERE p.published_date >= '2023-01-01' \n  AND p.published_date <= '2023-12-31';"}
{"instruction": "Perform a 'Gap Analysis' on a table of invoice numbers (assumed to be sequential integers). Identify the start and end of any missing ranges of invoice IDs.", "output": "WITH LeadInvoices AS (\n    SELECT \n        invoice_id,\n        LEAD(invoice_id) OVER (ORDER BY invoice_id) as next_invoice_id\n    FROM invoices\n)\nSELECT \n    invoice_id + 1 as gap_start,\n    next_invoice_id - 1 as gap_end\nFROM LeadInvoices\nWHERE next_invoice_id - invoice_id > 1;"}
{"instruction": "Write a query to pivot a sales table (columns: product, month, amount) to display months as columns (January, February, March) for the first quarter, summing the amount for each product. Use the PostgreSQL FILTER clause for readability.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE month = 'January') AS jan_sales,\n    SUM(amount) FILTER (WHERE month = 'February') AS feb_sales,\n    SUM(amount) FILTER (WHERE month = 'March') AS mar_sales\nFROM sales_data\nGROUP BY product_name\nORDER BY product_name;"}
{"instruction": "Write a PostgreSQL administration query to identify currently active queries that have been running for longer than 5 minutes, showing the user, the duration, and the query text.", "output": "SELECT \n    pid,\n    usename AS username,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE state = 'active' \n  AND (now() - query_start) > interval '5 minutes'\nORDER BY duration DESC;"}
{"instruction": "Update a JSONB column named 'settings' in a 'users' table. Specifically, set the property 'notifications_enabled' to true for all users who have a specific tag 'beta_tester' inside a JSON array stored in the same 'settings' column.", "output": "UPDATE users\nSET settings = jsonb_set(settings, '{notifications_enabled}', 'true')\nWHERE settings @> '{\"tags\": [\"beta_tester\"]}';"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to find the top 3 sales representatives by revenue within each region, but only for regions where the total sales exceed $1,000,000.", "output": "WITH RegionTotals AS (\n    SELECT region_id, SUM(sales_amount) as total_region_sales\n    FROM sales\n    GROUP BY region_id\n    HAVING SUM(sales_amount) > 1000000\n),\nRankedSales AS (\n    SELECT \n        s.rep_name, \n        s.region_id, \n        s.sales_amount,\n        DENSE_RANK() OVER (PARTITION BY s.region_id ORDER BY s.sales_amount DESC) as rank\n    FROM sales s\n    JOIN RegionTotals rt ON s.region_id = rt.region_id\n)\nSELECT rep_name, region_id, sales_amount\nFROM RankedSales\nWHERE rank <= 3;"}
{"instruction": "Create a recursive CTE to traverse an employee hierarchy (adjacency list model) to find the complete management chain (path) for a specific employee with ID 105, returning the path as a string (e.g., 'CEO > VP > Manager > Emp').", "output": "WITH RECURSIVE ManagementPath AS (\n    -- Anchor member: start with the specific employee\n    SELECT employee_id, manager_id, name, name::text as path\n    FROM employees\n    WHERE employee_id = 105\n    \n    UNION ALL\n    \n    -- Recursive member: join with manager\n    SELECT e.employee_id, e.manager_id, e.name, e.name || ' > ' || mp.path\n    FROM employees e\n    INNER JOIN ManagementPath mp ON e.employee_id = mp.manager_id\n)\nSELECT path \nFROM ManagementPath \nWHERE manager_id IS NULL;"}
{"instruction": "Write a query to calculate a 7-day moving average of daily revenue for the current year, ensuring that days with no sales are treated as 0 (requires generating a date series).", "output": "WITH DateSeries AS (\n    SELECT generate_series(\n        DATE_TRUNC('year', CURRENT_DATE), \n        DATE_TRUNC('year', CURRENT_DATE) + INTERVAL '1 year' - INTERVAL '1 day', \n        INTERVAL '1 day'\n    )::date AS sale_date\n),\nDailySales AS (\n    SELECT ds.sale_date, COALESCE(SUM(s.amount), 0) as daily_revenue\n    FROM DateSeries ds\n    LEFT JOIN sales s ON s.transaction_date = ds.sale_date\n    GROUP BY ds.sale_date\n)\nSELECT \n    sale_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_days\nFROM DailySales;"}
{"instruction": "Perform a 'Gaps and Islands' analysis to identify consecutive days a user logged in. Return the user_id, start date of the streak, end date of the streak, and the length of the streak in days.", "output": "WITH DailyLogins AS (\n    -- Ensure one record per user per day\n    SELECT DISTINCT user_id, login_date::date\n    FROM user_logs\n),\nGroups AS (\n    SELECT \n        user_id, \n        login_date,\n        -- Subtracting row_number from date creates a constant date for consecutive sequences\n        login_date - (ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) * INTERVAL '1 day') as grp\n    FROM DailyLogins\n)\nSELECT \n    user_id, \n    MIN(login_date) as streak_start, \n    MAX(login_date) as streak_end, \n    COUNT(*) as streak_days\nFROM Groups\nGROUP BY user_id, grp\nORDER BY streak_days DESC;"}
{"instruction": "Use a LATERAL JOIN to find the top 2 most recent orders for every customer who has placed at least 5 orders in total. This is often more efficient than a window function for retrieving 'top N per group' when N is small.", "output": "SELECT c.customer_name, o.order_id, o.order_date, o.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT order_id, order_date, total_amount\n    FROM orders\n    WHERE customer_id = c.id\n    ORDER BY order_date DESC\n    LIMIT 2\n) o\nWHERE c.id IN (\n    SELECT customer_id \n    FROM orders \n    GROUP BY customer_id \n    HAVING COUNT(*) >= 5\n);"}
{"instruction": "Write a PostgreSQL specific query to query a JSONB column named 'attributes'. Find all products where the 'color' key is 'red' and the product has a tag 'clearance' inside a 'tags' JSON array.", "output": "SELECT product_id, product_name, attributes\nFROM products\nWHERE \n    attributes ->> 'color' = 'red' \n    AND \n    attributes @> '{\"tags\": [\"clearance\"]}';"}
{"instruction": "Construct a Pivot Table using the ANSI SQL `FILTER` clause to display total sales for each product category (Electronics, Clothing, Home) per month for the year 2023.", "output": "SELECT \n    EXTRACT(MONTH FROM sale_date) as sale_month,\n    SUM(amount) FILTER (WHERE category = 'Electronics') as electronics_sales,\n    SUM(amount) FILTER (WHERE category = 'Clothing') as clothing_sales,\n    SUM(amount) FILTER (WHERE category = 'Home') as home_sales\nFROM sales\nWHERE EXTRACT(YEAR FROM sale_date) = 2023\nGROUP BY 1\nORDER BY 1;"}
{"instruction": "Database Administration: Write a query to identify currently active queries that have been running for more than 5 minutes, excluding the query you are currently running.", "output": "SELECT \n    pid, \n    usename, \n    state, \n    NOW() - query_start as duration, \n    query\nFROM pg_stat_activity\nWHERE \n    state = 'active' \n    AND (NOW() - query_start) > INTERVAL '5 minutes'\n    AND pid <> pg_backend_pid();"}
{"instruction": "Write an 'UPSERT' (Insert on Conflict) query for PostgreSQL. Insert a new user record; if the email already exists, update the `last_login` timestamp and increment a `login_count` column.", "output": "INSERT INTO users (username, email, last_login, login_count)\nVALUES ('jdoe', 'jdoe@example.com', NOW(), 1)\nON CONFLICT (email) \nDO UPDATE SET \n    last_login = EXCLUDED.last_login,\n    login_count = users.login_count + 1;"}
{"instruction": "Database Administration: Write a query to find the top 5 largest tables in the current database, displaying their size in a human-readable format (including indexes).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 5;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and a Window Function to calculate the running total of sales for each customer, ordered by the transaction date.", "output": "WITH CustomerSales AS (\n    SELECT \n        customer_id,\n        transaction_date,\n        amount\n    FROM sales\n)\nSELECT \n    customer_id,\n    transaction_date,\n    amount,\n    SUM(amount) OVER (\n        PARTITION BY customer_id \n        ORDER BY transaction_date\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ) AS running_total\nFROM CustomerSales\nORDER BY customer_id, transaction_date;"}
{"instruction": "Create a recursive CTE to traverse an employee hierarchy and retrieve all subordinates (direct and indirect) of a manager with `employee_id = 1`.", "output": "WITH RECURSIVE EmployeeHierarchy AS (\n    -- Anchor member: select the specific manager\n    SELECT \n        employee_id, \n        manager_id, \n        full_name, \n        1 AS level\n    FROM employees\n    WHERE employee_id = 1\n\n    UNION ALL\n\n    -- Recursive member: join to find subordinates\n    SELECT \n        e.employee_id, \n        e.manager_id, \n        e.full_name, \n        eh.level + 1\n    FROM employees e\n    INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM EmployeeHierarchy;"}
{"instruction": "Write a query to find the top 3 highest-paid employees in each department using the `DENSE_RANK()` window function, handling ties appropriately.", "output": "WITH RankedSalaries AS (\n    SELECT \n        department_id,\n        employee_name,\n        salary,\n        DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_num\n    FROM employees\n)\nSELECT \n    department_id,\n    employee_name,\n    salary\nFROM RankedSalaries\nWHERE rank_num <= 3\nORDER BY department_id, rank_num;"}
{"instruction": "Perform a gap analysis using `generate_series` to find days in January 2023 where no login events occurred.", "output": "SELECT \n    calendar_date::date AS missing_date\nFROM \n    generate_series('2023-01-01'::date, '2023-01-31'::date, '1 day') AS calendar_date\nLEFT JOIN user_logins ul \n    ON calendar_date = ul.login_timestamp::date\nWHERE \n    ul.login_timestamp IS NULL;"}
{"instruction": "Write a PostgreSQL administration query to identify the top 10 largest tables in the current database schema, including their total size on disk (data + indexes).", "output": "SELECT\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC\nLIMIT 10;"}
{"instruction": "Use PostgreSQL's `FILTER` clause to create a pivot-style report showing total sales for 'Electronics' and 'Furniture' categories side-by-side for each region.", "output": "SELECT \n    region,\n    SUM(sales_amount) FILTER (WHERE category = 'Electronics') AS electronics_sales,\n    SUM(sales_amount) FILTER (WHERE category = 'Furniture') AS furniture_sales\nFROM regional_sales\nGROUP BY region\nORDER BY region;"}
{"instruction": "Calculate the 7-day moving average of daily revenue using a Window Function with a specific frame clause.", "output": "SELECT \n    report_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY report_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average_7d\nFROM daily_financials\nORDER BY report_date;"}
{"instruction": "Write a query to identify duplicate email addresses in the `users` table and delete all but the one with the lowest `id`.", "output": "DELETE FROM users\nWHERE id IN (\n    SELECT id\n    FROM (\n        SELECT \n            id,\n            ROW_NUMBER() OVER (PARTITION BY email ORDER BY id ASC) as row_num\n        FROM users\n    ) t\n    WHERE t.row_num > 1\n);"}
{"instruction": "Write a database administration query to list all currently active queries running for longer than 5 minutes, showing the user, IP address, and the query text.", "output": "SELECT \n    pid,\n    usename,\n    client_addr,\n    state,\n    now() - query_start AS duration,\n    query\nFROM pg_stat_activity\nWHERE \n    state = 'active' \n    AND (now() - query_start) > interval '5 minutes';"}
{"instruction": "Query a table containing a JSONB column named `attributes` to find products where the 'color' key is 'red' and the 'weight' key is greater than 10.", "output": "SELECT \n    product_id,\n    product_name,\n    attributes\nFROM products\nWHERE \n    attributes ->> 'color' = 'red'\n    AND (attributes ->> 'weight')::numeric > 10;"}
{"instruction": "Write a query using a Common Table Expression (CTE) and Window Functions to calculate the daily revenue, the running total revenue for the month, and the 7-day moving average of revenue for a specific store.", "output": "WITH daily_sales AS (\n    SELECT \n        sale_date,\n        SUM(amount) as daily_revenue\n    FROM sales\n    WHERE store_id = 1\n    GROUP BY sale_date\n)\nSELECT \n    sale_date,\n    daily_revenue,\n    SUM(daily_revenue) OVER (ORDER BY sale_date) as running_total,\n    AVG(daily_revenue) OVER (\n        ORDER BY sale_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) as moving_avg_7_day\nFROM daily_sales\nORDER BY sale_date;"}
{"instruction": "Create a recursive CTE to generate a full hierarchical path (e.g., 'CEO > VP > Manager') for every employee in an 'employees' table containing 'id', 'name', and 'manager_id'.", "output": "WITH RECURSIVE hierarchy AS (\n    -- Anchor member: employees with no manager (top level)\n    SELECT \n        id, \n        name, \n        manager_id, \n        CAST(name AS TEXT) as path\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive member: join employees to their managers\n    SELECT \n        e.id, \n        e.name, \n        e.manager_id, \n        h.path || ' > ' || e.name\n    FROM employees e\n    INNER JOIN hierarchy h ON e.manager_id = h.id\n)\nSELECT * FROM hierarchy ORDER BY path;"}
{"instruction": "Write a PostgreSQL query to identify customers who have purchased 'Product A' but have never purchased 'Product B' using NOT EXISTS.", "output": "SELECT DISTINCT c.customer_id, c.customer_name\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN order_items oi ON o.order_id = oi.order_id\nJOIN products p ON oi.product_id = p.product_id\nWHERE p.product_name = 'Product A'\nAND NOT EXISTS (\n    SELECT 1\n    FROM orders o2\n    JOIN order_items oi2 ON o2.order_id = oi2.order_id\n    JOIN products p2 ON oi2.product_id = p2.product_id\n    WHERE o2.customer_id = c.customer_id\n    AND p2.product_name = 'Product B'\n);"}
{"instruction": "Use the DENSE_RANK() window function to find the top 3 highest-paid employees in each department. If there is a tie for salary, they should share the rank, and no ranks should be skipped.", "output": "WITH ranked_employees AS (\n    SELECT \n        employee_id,\n        first_name,\n        last_name,\n        department_id,\n        salary,\n        DENSE_RANK() OVER (\n            PARTITION BY department_id \n            ORDER BY salary DESC\n        ) as rank_num\n    FROM employees\n)\nSELECT * \nFROM ranked_employees \nWHERE rank_num <= 3;"}
{"instruction": "DBA Task: Write a query to list all tables in the current database schema along with their total size (including indexes) in a human-readable format (e.g., MB, GB).", "output": "SELECT\n    schemaname AS schema_name,\n    relname AS table_name,\n    pg_size_pretty(pg_total_relation_size(relid)) AS total_size\nFROM pg_catalog.pg_statio_user_tables\nORDER BY pg_total_relation_size(relid) DESC;"}
{"instruction": "Perform a 'pivot' operation using PostgreSQL's FILTER clause to display total sales per product (rows) for each quarter (columns) of the current year.", "output": "SELECT \n    product_name,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 1) AS q1_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 2) AS q2_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 3) AS q3_sales,\n    SUM(amount) FILTER (WHERE EXTRACT(QUARTER FROM sale_date) = 4) AS q4_sales\nFROM sales\nJOIN products ON sales.product_id = products.product_id\nWHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE)\nGROUP BY product_name;"}
{"instruction": "Write a query using a LATERAL join to retrieve the single most recent order for every customer efficiently without using window functions or subqueries in the select list.", "output": "SELECT \n    c.customer_id,\n    c.name,\n    recent_order.order_id,\n    recent_order.order_date,\n    recent_order.total_amount\nFROM customers c\nCROSS JOIN LATERAL (\n    SELECT *\n    FROM orders o\n    WHERE o.customer_id = c.customer_id\n    ORDER BY o.order_date DESC\n    LIMIT 1\n) AS recent_order;"}
{"instruction": "DBA Task: Identify currently running queries that are blocked by other transactions, showing the blocked PID, the blocking PID, and the query text for both.", "output": "SELECT\n    blocked_locks.pid     AS blocked_pid,\n    blocked_activity.usename  AS blocked_user,\n    blocked_activity.query    AS blocked_query,\n    blocking_locks.pid     AS blocking_pid,\n    blocking_activity.usename AS blocking_user,\n    blocking_activity.query   AS blocking_query\nFROM  pg_catalog.pg_locks         blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks         blocking_locks \n    ON blocking_locks.locktype = blocked_locks.locktype\n    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n    AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;"}
{"instruction": "Calculate 'Day 1 Retention' (users who signed up and performed an action the very next day) using a self-join and date arithmetic.", "output": "SELECT \n    COUNT(DISTINCT s.user_id) AS signups,\n    COUNT(DISTINCT a.user_id) AS retained_users,\n    (COUNT(DISTINCT a.user_id)::FLOAT / COUNT(DISTINCT s.user_id)) * 100 AS retention_rate_percent\nFROM user_actions s\nLEFT JOIN user_actions a \n    ON s.user_id = a.user_id \n    AND a.action_date = s.action_date + INTERVAL '1 day'\nWHERE s.action_type = 'signup';"}
{"instruction": "PostgreSQL JSONB: Write a query that filters a table 'api_logs' for rows where the JSONB column 'payload' contains a key 'status' with value 'error', and then expands a JSON array stored in 'payload->errors' into separate rows.", "output": "SELECT \n    log_id,\n    created_at,\n    error_detail\nFROM api_logs,\nLATERAL jsonb_array_elements_text(payload -> 'errors') AS error_detail\nWHERE payload @> '{\"status\": \"error\"}';"}
